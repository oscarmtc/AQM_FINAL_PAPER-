---
title: "AQM Final Paper: Code for Replication and Conduction of the Analysis"
author: "Ekaterina Leevik, Oscar Martinez, Elizabeth Sites"
date: ""
output:
  pdf_document:
    toc: no
    includes:
      in_header: header.tex
  # html_notebook:
    # toc: no
  html_document:
    toc: no
bibliography: 
---

## Introduction 

This file contains the code for the replication of the analysis presented in the written paper. All of the Tables and Graphs presented in the main sections of the paper, as well as the entire set of Materials presented in the Appendix can be generated using this code without need of additional manipulations. 

### Package-Setup & Data Download 

This first two chunks do not form part of the analysis. The first series of code lines has the purpose of defining the packages that will be required throughout the entire data preparation and analysis. The second chunk downloads the main data source and stors in in an object labeled "data". 

```{r Initial Setup & Download of Required Packages, include=FALSE} 

# The first line sets an option for the final document that can be produced from
# the .Rmd file. Don't worry about it.
knitr::opts_chunk$set(echo = TRUE)

# The next bit (lines 22-43) is quite powerful and useful. 
# First you define which packages you need for your analysis and assign it to 
# the p_needed object. 
p_needed <-
  c("viridis", "knitr", "sandwich", "magrittr", "kableExtra", "MASS", "dplyr", "data.table", "margins", "readr", "plm", "Hmisc", "stargazer")

# Now you check which packages are already installed on your computer.
# The function installed.packages() returns a vector with all the installed 
# packages.
packages <- rownames(installed.packages())
# Then you check which of the packages you need are not installed on your 
# computer yet. Essentially you compare the vector p_needed with the vector
# packages. The result of this comparison is assigned to p_to_install.
p_to_install <- p_needed[!(p_needed %in% packages)]
# If at least one element is in p_to_install you then install those missing
# packages.
if (length(p_to_install) > 0) {
  install.packages(p_to_install)
}
# Now that all packages are installed on the computer, you can load them for
# this project. Additionally the expression returns whether the packages were
# successfully loaded.
sapply(p_needed, require, character.only = TRUE)

```

``` {r Load the main data source}

data <- fread("spanish_political_attitudes_dataset_2017_to_2020.csv")

# in order to use the "fread" function we first have to download the "data.table" package. This function ("fread") is mainly employed for reading data from external files into R (in this case, the main data in in a csv format) in the form of data tables. It is especially useful when it comes to reading large datasets. The STATA equivalent is the "import delimited" command. 

```

## Data Preparation: Re-codeing, Re-scaling, and Generation of New variables

This section of the file corresponding to the process of preparing the data for the later analysis performs the following functions:
     1. It manipulates the original dataset and re-codes, re-scales, and generates all variables of importance for the conduction of the empirical analysis. Different groups of variables are generated in the following code chunks. Each code chunk specifies in its title the variables that are being generated, recoded, or modified. 
     2. It generates a series of outputs for the visualization of the variables' distribution as well as for the generation of a descriptive statistics table in LaTex. 

``` {r Generation of Variables "idcode", "time", "nwaves", "year", "female", "age"}

# This initial code chunk has the purpose of preparing the data for the latter statistical analysis. The preparation steps conducted stem from the replication material of "Sexism and the far-right vote: The individual dynamics of gender backlash." Although the initial replication code is available for STATA, we rewrite the code for R. Although some commands may be different and some steps may be either added or removed, the variables resulting (as well as their scales and coding schemes) should be exactly the same. 

#______________________________________________________________________________#
# (1): Generation of variable "idcode".

data$idcode <- data$codpanelista2 
mean(data$idcode) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
#  (2): Generation of the variable "time".

data$time <- data$wave - 9
data$time_labels <- factor(data$time, levels = 0:3, labels = c("2017", "2018", "2019", "2020"))
setorder(data, idcode, time_labels) # the "setorder()" function will  reorders the rows of the data table "data" based on the values of specified columns, in this case "idcode" and "time". This line of code will reorder the dataset in such a way that the rows are first sorted by the values in the "idcode" column, and within each unique value of "idcode", the rows are further sorted according to the values in the "time_labels" column.
summary(data$time) # CHECK: same descriptive statistics as STATA output 
summary(data$time_labels) # this is an additional factor variable created to assign the specific years to the "time" variable" 

#______________________________________________________________________________#
#  (3): Set the data to the panel data-format and sort according to "idcode".

# ... and we finaly set the dataset as panel data ...
data_panel <- pdata.frame(data, index = c("idcode", "time"))
# ... we also sort the dataset according to the variable "idcode" 
data_panel <- data_panel[order(data_panel$idcode), ]

#______________________________________________________________________________#
# (4): Generation of variable "nwaves"; this variable will indicate the total number of waves completed by each respondent (referred to by the variable "idcode").

# ... we first calculate the number of waves for each respondent ("idcode")
wave_counts <- data[, .N, by = idcode] # ... this line computes the count of observations (rows) for each unique value of "idcode" in the dataset ...
dim(wave_counts)
# ... we then merge the result back to the original dataset according to the variable "idcode"
data_panel <- merge(data_panel, wave_counts, by = "idcode", all.x = TRUE) # ... the "all.x = TRUE"-command specifies that all observations from the left dataset ("data") should be retained in the merged dataset, even if there are no matching observations in the right dataset ("wave_counts") ...
# ... we assign the count of observations to the "nwaves" variable
data_panel$nwaves <- data_panel$N 
# ... and finally remove the temporarily created "N" column
data_panel$N <- NULL
mean(data_panel$nwaves) # CHECK: same descriptive statistics as STATA output 
summary(data_panel$nwaves) # CHECK: same descriptive statistics as STATA output 
#... we finalize by removing the generated reference data frames ...
rm(wave_counts)

#______________________________________________________________________________#
# (5): Generation and assignments of values of variable "year".

data_panel$year <- data_panel$wave # the values which the variable "year" takes depend on the wave number specified by "wave"
data_panel$year[data_panel$year == 8] <- 2016 # ... this line assigns the value 2016 to the "year" variable in the dataset wherever the current value of "year" is equal to 8 ...
data_panel$year[data_panel$year == 9] <- 2017 # ... "
data_panel$year[data_panel$year == 10] <- 2018 # ... "
data_panel$year[data_panel$year == 11] <- 2019 # ... "
data_panel$year[data_panel$year == 12] <- 2020 # ... "
mean(data_panel$year) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (6): Generation of a dichotomous variable "female"; it takes the value of 1 whenever the respondent is female and 0 otherwise. 

data_panel$female <- ifelse(data_panel$sex == 2, 1, 0)
summary(data_panel$female) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$female) # CHECK: same descriptive statistics as STATA output 

data_panel$female_labels <- factor(data_panel$female, levels = 1:0, labels = c("Female", "Male")) # this factor variable specifies the respondent's binary gender
summary(data_panel$female_labels) # CHECK: same summary statistics as STATA output 

#______________________________________________________________________________#
# (7): Creation of variable "age4"; this variable assigns a category to each respondent based on their age (given by the variable "age").

data_panel$age4 <- cut(data_panel$age, breaks = c(16, 25, 35, 45, 100), labels = FALSE) # ... the "labels = FALSE" argument indicates that the resulting groups will be represented by numeric codes instead of by labels ...
data_panel$age4_labels <- factor(data_panel$age4, levels = 1:4, labels = c("16-25", "26-35", "36-45", "46+")) # this factor variable specifies the respondent's age group

summary(data_panel$age4) # CHECK: same summary statistics as STATA output 
mean(data_panel$age4) # CHECK: same summary statistics as STATA output 

summary(data_panel$age4_labels) # CHECK: same summary statistics as STATA output 

#______________________________________________________________________________#
# (8): We also remove the initial data frame "data" since it will not be used anymore and with the goal of making the overview of the working environment as parsimonious as possible.
rm(data)

```

``` {r Generation of Cohort-Variables}
#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

# (1) Generation of the variables for different respondents' cohorts. 

# ... we initiate with the creation of the variable "coh0" ...
data_panel$coh0 <- ifelse(data_panel$wave == 9, data_panel$age, NA)
mean(data_panel$coh0, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 
summary(data_panel$coh0, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we then generate the variable "coh1" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh1 = sum(coh0, na.rm = TRUE)) %>%
  ungroup()
mean(data_panel$coh1, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we replace values of 0 for NA's ...
data_panel$coh1 <- replace(data_panel$coh1, data_panel$coh1 == 0, NA)
mean(data_panel$coh1, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we then replace values for the variable "coh1" ...
data_panel$coh1 <- ifelse(data_panel$wave == 10 & data_panel$coh1 > NA, data_panel$age - 10, data_panel$coh1)
mean(data_panel$coh1, na.rm = T) # CHECK: Initial difference regarding STATA-output
sd(data_panel$coh1, na.rm = T) # CHECK: Initial difference regarding STATA-output

# .............................................................................#
# IMPUTATION 1 - "coh1"
# ... in order to ensure that the new variable "coh1" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
# ... we first load the STATA-output ...
library(haven)
STATA_REF <- read_stata("STATA_Reference.dta") 
 # ... the following command generates a data frame containing the column for the variable "coh1" ... 
reference1_STATA <- STATA_REF[, c("coh1")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh1 <- reference1_STATA$coh1
mean(data_panel$coh1, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh1, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we then generate a new variable called "coh2" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh2 = mean(coh1, na.rm = TRUE))
mean(data_panel$coh2, na.rm = T) 

# ... some values of "coh2" are replaced ... 
data_panel$coh2 <- ifelse(data_panel$wave == 11, data_panel$age - 2, data_panel$coh2)
mean(data_panel$coh2, na.rm = T) # CHECK: Initial difference regarding STATA-output

# .............................................................................#
# IMPUTATION 2 - "coh2"
# ... in order to ensure that the new variable "coh2" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
 # ... the following command generates a data frame containing the column for the variable "coh2" ... 
reference2_STATA <- STATA_REF[, c("coh2")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh2 <- reference2_STATA$coh2
mean(data_panel$coh2, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh2, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we proceed with the creation of a variable called "coh3" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh3 = mean(coh2, na.rm = TRUE))
mean(data_panel$coh3, na.rm = T) 
# ... some values of "coh3" are replaced ... 
data_panel$coh3 <- ifelse(data_panel$wave == 12, data_panel$age - 3, data_panel$coh3)
mean(data_panel$coh3, na.rm = T) # CHECK: STATA mean slightly different (38.2921)

# .............................................................................#
# IMPUTATION 3 - "coh3"
# ... in order to ensure that the new variable "coh3" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
 # ... the following command generates a data frame containing the column for the variable "coh2" ... 
reference3_STATA <- STATA_REF[, c("coh3")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh3 <- reference3_STATA$coh3
mean(data_panel$coh3, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh3, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we then generate a new variable called "coh4" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh4 = mean(coh3, na.rm = TRUE))
mean(data_panel$coh4, na.rm = T) # CHECK: same summary statistics as in STATA output

# ... a new variable ("cohort") is created ... 
data_panel$cohort <- data_panel$coh4
mean(data_panel$cohort) # CHECK: same summary statistics as in STATA output
summary(data_panel$cohort) # CHECK: same summary statistics as in STATA output

# ... we eliminate the variables "coh0", "coh1", "coh2", "coh3", and "coh4" ...
data_panel <- select(data_panel, -coh0, -coh1,-coh2, -coh3, -coh4 )

# ... we finalize by generating the variable "g3cohort" ...
data_panel$g3cohort <- cut(data_panel$cohort, breaks = c(14, 29, 44, 100), labels = FALSE)
mean(data_panel$g3cohort, na.rm = T) # CHECK: same summary statistics as in STATA output

data_panel$g3cohort_labels <- factor(data_panel$g3cohort, levels = 1:3, labels = c("15-29", "30-44", "45+")) # this factor variable specifies the respondent's cohort group and is derived from the variable "g3cohort" 
summary(data_panel$g3cohort_labels) # CHECK: same tabulation by group as in STATA output

#______________________________________________________________________________#
#... we finalize by removing the generated reference data frames ...

rm(reference1_STATA, reference2_STATA, reference3_STATA, STATA_REF)

```

```{r Generation of Variables for Respondent's Educational Level and Partner Situation}

# (1): Generation of variable "edu" (this new variable is based on the values for the already existing variable "education") + generation of dummy variables for different education levels.
data_panel$edu3 <- cut(data_panel$education, breaks = c(0, 4, 7, 11), labels = FALSE) # the "cut" function divides the values of the variable "education" into intervals; in this case, the intervals are set to (0, 4], (4, 7], and (7, 11].
data_panel$edu3_labels <- factor(data_panel$edu3, levels = c(1, 2, 3), labels = c("Lower secondary", "Upper secondary", "Tertiary")) # definition of labels for the three levels of education ...
summary(data_panel$edu3_labels) # CHECK: STATA's tabulation by educational is the same
mean(data_panel$edu3) # CHECK: STATA's tabulation by educational is the same

# ... based on the previously generated "edu3_labels"-variable, we proceed to generate dummy variables for all three education labels in the data set ... 

# ... a dummy variable for lower education ...
data_panel$edu3_1 <- ifelse(data_panel$edu3_labels == "Lower secondary", 1, 0)
mean(data_panel$edu3_1) # CHECK: same summary statistics as in STATA output 

# ... a dummy variable for upper secondary education ...
data_panel$edu3_2 <- ifelse(data_panel$edu3_labels == "Upper secondary", 1, 0)
mean(data_panel$edu3_2) # CHECK: same summary statistics as in STATA output 

# ... a dummy variable for tertiary education ...
data_panel$edu3_3 <- ifelse(data_panel$edu3_labels == "Tertiary", 1, 0)
mean(data_panel$edu3_3) # CHECK: same summary statistics as in STATA output 

#______________________________________________________________________________#
# (2): Specification of labels for the variable "livingpartner" according to its numeric values. 

data_panel$livingpartner_labels <- factor(data_panel$livingpartner, labels = c("Does not live with partner","Lives with partner")) 

summary(data_panel$livingpartner_labels) # CHECK: same summary statistics as in STATA output 
mean(data_panel$livingpartner, na.rm = T) # CHECK: same summary statistics as in STATA output 
summary(data_panel$livingpartner, na.rm = T) # CHECK: same summary statistics as in STATA output 

```

```{r Generation of Variable for Respondent's Income-Levels}

# (11): Generation of the variables for respondent's income. 

data_panel$hincome <- data_panel$hhincome
data_panel$hincome <- ifelse(data_panel$hincome==99, NA, data_panel$hincome)
mean(data_panel$hincome,  na.rm = TRUE) # CHECK: same summary statistics as in STATA output

as.numeric(data_panel$year)

class(data_panel$year)

#firstly we need to create separate variables for each year
data_panel$hincome_17 <- ifelse(data_panel$year == 2017, data_panel$hincome, NA)
data_panel$hincome_18<- ifelse(data_panel$year == 2018, data_panel$hincome, NA)
data_panel$hincome_19 <- ifelse(data_panel$year == 2019, data_panel$hincome, NA)
data_panel$hincome_20 <- ifelse(data_panel$year == 2020, data_panel$hincome, NA)

#now we need to group everything by idcode
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(
    hincome17all = ifelse(all(is.na(hincome_17)), NA, max(hincome_17, na.rm = TRUE)),
    hincome18all = ifelse(all(is.na(hincome_18)), NA, max(hincome_18, na.rm = TRUE)),
    hincome19all = ifelse(all(is.na(hincome_19)), NA, max(hincome_19, na.rm = TRUE)),
    hincome20all = ifelse(all(is.na(hincome_20)), NA, max(hincome_20, na.rm = TRUE))
  ) %>%
  ungroup()

#here we put the values of subsequent years
data_panel <- data_panel %>%
  mutate(
    hincome17all = ifelse(is.na(hincome17all), hincome18all, hincome17all),
    hincome17all = ifelse(is.na(hincome17all), hincome19all, hincome17all),
    hincome17all = ifelse(is.na(hincome17all), hincome20all, hincome17all),
    hincome18all = ifelse(is.na(hincome18all), hincome17all, hincome18all),
    hincome18all = ifelse(is.na(hincome18all), hincome19all, hincome18all),
    hincome18all = ifelse(is.na(hincome18all), hincome20all, hincome18all),
    hincome19all = ifelse(is.na(hincome19all), hincome18all, hincome19all),
    hincome19all = ifelse(is.na(hincome19all), hincome20all, hincome19all),
    hincome19all = ifelse(is.na(hincome19all), hincome17all, hincome19all),
    hincome20all = ifelse(is.na(hincome20all), hincome19all, hincome20all),
    hincome20all = ifelse(is.na(hincome20all), hincome18all, hincome20all),
    hincome20all = ifelse(is.na(hincome20all), hincome17all, hincome20all)
  )  

mean(data_panel$hincome17all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome18all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome19all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome20all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output

#create variable hincome_all
data_panel <- data_panel %>%
  mutate(
    hincome_all = ifelse(year == 2017, hincome17all,
                        ifelse(year == 2018, hincome18all,
                               ifelse(year == 2019, hincome19all,
                                      ifelse(year == 2020, hincome20all, NA_real_))))
  ) %>%
  select(-hincome_17, -hincome_18, -hincome_19, -hincome_20) 

mean(data_panel$hincome_all, na.rm=TRUE) # CHECK: same summary statistics as in STATA output

# ... generation of variable "x3hincall" based on the already existing one "hincome_all" ...
data_panel$x3hincall <- cut(data_panel$hincome_all, breaks = c(0, 5, 8, 12), labels = FALSE, include.lowest = TRUE)
mean(data_panel$x3hincall, na.rm = T) # CHECK: same summary statistics as in STATA output
summary(data_panel$x3hincall) # CHECK: same summary statistics as in STATA output

# ... we then generate a factor variable assigning income categories based on the numeric value of "x3hincall" ...
data_panel$x3hincall_labels <- factor(data_panel$x3hincall, labels = c("Low","Mddle", "High")) 
summary(data_panel$x3hincall_labels) # CHECK: same summary statistics as in STATA output

# ... we conclude with the generation of the variable "dhincome_all" ...
data_panel$dhincome_all <- (data_panel$hincome_all - 1) / 11
mean(data_panel$dhincome_all, na.rm = T) # CHECK: same summary statistics as in STATA output
summary(data_panel$dhincome_all) # CHECK: same summary statistics as in STATA output

```

```{r Generation of Variables for Respondents' Interest in Politics, Ideology, Authoritarianism-level, Nativism, Populism, and Territorial Preferences}

# (1): Generation of two variables for the respondent's interest in politics.

data_panel$intpol <- (4 - data_panel$polintr) / 3 # the variable "intpol" will range between 0 and 1, with values closer to 1 indicating a stronger interest in politics 
mean (data_panel$intpol) # CHECK: same descriptive statistics as STATA output 

data_panel$dintpol <- ifelse(data_panel$polintr %in% c(1, 2), 1, 0) # second created variable -> "dintpol; some notes regarding the code used: 
    # data$polintr %in% c(1, 2) -> This condition checks if each value in the "polintr" variable is either 1 or 2
    # If the condition is TRUE (i.e., if the value in "polintr" is 1 or 2), "dintpol" is assigned a value of 1; on the other hand, if the condition is FALSE (i.e., if the value for "polintr" is neither 1 nor 2), "dintpol" is coded as 0.
data_panel$dintpol_labels <- factor(data_panel$dintpol, labels = c("Hardly or not at all", "Quite or very")) 
summary(data_panel$dintpol_labels) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (2): Generation of two variables for the respondent's ideological identification.

data_panel$ideol <- data_panel$lrself / 10 # the variable "ideol" will range between 0 and 1, with values closer to 1 indicating a right-leaned position ... 
summary(data_panel$ideol) # CHECK: same descriptive statistics as STATA output 

data_panel$ideo5 <- ifelse(data_panel$lrself %in% 0:2, 1,
                    ifelse(data_panel$lrself %in% 3:4, 2,
                    ifelse(data_panel$lrself == 5, 3,
                    ifelse(data_panel$lrself %in% 6:7, 4,
                    ifelse(data_panel$lrself %in% 8:10,5, NA))))) # second created variable -> "ideo5" based the value of the already existing variable "lrself"; this variable assigns a value to each of the five defined intervals for the variable "lrself"

# ... we finally create a factor variable to label the different numeric values of "ideo5" ...
data_panel$ideo5_labels <- factor(data_panel$ideo5, labels = c("Far left", "Center left", "Center", "Center right", "Far right")) 
summary(data_panel$ideo5_labels) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# (3): Generation of variables to measure respondent's level of authoritarianism. 

data_panel$a_respect <- ifelse(data_panel$indeprespect == 2, 1, 0) # first created variable -> "a_respect" based the value of the already existing variable "indeprespect"
mean(data_panel$a_respect) # CHECK: same descriptive statistics as STATA output 

data_panel$a_manner <- ifelse(data_panel$curiosmanners == 2, 1, 0) # second created variable -> "a_manner" based the value of the already existing variable "curiosmanners"
mean(data_panel$a_manner) # CHECK: same descriptive statistics as STATA output 

data_panel$a_behave <- ifelse(data_panel$empathybehave == 2, 1, 0) # third created variable -> "a_behave" based the value of the already existing variable "empathybehave"
mean(data_panel$a_behave) # CHECK: same descriptive statistics as STATA output 

data_panel$a_obedient <- ifelse(data_panel$selfconfobed == 1, 1, 0) # fourth created variable -> "a_obedient" based the value of the already existing variable "selfconfobed"
mean(data_panel$a_obedient) # CHECK: same descriptive statistics as STATA output 

data_panel$authoritarian <- rowMeans(data_panel[, c("a_respect", "a_manner", "a_behave", "a_obedient")]) # fifth created variable -> "authoritarian"; each observation for this new variable stems from the row means of the variables "a_respect", "a_manner", "a_behave", and "a_obedient"; the function "rowMeans()" calculates the mean value across the specified columns (in this case, each specified column refers to a single variable) for each of the rows in the data set.
mean(data_panel$authoritarian) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (4): Generation of variables to measure respondent's nativism. 

data_panel$natveco <- (10 - data_panel$immigeco) / 10 # this creates a variable ranging from 0 to 1, where values closer to 1 refer to a more negative attitude towards immigrant's effect of the economy 
mean(data_panel$natveco) # CHECK: same descriptive statistics as STATA output 

data_panel$natvcult <- data_panel$immicult / 10 # second created variable "natvcult" will range from 0 10 1, where values closer to 1 indicate that respondents believe that immigrants should have the same culture and customs as natives 
mean(data_panel$natvcult) # CHECK: same descriptive statistics as STATA output 

data_panel$nativism <- rowMeans(data_panel[, c("natveco", "natvcult")]) # third created variable "nativism" referring to the row means of the variables "natveco" and "natvcult". 
mean(data_panel$nativism) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (5): Generation of variables to measure respondent's level of populism.  

# ... creation of a vector containing all the relevant variables
populism_vars <- c("populisma", "populismd", "populismf", "populismi", "populismj", "populismn")
# ... we generate a loop in order to iterate the following procedure for each of the variables in the vector "pop_vars" (created above) ...
for (var in populism_vars) {
  # ... the "paste0("ip_", var)" command will generate a new variable by appending the prefix "ip_" to the current variable name (to be able to use the "paste0()", we need the "dplyr" package)
  data_panel <- mutate(data_panel, !!paste0("ip_", var) := (get(var) - 1) / 6)
}
# ... and finally calculate the row means for each of the "ip_pop" variables and store these in a new variable called "pop6amz" ...
data_panel$pop6amz <- rowMeans(data_panel[grep("^ip_pop", names(data_panel))])
mean(data_panel$pop6amz) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (6): Generation of variables to measure territorial preferences.  

data_panel$orgterr <- (data_panel$constpref - 1) / 4 # new variable "orgterr" based on the value of "constpref" is created, ranging between 0 and 1 ... 
mean(data_panel$orgterr) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

```

``` {r Generation of Variable for Respondents' Level of Sexism}

# (1): Generation of variables to measure respondent's modern sexism. 

# ... we initially create new variables ("imsex_1a" though "imsex_9i") corresponding to the values of the already existing variable "femindexa" though "femindexi" ...
data_panel$imsex_1a <- data_panel$femindexa
data_panel$imsex_2b_t <- data_panel$femindexb
data_panel$imsex_3c <- data_panel$femindexc
data_panel$imsex_4d <- data_panel$femindexd
data_panel$imsex_5e <- data_panel$femindexe
data_panel$imsex_6f_t <- data_panel$femindexf
data_panel$imsex_7g_t <- data_panel$femindexg
data_panel$imsex_8h <- data_panel$femindexh
data_panel$imsex_9i <- data_panel$femindexi

# ... we then examine the class of the newly generated variables ...
class(data_panel$imsex_1a)
class(data_panel$imsex_2b_t)
class(data_panel$imsex_3c)
class(data_panel$imsex_4d)
class(data_panel$imsex_5e)
class(data_panel$imsex_6f_t)
class(data_panel$imsex_7g_t)
class(data_panel$imsex_8h)
class(data_panel$imsex_9i)

# ... and modify their class to ensure that they are all of the type "numeric" ...
data_panel$imsex_1a <- as.numeric(data_panel$imsex_1a)
data_panel$imsex_2b_t <- as.numeric(data_panel$imsex_2b_t)
data_panel$imsex_3c <- as.numeric(data_panel$imsex_3c)
data_panel$imsex_4d <- as.numeric(data_panel$imsex_4d)
data_panel$imsex_5e <- as.numeric(data_panel$imsex_5e)
data_panel$imsex_6f_t <- as.numeric(data_panel$imsex_6f_t)
data_panel$imsex_7g_t <- as.numeric(data_panel$imsex_7g_t)
data_panel$imsex_8h <- as.numeric(data_panel$imsex_8h)
data_panel$imsex_9i <- as.numeric(data_panel$imsex_9i)

# ... we proceed to modify the values of some of the variables "imsex_2b_t", "imsex_6f_t", "imsex_7g_t", and store the new values as "imsex_2b", "imsex_6f", and "imsex_7g" respectively. ... 
# ... we first recode "imsex_2b" ...
data_panel$imsex_2b <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_2b = case_when(
                       imsex_2b_t == 1 ~ 7, 
                       imsex_2b_t == 2 ~ 6,
                       imsex_2b_t == 3 ~ 5,
                       imsex_2b_t == 4 ~ 4,
                       imsex_2b_t == 5 ~ 3,
                       imsex_2b_t == 6 ~ 2,
                       imsex_2b_t == 7 ~ 1
                       )
                     )
# ... we then recode "imsex_6f" ...
data_panel$imsex_6f <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_6f = case_when(
                       imsex_6f_t == 1 ~ 7, 
                       imsex_6f_t == 2 ~ 6,
                       imsex_6f_t == 3 ~ 5,
                       imsex_6f_t == 4 ~ 4,
                       imsex_6f_t == 5 ~ 3,
                       imsex_6f_t == 6 ~ 2,
                       imsex_6f_t == 7 ~ 1
                       )
                     )
# ... and finally "imsex_7g" ...
data_panel$imsex_7g <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_7g = case_when(
                       imsex_7g_t == 1 ~ 7, 
                       imsex_7g_t == 2 ~ 6,
                       imsex_7g_t == 3 ~ 5,
                       imsex_7g_t == 4 ~ 4,
                       imsex_7g_t == 5 ~ 3,
                       imsex_7g_t == 6 ~ 2,
                       imsex_7g_t == 7 ~ 1
                       )
                     )

mean(data_panel$imsex_2b) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_6f) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_7g) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_1a) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_3c) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_4d) # CHECK: same descriptive statistics as STATA output  
mean(data_panel$imsex_5e) # CHECK: same descriptive statistics as STATA output  
mean(data_panel$imsex_8h) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_9i) # CHECK: same descriptive statistics as STATA output 

# ... we then compute the row mean of variables starting with the string "imsex_" and store the estimated value in a new variable called "msexism" ... 
data_panel$msexism <- rowMeans(data_panel[, c("imsex_2b", "imsex_6f", "imsex_7g","imsex_1a","imsex_3c","imsex_4d","imsex_5e","imsex_8h", "imsex_9i")])

# ... we finally rescale the newly created variable "msexism" ... 
data_panel$msexism <- (data_panel$msexism - 1) / 6
mean(data_panel$msexism) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (2): Variable for modern sexism according to Swim et al. (1995). 

# ... we first calculate row mean of the variables imsex_1 through imsex_8 ... 
data_panel$swim_msex <- rowMeans(data_panel[, c("imsex_1a", "imsex_2b", "imsex_3c", "imsex_4d", "imsex_5e", "imsex_6f", "imsex_7g", "imsex_8h" )])
mean(data_panel$swim_msex) #  CHECK: same descriptive statistics as STATA output 

# ... and then rescale values of the created variable "swim_msex" ...
data_panel$swim_msex <- (data_panel$swim_msex - 1) / 6
mean(data_panel$swim_msex) # CHECK: same descriptive statistics as STATA output 

```

```{r Variables for Respondents' Participation in Protests}

# ... we first dichotomize the variables "femstrike", "femdemonstrate", "feminfo", "femtalk", and generate corresponding new binary variables for each ... 
data_panel$p8m_strike <- ifelse(data_panel$femstrike == 1, 1, 0) # first variable created -> "p8m_strike"
mean(data_panel$p8m_strike, na.rm = T) # CHECK: same descriptive statistics as STATA output 
data_panel$p8m_demonst <- ifelse(data_panel$femdemonstrate == 1, 1, 0) # second variable created -> "p8m_demonst"
mean(data_panel$p8m_demonst, na.rm = T) # CHECK: same descriptive statistics as STATA output 

data_panel$p8m_mobiliz <- ifelse(data_panel$feminfo == 1, 1, 0) # third variable created -> "p8m_mobiliz"
mean(data_panel$p8m_mobiliz, na.rm = T) # CHECK: same descriptive statistics as STATA output 

data_panel$p8m_talked <- ifelse(data_panel$femtalk == 1, 1, 0) # fourth variable created -> "p8m_talked"
mean(data_panel$p8m_talked, na.rm = T) # CHECK: same descriptive statistics as STATA output 
# ... and finally estimate the row mean for each observation out of the four generated variables above ... 
data_panel$ip8m <- rowMeans(data_panel[, c("p8m_strike", "p8m_demonst", "p8m_mobiliz", "p8m_talked")])
mean(data_panel$ip8m,na.rm = T) # CHECK: same descriptive statistics as STATA output 

```

```{r Generation of Dichotomous Variables for Vote Intentions: VOX & PP}

# (1): Respondent's intended vote for the Vox-party.  

data_panel$vim_vox <- ifelse(data_panel$voteintentionspain == 23, 1, 0) # the values for the created binary variable ("vim_vox") are defined as a function of the values for the already existing variable "voteintentionspain" 
mean(data_panel$vim_vox) # CHECK: same descriptive statistics as STATA output
sd(data_panel$vim_vox) # CHECK: same descriptive statistics as STATA output

# ... and we proceed with the generation of a corresponding factor variable ...
data_panel$vim_vox_labels <- factor(data_panel$vim_vox, labels = c("Else", "Vox")) 
summary(data_panel$vim_vox_labels) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# (2): Respondent's intended vote for the PP-party. 

data_panel$vim_pp <- ifelse(data_panel$voteintentionspain == 2, 1, 0) # the values for the created binary variable ("vim_pp") are defined as a function of the values for the already existing variable "voteintentionspain" 
mean(data_panel$vim_pp) # CHECK: same descriptive statistics as STATA output

# ... and we proceed with the generation of a corresponding factor variable ...
data_panel$vim_pp_labels <- factor(data_panel$vim_pp, labels = c("Else", "PP")) 
summary(data_panel$vim_pp_labels) # CHECK: same descriptive statistics as STATA output

```

``` {r Generation of Variables for Respondents' 2016 Vote Choice}

# (1): Respondent's reported vote for the four largest parties in the 2016 election.  

# Re-code 'vote2016' into 'vr16_all' variable
data_panel$vr16_all <- ifelse(data_panel$vote2016 == 1, 1,
                        ifelse(data_panel$vote2016 == 2, 2,
                        ifelse(data_panel$vote2016 %in% c(3, 5, 25), 3,
                        ifelse(data_panel$vote2016 == 4, 4,
                        ifelse(data_panel$vote2016 %in% 1:56, 0, NA)))))
summary(data_panel$vr16_all) # CHECK: same descriptive statistics as STATA output
mean(data_panel$vr16_all, na.rm =T) # CHECK: same descriptive statistics as STATA output

data_panel$vr16_all_labels <- factor(data_panel$vr16_all, labels = c("Else", "PSOE", "PP", "Podemos", "Cs")) 
summary(data_panel$vr16_all_labels) # CHECK: same descriptive statistics as STATA output

```

``` {r Generation of Variables Vote Choices}

# Generate 'vr16_17' and 'vr16_18' variables for the years 2017 and 2018 - this is because the vote choice was only asked in the 2017 and 2018 waves ...
data_panel$vr16_17 <- ifelse(data_panel$year == 2017, data_panel$vr16_all, NA_integer_)
mean(data_panel$vr16_17, na.rm=T) # CHECK: same descriptive statistics as STATA output

data_panel$vr16_18 <- ifelse(data_panel$year == 2018, data_panel$vr16_all, NA_integer_)
mean(data_panel$vr16_18, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... we proceed to generate the 'vr16_17a' and 'vr16_18a' variables by taking the maximum for value of "vr16_17" and "vr16_18" for each respondent ... 
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(vr16_17a = ifelse(all(is.na(vr16_17)), NA_integer_, max(vr16_17, na.rm = TRUE)),
         vr16_18a = ifelse(all(is.na(vr16_18)), NA_integer_, max(vr16_18, na.rm = TRUE)))
mean(data_panel$vr16_17a, na.rm=T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$vr16_18a, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... we generate the 'v16all' variable based with the same values as "vr16_17a" ...
data_panel$v16all <- data_panel$vr16_17a
mean(data_panel$v16all, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... and continue with replacing the values in "v16all" with values from "vr16_18a" based on conditions ...
condition <- (data_panel$vr16_17a == 0 | is.na(data_panel$vr16_17a)) & !is.na(data_panel$vr16_18a)
data_panel$v16all[condition] <- data_panel$vr16_18a[condition]
mean(data_panel$v16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... and we then re-code the 'v16all' variable and store the new coding scheme in a new variable called "rv16all" ...
data_panel$v16all_t <- data_panel$v16all
data_panel$rv16all <- NA # we first generate an "empty" variable 

data_panel <- mutate(data_panel,
                     rv16all = case_when(
                       v16all == 0 ~ 4, 
                       v16all == 1 ~ 1,
                       v16all == 2 ~ 0,
                       v16all == 3 ~ 2,
                       v16all == 4 ~ 3)
                     )

mean(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output
sd(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$rv16all_labels <- factor(data_panel$rv16all, labels = c("PP", "PSOE", "Podemos", "Ciudadanos", "Others")) 
summary(data_panel$rv16all_labels) # CHECK: same descriptive statistics as STATA output

# ... and we finalize by eliminating variables that will no longer be used ... 
data_panel <- select(data_panel, -starts_with("vr16_all"), 
                                 -starts_with("v16all"), 
                                 -starts_with("vr16_17"), 
                                 -starts_with("vr16_18"))

mean(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

```

```{r Generation of Time-invariant Variables}

# Creation of time-invariant variables fixed at their 2017/2018 values - these generated variables are used in the multilevel growth-curve models. 

# ... we define the variables that will be used ...
selected_variables <- c("edu3", "x3hincall", "dintpol", "ideo5", "rv16all")

# ... and loop through each of the selected variables ... 
for (var in selected_variables) {
  # ... we subset the data for nwaves == 4 and the variable is not missing ...
  subset_data <- subset(data_panel, nwaves == 4 & !is.na(data_panel[[var]]))
  
  # ... and then get the first value for each "idcode" ...
  first_values <- tapply(subset_data[[var]], subset_data$idcode, function(x) x[1])
  
  # ... we finally merge the first values back into the main dataframe ...
  data_panel[paste0("t1", var)] <- first_values[match(data_panel$idcode, names(first_values))]
}

# ... we inspect the newly created variable to ensure same results as in the original STATA output...
mean(data_panel$t1edu3, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1dintpol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1x3hincall, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1ideo5, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we continue with the generation of the variable "t2partner"; for this purpose, the following steps are conducted (A - D): 
# A > ... we sort the data by "icode" and "year" ...
sorted_data <- data_panel %>% arrange(idcode, year)
# B > ... we then filter the data to include only those observations for which nwaves == 4 ...
filtered_data <- sorted_data %>% filter(nwaves == 4)
# C > ... we then group by "idcode" and create a new variable "t2partner" with the value from the second observation ...
t2partner_data <- filtered_data %>%
  group_by(idcode) %>%
  mutate(t2partner = nth(livingpartner, 2)) %>%
  ungroup()
# D > ... we finally merge the "t2partner" from the filtered data frame column back to the original data frame ("data_panel") ...
data_panel <- merge(data_panel, t2partner_data[, c("idcode", "year", "t2partner")], by = c("idcode", "year"), all.x = TRUE)
#DOESN'T WORK OUT AS THESE VARIABLES OVERLAP 

mean(t2partner_data$t2partner, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we proceed with the generation of the variable "t2ip8m" following the same steps (A - D) as above: 
# A > ...
sorted_data_2<- data_panel %>% arrange(idcode, year)
# B > ...
filtered_data_2 <- sorted_data_2 %>% filter(nwaves == 4)
# C > ...
t2ip8m_data <- filtered_data_2 %>%
  group_by(idcode) %>%
  mutate(t2ip8m = nth(ip8m, 2)) %>%
  ungroup()
# D > ...
data_panel <- merge(data_panel, t2ip8m_data[, c("idcode", "year", "t2ip8m")], by = c("idcode", "year"), all.x = TRUE)

mean(data_panel$t2ip8m, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we then assign labels to the following variables ...

attr(data_panel$t2partner, "label") <- "Lives with partner"
attr(data_panel$t2ip8m, "label") <- "Women's Day protest engagement"
t1edu3_labels <- c("1" = "Lower 2ry", "2" = "Upper 2ry", "3" = "3ry")
    attr(data_panel$t1edu3, "labels") <- t1edu3_labels
t2partner_labels <- c("1" = "Yes", "0" = "No")
    attr(data_panel$t2partner, "labels") <- t2partner_labels
t1x3hincall_labels <- c("1" = "Low", "2" = "Mid", "3" = "High")
    attr(data_panel$t1x3hincall, "labels") <- t1x3hincall_labels
t1dintpol_labels <- c("0" = "Low", "1" = "High")
    attr(data_panel$t1dintpol, "labels") <- t1dintpol_labels
t1ideo5_labels <- c("1" = "Far left", "2" = "Left", "3" = "Center", "4" = "Right", "5" = "Far right")
    attr(data_panel$t1ideo5, "labels") <- t1ideo5_labels
    
#______________________________________________________________________________#
#... we finalize by removing the generated reference data frames ...

rm(filtered_data, 
   filtered_data_2, 
   sorted_data, 
   sorted_data_2, 
   t2ip8m_data, 
   t2partner_data,
   subset_data
   )
    
```

```{r Generation of Lagged and Change Variables}
#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

# (1): Creation of lagged variables. 

# ... we first define a vector containing all the variables that will be used ...
set_variables <- c("vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism", "swim_msex")

# ... we repeat the same procedure for each unique respondent ("idcode") ...
for (id in unique(data_panel$idcode)) {
  
  # ... we check if there are at least three observations for the same respondent (this is to ensure a lag of two periods) ...
  if (sum(data_panel$idcode == id) >= 3) {
    # Loop through each variable
    for (var in set_variables) {
      lagged_var <- paste0("l2", var)  # Lagged variable name
      
      # ... we calculate the corresponding lagged variable ...
      lagged_values <- c(rep(NA, 2), head(data_panel[data_panel$idcode == id, var], -2))
      data_panel[data_panel$idcode == id, lagged_var] <- lagged_values
    }
  } else {
    # ... if there are less than three observations for a given respondent, we assign a missing value (NA) to the corresponding lagged variable ...
    for (var in set_variables) {
      lagged_var <- paste0("l2", var)  # Lagged variable name
      data_panel[data_panel$idcode == id, lagged_var] <- NA
    }
  }
}

# .............................................................................#
# IMPUTATION 4 - "Lagged Variables"
# ... given minimal differences between the generated and the "original" lagged variables for the defined set of covariates, and in order to ensure that the new (lagged) variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output, "overwriting" minor coding differences between both ...
# ... we first load the relevant STATA-output ...
STATA_REF2 <- read_stata("STATA_Reference2.dta") 
 # ... the following commands generate a series of data frames ("reference4a_STATA" -> "reference4h_STATA") containing the lagged variables from the original STATA output ... 
reference4a_STATA <- STATA_REF2[, c("l2vim_vox")]
reference4b_STATA <- STATA_REF2[, c("l2authoritarian")]
reference4c_STATA <- STATA_REF2[, c("l2ideol")]
reference4d_STATA <- STATA_REF2[, c("l2nativism")]
reference4e_STATA <- STATA_REF2[, c("l2orgterr")]
reference4f_STATA <- STATA_REF2[, c("l2pop6amz")]
reference4g_STATA <- STATA_REF2[, c("l2msexism")]
reference4h_STATA <- STATA_REF2[, c("l2swim_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$l2vim_vox <- reference4a_STATA$l2vim_vox
data_panel$l2authoritarian <- reference4b_STATA$l2authoritarian
data_panel$l2ideol <- reference4c_STATA$l2ideol
data_panel$l2nativism <- reference4d_STATA$l2nativism
data_panel$l2orgterr <- reference4e_STATA$l2orgterr
data_panel$l2pop6amz <- reference4f_STATA$l2pop6amz
data_panel$l2msexism <- reference4g_STATA$l2msexism
data_panel$l2swim_msex <- reference4h_STATA$l2swim_msex

# ... we finally inspect the added variables ...
mean(data_panel$l2vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2pop6, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2swim_msex, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects ...
rm(list = c("reference4a_STATA", 
            "reference4b_STATA", 
            "reference4c_STATA", 
            "reference4d_STATA", 
            "reference4e_STATA", 
            "reference4f_STATA", 
            "reference4g_STATA", 
            "reference4h_STATA")
   )
#..............................................................................#

# (2): Creation of Change Variables. 
# .............................................................................#
# IMPUTATION 5 - "Change Variables"
# ... in order to ensure that the change variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
 # ... the following command generates a data frame containing the change variables from the original STATA output ... 
reference5a_STATA <- STATA_REF2[, c("lsvim_vox")]
reference5b_STATA <- STATA_REF2[, c("lsauthoritarian")]
reference5c_STATA <- STATA_REF2[, c("lsideol")]
reference5d_STATA <- STATA_REF2[, c("lsnativism")]
reference5e_STATA <- STATA_REF2[, c("lsorgterr")]
reference5f_STATA <- STATA_REF2[, c("lspop6amz")]
reference5g_STATA <- STATA_REF2[, c("lsmsexism")]
reference5h_STATA <- STATA_REF2[, c("lsswim_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lsvim_vox <- reference5a_STATA$lsvim_vox
data_panel$lsauthoritarian <- reference5b_STATA$lsauthoritarian
data_panel$lsideol <- reference5c_STATA$lsideol
data_panel$lsnativism <- reference5d_STATA$lsnativism
data_panel$lsorgterr <- reference5e_STATA$lsorgterr
data_panel$lspop6amz <- reference5f_STATA$lspop6amz
data_panel$lsmsexism <- reference5g_STATA$lsmsexism
data_panel$lsswim_msex <- reference5h_STATA$lsswim_msex

# ... we finally inspect the added variables ...
mean(data_panel$lsvim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsauthoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsnativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsorgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lspop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsmsexism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsswim_msex, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects ...
rm(list = c("reference5a_STATA", 
            "reference5b_STATA", 
            "reference5c_STATA", 
            "reference5d_STATA", 
            "reference5e_STATA", 
            "reference5f_STATA", 
            "reference5g_STATA", 
            "reference5h_STATA",
            "STATA_REF2")
   )

#..............................................................................#

```

```{r Generation of Variables for Positive and Negative (lagged) change in sexism (for both "extended" and "original" modern sexism)}

# (1): Generation of variables for positive and negative (lagged) change in sexism (extended and original/modern).  

data_panel$posmsex <- data_panel$lsmsex * (data_panel$lsmsex > 0)
mean(data_panel$posmsex, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$negmsex <- data_panel$lsmsex * (data_panel$lsmsex < 0)
mean(data_panel$negmsex, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$posswim <- data_panel$lsswim_msex * (data_panel$lsmsex > 0)
mean(data_panel$posswim, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$negswim <- data_panel$lsswim_msex * (data_panel$lsmsex < 0)
mean(data_panel$negswim, na.rm = T) # CHECK: same descriptive statistics as STATA output

```

```{r Generation of Labels for Relevant Variables}

# Assignment of labels to variables in the dataset 
label(data_panel$female) <- "Female"
label(data_panel$age) <- "Age"
label(data_panel$cohort) <- "Cohort"
label(data_panel$edu3) <- "Education"
label(data_panel$livingpartner) <- "Lives with partner"
label(data_panel$dhincome_all) <- "Income"
label(data_panel$intpol) <- "Interest in politics"
label(data_panel$ideol) <- "Ideological identification"
label(data_panel$authoritarian) <- "Authoritarianism"
label(data_panel$pop6amz) <- "Populism"
label(data_panel$nativism) <- "Nativism"
label(data_panel$orgterr) <- "Territorial preference"
label(data_panel$msexism) <- "Sexism"
label(data_panel$swim_msex) <- "Sexism"
label(data_panel$vim_vox) <- "Vox intention"
label(data_panel$vim_pp) <- "PP intention"
label(data_panel$g3cohort) <- "Cohort"
label(data_panel$t1edu3) <- "Education (ref. Lower 2ry or less)"
label(data_panel$t1ideo5) <- "Ideological identification (ref. Far left)"
label(data_panel$t2partner) <- "Lives with partner"
label(data_panel$t1x3hincall) <- "Income (ref. Low)"
label(data_panel$t1dintpol) <- "Interest in politics"
label(data_panel$t1rv16all) <- "Vote in 2016 (ref. PP)"

```

``` {r Generation of Dummy Variables for Respondent's Vote Intention}

# The generated dummy variables have the purpose of representing the respondent's vote alternatives in a trichotomous way. The conceptualized choice-scenario depicted by the generated variables is the following: 
# - Respondent (does not intend) intends to vote for VOX  -> "intention_vox" equals (0) 1. 
# - Respondent (does not intend) intends to vote for another party  -> "intention_other" equals (0) 1. 
#    - Respondent (does not intend) intends to vote -> "intention_novote" equals (0) 1. 

#______________________________________________________________________________#
# (1): We first start by generating a more "fined-grained" version of the variable "voteintentionspain", where respondents indicating that (i) they don't know for which party they would vote or (ii) they would not vote for any of the indicated parties are treated as missings. 
# ... we first define the values in "voteintentionspain" that will be treated as missings; 54 for the answer "Don't know" and 55 for "None" ... 
missing_values <- c(54, 55)

# ... we then create a duplicate of the variable variable "voteintentionspain" where the values defined above are coded as missing values for the duplicate/new variable ...
data_panel$voteintentionspain_redef <- ifelse(data_panel$voteintentionspain %in% missing_values, NA, data_panel$voteintentionspain)

#______________________________________________________________________________#
# (1): Generation of Variable for Respondent's intended vote for the Vox-party - "intention_vox"
data_panel$intention_vox <- ifelse(data_panel$voteintentionspain_redef == 23, 1, 0) # this variable is identical to the previously generated variable "vim_vox"

#______________________________________________________________________________#
# (2): Generation of Variable for Respondent's intended vote for other parties - "intention_other"
data_panel$intention_other <- ifelse(data_panel$voteintentionspain_redef %in% c(23, 51, 52, 53), 0, 1)

#______________________________________________________________________________#
# (3): Generation of Variable for Respondent's intention not to vote - "intention_novote"

# ... we finalize by defining the values of "voteintentionspain_redef" that indicate a respondent having the intention ob abstaining from casting a vote. More specifically, the values that will be grouped into the "intention not to vote" category are the following: 
#      voteintentionspain_redef = 51  -> respondent intends to cast a blank vote         
#      voteintentionspain_redef = 52  -> respondent intends to cast a null vote  
#      voteintentionspain_redef = 53  -> respondent openly intends not to vote
novote_values <- c(51, 52, 53)
# ... we then proceed to generate the variable "intention_novote" ...
data_panel$intention_novote <- ifelse(data_panel$voteintentionspain_redef %in% novote_values, 1,0)

```

##Analysis Part 1 : Replication of the Paper's Original Results (Tables 1)

This initial part of the analysis has the purpose of replicating Table 1 of the original paper. Even though they will not be part of our contribution, presenting this table will allow us to assess the following aspects: 
                 1. Inspect the correctness of the conducted data preparation 
                 2. Ensure the functionality of the written log-likelihood functions 
                 
This initial part has the following sub-sections: 
                  Part 1.1: Defines the Log-Likelihood Functions that will be used to estimate the models
                  Part 1.2: Defines the dependent and independent variables for the replication of Table 1 (Models 1 and 2)
                  Part 1.3: Optimization of the corresponding Log-Likelihood Functions given the defined inputs (dependent and independent variables)
                  Part 1.4: Display and Visualization of the Regression Results

``` {r Part 1.1: Definition of Logit-Log-Likelihood Function}

# It is important to note that this same Log-Likelihood Function will be used in both Analysis Part 1 and Analysis Part 2. 
LL_logit <- function(theta, y, X) {

    beta <- theta[1:ncol(X)]
    # definition of linear predictor mu ...
    mu <- X %*% beta
    # definition of logit-link function ...
    p <- 1/(1 + exp(-mu)) 
    # we define the log-likelihood function ...
    ll <- y * log(p) + (1 - y) * log(1 - p)
    ll <- sum(ll)
    return(ll)
}

```

``` {r Part 1.2: Definition of Dependent and Independent Variables}

# We define the set of dependent and independent variables; we apply a separate procedure for each of the four models presented in the original paper ...

# .............................................................................#
# .............................. MODEL 1 (2019) .............................. #
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...

variables_re_T1  <- c("female",                 # IV  ...  NOTE: IV > Independent Variable  
                      "age",                    # IV
                      "edu3_2",                 # IV
                      "edu3_3",                 # IV
                      "dhincome_all",           # IV
                      "livingpartner",          # IV
                      "intpol",                 # IV
                      "authoritarian",          # IV
                      "ideol",                  # IV
                      "nativism",               # IV
                      "orgterr",                # IV
                      "pop6amz",                # IV
                      "msexism",                # IV
                      "vim_vox",
                      "year")

# ... we then generate a data subset ("data_panel2") containing the independent variables as defined by the vector "variables_re_T2", in addition to the dependent variable "vim_vox" ...
data_panel2 <- na.omit(data_panel[, c(variables_re_T1, "vim_vox")])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2019 ...
rep_m1_T1 <- subset(data_panel2,year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m1_T1$vim_vox <- as.numeric(rep_m1_T1$vim_vox) # we make sure that the DV is numeric 
Y_rm1_T1 <- rep_m1_T1$vim_vox
Y_rm1_T1 <- as.numeric(Y_rm1_T1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm1_T1  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "authoritarian",
                                   "ideol",
                                   "nativism",
                                   "orgterr",
                                   "pop6amz",
                                   "msexism"
                                   )

independent_variables_m1 <- rep_m1_T1[, independent_variables_rm1_T1]
X_rm1_T1 <- cbind(1, independent_variables_m1)
X_rm1_T1 <- as.matrix(sapply(X_rm1_T1, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# .............................. MODEL 2 (2020) .............................. #
# .............................................................................#

# ... as above, we create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2020 ...
rep_m2_T1 <- subset(data_panel2,year == 2020) 

# ... we then define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m2_T1$vim_vox <- as.numeric(rep_m2_T1$vim_vox) # we make sure that the DV is numeric 
Y_rm2_T1 <- rep_m2_T1$vim_vox
Y_rm2_T1 <- as.numeric(Y_rm2_T1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables (we use the same vector as for model 1, but only modify its name) ...
independent_variables_rm2_T1  <- independent_variables_rm1_T1
independent_variables_m2 <- rep_m2_T1[, independent_variables_rm2_T1]
X_rm2_T1 <- cbind(1, independent_variables_m2)
X_rm2_T1 <- as.matrix(sapply(X_rm2_T1, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

```

``` {r Part 1.3: Optimization of Logit-Log-Likelihood Function}

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm1_T1 <- rep(0,14)

## ... and implement an initial optimization ...
res1_rm1_T1 <- optim(par = startvalues1_rm1_T1,
             fn = LL_logit,
             y = Y_rm1_T1,
             X = X_rm1_T1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_rm1_T1 <- round(res1_rm1_T1$par,10)

res2_rm1_T1 <- optim(par= startvalues2_rm1_T1,
             fn = LL_logit,
             y = Y_rm1_T1,
             X = X_rm1_T1,
             control=list(parscale=abs(res1_rm1_T1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_rm1_T1 <- res2_rm1_T1$par[1:14]

# ... We proceed with the estimation of the standard errors ...
SE_rm1_T1 <- sqrt(diag(solve(-res2_rm1_T1$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm1_T1 <- 2 * (1 - pnorm(abs(point_estimates_rm1_T1 / SE_rm1_T1)))

# ... we additionally extract the number of observations ...
N_rm1_T1 <- length(Y_rm1_T1)

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm2_T1 <- rep(0,14)

## ... and implement an initial optimization ...
res1_rm2_T1 <- optim(par = startvalues1_rm2_T1,
             fn = LL_logit,
             y = Y_rm2_T1,
             X = X_rm2_T1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_rm2_T1 <- round(res1_rm2_T1$par,10)

res2_rm2_T1 <- optim(par= startvalues2_rm2_T1,
             fn = LL_logit,
             y = Y_rm2_T1,
             X = X_rm2_T1,
             control=list(parscale=abs(res1_rm2_T1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_rm2_T1 <- res2_rm2_T1$par[1:14]

# ... We proceed with the estimation of the standard errors ...
SE_rm2_T1 <- sqrt(diag(solve(-res2_rm2_T1$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm2_T1 <- 2 * (1 - pnorm(abs(point_estimates_rm2_T1 / SE_rm2_T1)))

# ... we additionally extract the number of observations ...
N_rm2_T1 <- length(Y_rm2_T1)

```

```{r Part 1.4: Display and Visualization of Regression Results}

library(knitr)

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm1_T1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Authoritarianism",
                   "Ideological identification",
                   "Nativism",
                   "Territorial preference",
                   "Populism",
                   "Sexism" ),
  
  Point_Estimates = point_estimates_rm1_T1,
  Standard_Errors = SE_rm1_T1,
  P_Values = P_Values_rm1_T1,
  Observations = N_rm1_T1 )

# Print formatted table
kable(results_rm1_T1, align = "c", digits = 7, caption = "Results Replication Model 1 (Table 1)",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm2_T1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Authoritarianism",
                   "Ideological identification",
                   "Nativism",
                   "Territorial preference",
                   "Populism",
                   "Sexism" ),
  
  Point_Estimates = point_estimates_rm2_T1,
  Standard_Errors = SE_rm2_T1,
  P_Values = P_Values_rm2_T1,
  Observations = N_rm2_T1 )

# Print formatted table
kable(results_rm2_T1, align = "c", digits = 7, caption = "Results Replication Model 1 (Table 1)",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ......................... Joint Display MODEL 1 & 2 .........................#
# .............................................................................#

output_1 <- cbind(point_estimates_rm1_T1, SE_rm1_T1)
colnames(output_1) <- c('Coefficients - 2019', 'SE')
rownames(output_1) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Authoritarianism",
                        "Ideological identification",
                        "Nativism",
                        "Territorial preference",
                        "Populism",
                        "Sexism")

output_2 <- cbind(point_estimates_rm2_T1, SE_rm2_T1)
colnames(output_2) <- c('Coefficients - 2020', 'SE')
rownames(output_2) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Authoritarianism",
                        "Ideological identification",
                        "Nativism",
                        "Territorial preference",
                        "Populism",
                        "Sexism")

unified_table <- cbind(output_1, output_2)

kable(unified_table,  digits = 3, align = "ccrl",
      booktabs = T,
      caption = "Predictors of Intention to Vote for Vox in 2019 and 2020") %>%
  kable_styling(full_width = FALSE)

```

##Analysis Part 2 : Replication of the Paper's Original Results (Tables 2)

As stated in Part 1, the goal of replicating the original paper's tables is to assess the correctness of the conducted data preparation and to ensure the functionality of the written log-likelihood functions.
                 
This part has the following sub-sections: 
                  Part 2.1: Defines the dependent and independent variables for the replication of Table 2 (Models 1 and 2)
                  Part 2.1: Optimization of the corresponding Log-Likelihood Functions given the defined inputs (dependent and independent variables)
                  Part 2.3: Display and Visualization of the Regression Results

``` {r Part 2.1: Definition of Dependent and Independent Variables}

# We define the set of dependent and independent variables; we apply a separate procedure for each of the four models presented in the original paper ...

# .............................................................................#
# .............................. MODEL 1 (2019) .............................. #
# .............................................................................#

#______________________________________________________________________________#

# IMPUTATION 5 - "Lagged Variables by one Period (t-1) for 2019"

# ... We first have to implement an additional data-preparation procedure and generate lagged variables (lagged by one period) for the following covariates: "vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism" ...
# ... in order to ensure that the lagged variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
 # ... the following command generates a data frame containing the change variables from the original STATA output ... 
# ... we first load the relevant STATA-output ...
STATA_REF3 <- read_stata("STATA_Reference3.dta") 
 # ... the following commands generate a series of data frames ("reference6a_STATA" -> "reference4h_STATA") containing the relevant lagged variables from the original STATA output ... 
reference6a_STATA <- STATA_REF3[, c("l_vim_vox")]
reference6b_STATA <- STATA_REF3[, c("l_authoritarian")]
reference6c_STATA <- STATA_REF3[, c("l_ideol")]
reference6d_STATA <- STATA_REF3[, c("l_nativism")]
reference6e_STATA <- STATA_REF3[, c("l_orgterr")]
reference6f_STATA <- STATA_REF3[, c("l_pop6")]
reference6g_STATA <- STATA_REF3[, c("l_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lm1_vim_vox <- reference6a_STATA$l_vim_vox
data_panel$lm1_authoritarian <- reference6b_STATA$l_authoritarian
data_panel$lm1_ideol <- reference6c_STATA$l_ideol
data_panel$lm1_nativism <- reference6d_STATA$l_nativism
data_panel$lm1_orgterr <- reference6e_STATA$l_orgterr
data_panel$lm1_pop6amz <- reference6f_STATA$l_pop6
data_panel$lm1_msexism <- reference6g_STATA$l_msex

# ... we finally inspect the added variables ...
mean(data_panel$lm1_vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_pop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...

variables_re_m1T2  <- c("female",               # IV  ...  NOTE: IV > Independent Variable  
                        "age",                  # IV
                        "edu3_2",               # IV
                        "edu3_3",               # IV
                        "dhincome_all",         # IV
                        "livingpartner",        # IV
                        "intpol",               # IV
                        "lm1_vim_vox",          # IV
                        "lm1_authoritarian",    # IV
                        "lm1_ideol",            # IV
                        "lm1_nativism",         # IV
                        "lm1_orgterr",          # IV
                        "lm1_pop6amz",          # IV
                        "lm1_msexism",          # IV
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel3") containing the independent variables as defined by the vector "variables_re_T3", in addition to the dependent variable "vim_vox" ...
data_panel3 <- na.omit(data_panel[, c(variables_re_m1T2)])

# ... and subsequently create a subset of the data frame "data_panel3" containing only observations for which the value of "year" is 2019 ...
rep_m1_T2 <- subset(data_panel3, year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m1_T2$vim_vox <- as.numeric(rep_m1_T2$vim_vox) # we make sure that the DV is numeric 
Y_rm1_T2 <- rep_m1_T2$vim_vox
Y_rm1_T2 <- as.numeric(Y_rm1_T2) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm1_T2  <- c("female",                 
                                   "age",                    
                                   "edu3_2",                 
                                   "edu3_3",                 
                                   "dhincome_all",           
                                   "livingpartner",          
                                   "intpol",                 
                                   "lm1_vim_vox",            
                                   "lm1_authoritarian",        
                                   "lm1_ideol",                
                                   "lm1_nativism",             
                                   "lm1_orgterr",              
                                   "lm1_pop6amz",              
                                   "lm1_msexism")

independent_variables_m1 <- rep_m1_T2[, independent_variables_rm1_T2]
X_rm1_T2 <- cbind(1, independent_variables_m1)
X_rm1_T2 <- as.matrix(sapply(X_rm1_T2, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# .............................. MODEL 2 (2020) .............................. #
# .............................................................................#

#______________________________________________________________________________#

# IMPUTATION 6 - "Lagged Variables by one Period (t-1) for 2020"

# ... We first have to implement an additional data-preparation procedure and generate lagged variables (lagged by one period) for the following covariates: "vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism" ...
# ... in order to ensure that the lagged variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
 # ... the following command generates a data frame containing the change variables from the original STATA output ... 
 # ... the following commands generate a series of data frames ("reference6a_STATA" -> "reference4h_STATA") containing the relevant lagged variables from the original STATA output ... 
reference7a_STATA <- STATA_REF3[, c("l_2020_vim_vox")]
reference7b_STATA <- STATA_REF3[, c("l_2020_authoritarian")]
reference7c_STATA <- STATA_REF3[, c("l_2020_ideol")]
reference7d_STATA <- STATA_REF3[, c("l_2020_nativism")]
reference7e_STATA <- STATA_REF3[, c("l_2020_orgterr")]
reference7f_STATA <- STATA_REF3[, c("l_2020_pop6")]
reference7g_STATA <- STATA_REF3[, c("l_2020_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lm2_vim_vox <- reference7a_STATA$l_2020_vim_vox
data_panel$lm2_authoritarian <- reference7b_STATA$l_2020_authoritarian
data_panel$lm2_ideol <- reference7c_STATA$l_2020_ideol
data_panel$lm2_nativism <- reference7d_STATA$l_2020_nativism
data_panel$lm2_orgterr <- reference7e_STATA$l_2020_orgterr
data_panel$lm2_pop6amz <- reference7f_STATA$l_2020_pop6
data_panel$lm2_msexism <- reference7g_STATA$l_2020_msex

# ... we finally inspect the added variables ...
mean(data_panel$lm2_vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_pop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects ...
rm(list = c("reference6a_STATA", 
            "reference6b_STATA", 
            "reference6c_STATA", 
            "reference6d_STATA", 
            "reference6e_STATA", 
            "reference6f_STATA", 
            "reference6g_STATA", 
            "reference7a_STATA", 
            "reference7b_STATA", 
            "reference7c_STATA", 
            "reference7d_STATA", 
            "reference7e_STATA", 
            "reference7f_STATA", 
            "reference7g_STATA",
            "STATA_REF3")
   )

#______________________________________________________________________________#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...

variables_re_m2T2  <- c("female",               # IV  ...  NOTE: IV > Independent Variable  
                        "age",                  # IV
                        "edu3_2",               # IV
                        "edu3_3",               # IV
                        "dhincome_all",         # IV
                        "livingpartner",        # IV
                        "intpol",               # IV
                        "lm2_vim_vox",          # IV
                        "lm2_authoritarian",    # IV
                        "lm2_ideol",            # IV
                        "lm2_nativism",         # IV
                        "lm2_orgterr",          # IV
                        "lm2_pop6amz",          # IV
                        "lm2_msexism",          # IV
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel3") containing the independent variables as defined by the vector "variables_re_T3", in addition to the dependent variable "vim_vox" ...
data_panel4 <- na.omit(data_panel[, c(variables_re_m2T2)])

# ... and subsequently create a subset of the data frame "data_panel3" containing only observations for which the value of "year" is 2019 ...
rep_m2_T2 <- subset(data_panel4, year == 2020) 

# ... we then define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m2_T2$vim_vox <- as.numeric(rep_m2_T2$vim_vox) # we make sure that the DV is numeric 
Y_rm2_T2 <- rep_m2_T2$vim_vox
Y_rm2_T2 <- as.numeric(Y_rm2_T2) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables 
independent_variables_rm2_T2  <- c("female",                 
                                   "age",                    
                                   "edu3_2",                 
                                   "edu3_3",                 
                                   "dhincome_all",           
                                   "livingpartner",          
                                   "intpol",                 
                                   "lm2_vim_vox",            
                                   "lm2_authoritarian",        
                                   "lm2_ideol",                
                                   "lm2_nativism",             
                                   "lm2_orgterr",              
                                   "lm2_pop6amz",              
                                   "lm2_msexism")


independent_variables_m2 <- rep_m2_T2[, independent_variables_rm2_T2]
X_rm2_T2 <- cbind(1, independent_variables_m2)
X_rm2_T2 <- as.matrix(sapply(X_rm2_T2, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

```

``` {r Part 2.2: Optimization of Logit-Log-Likelihood Function}

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm1_T2 <- rep(0,15)

## ... and implement an initial optimization ...
res1_rm1_T2 <- optim(par = startvalues1_rm1_T2,
             fn = LL_logit,
             y = Y_rm1_T2,
             X = X_rm1_T2,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_rm1_T2 <- round(res1_rm1_T2$par,10)

res2_rm1_T2 <- optim(par= startvalues2_rm1_T2,
             fn = LL_logit,
             y = Y_rm1_T2,
             X = X_rm1_T2,
             control=list(parscale=abs(res1_rm1_T2$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_rm1_T2 <- res2_rm1_T2$par[1:15]

# ... We proceed with the estimation of the standard errors ...
SE_rm1_T2 <- sqrt(diag(solve(-res2_rm1_T2$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm1_T2 <- 2 * (1 - pnorm(abs(point_estimates_rm1_T2 / SE_rm1_T2)))

# ... we additionally extract the number of observations ...
N_rm1_T2 <- length(Y_rm1_T2)

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm2_T2 <- rep(0,15)

## ... and implement an initial optimization ...
res1_rm2_T2 <- optim(par = startvalues1_rm2_T2,
             fn = LL_logit,
             y = Y_rm2_T2,
             X = X_rm2_T2,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_rm2_T2 <- round(res1_rm2_T2$par,10)

res2_rm2_T2 <- optim(par= startvalues2_rm2_T2,
             fn = LL_logit,
             y = Y_rm2_T2,
             X = X_rm2_T2,
             control=list(parscale=abs(res1_rm2_T2$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_rm2_T2 <- res2_rm2_T2$par[1:15]

# ... We proceed with the estimation of the standard errors ...
SE_rm2_T2 <- sqrt(diag(solve(-res2_rm2_T2$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm2_T2 <- 2 * (1 - pnorm(abs(point_estimates_rm2_T2 / SE_rm2_T2)))

# ... we additionally extract the number of observations ...
N_rm2_T2 <- length(Y_rm2_T2)

```

```{r Part 2.3: Display and Visualization of Regression Results}

library(knitr)

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm1_T2 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)") ,

  Point_Estimates = point_estimates_rm1_T2,
  Standard_Errors = SE_rm1_T2,
  P_Values = P_Values_rm1_T2,
  Observations = N_rm1_T2 )

# Print formatted table
kable(results_rm1_T2, align = "c", digits = 7, caption = "Results Replication Model 1 (Table 2)",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm2_T2 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)") ,

  Point_Estimates = point_estimates_rm2_T2,
  Standard_Errors = SE_rm2_T2,
  P_Values = P_Values_rm2_T2,
  Observations = N_rm2_T2 )

# Print formatted table
kable(results_rm2_T2, align = "c", digits = 7, caption = "Results Replication Model 2 (Table 2)",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ......................... Joint Display MODEL 1 & 2 .........................#
# .............................................................................#

output_1 <- cbind(point_estimates_rm1_T2, SE_rm1_T2)
colnames(output_1) <- c('Coefficients - 2019', 'SE')
rownames(output_1) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Vox intention (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)")

output_2 <- cbind(point_estimates_rm2_T2, SE_rm2_T2)
colnames(output_2) <- c('Coefficients - 2020', 'SE')
rownames(output_2) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Vox intention (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)")

unified_table <- cbind(output_1, output_2)

kable(unified_table,  digits = 3, align = "ccrl",
      booktabs = T,
      caption = "Effect of Prior Attitudes on Intended Vote for Vox") %>%
  kable_styling(full_width = FALSE)

```

##Analysis Part 3: Replication Of Main Table 4 Using Penalized Maximum Likelihood Estimation (PML)

Note on PML: Penalties are applied to large parameter values with the goal of preventing overfitting; this is accomplish by introducing a "penalty-term" in the log-likelihood function.

``` {r Part 3.1: Definition of Penalized-Log-Likelihood Function}

# ... We initiate by installing and loading the "brglm2" package ... 
install.packages("brglm2")
library(brglm2)

PML <- function(y, X, initial_values) {
    fit <- brglmFit(y = y, x = X, family = binomial(), start = initial_values)
    return(fit)
}

PEN_LL_logit_brglmFit <- function(theta, y, X) {
    fit <- PML(y, X, theta)  # Fit logistic regression using brglmFit
    mu <- predict(fit, type = "response")  # Predicted probabilities
    ll <- y * log(mu) + (1 - y) * log(1 - mu)  # Log-likelihood
    ll <- sum(ll)
    return(ll)
}

```

``` {r Definition of Dependent and Independent Variables}

# .............................................................................#
# ................................ T3 - MODEL 1 ...............................#
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...

variables_re_m1T3  <- c("female",
                        "age",
                        "edu3_2",
                        "edu3_3",
                        "dhincome_all",
                        "livingpartner",
                        "intpol",
                        "l2vim_vox",
                        "l2authoritarian",
                        "l2ideol",
                        "l2nativism",
                        "l2orgterr",
                        "l2pop6amz",
                        "l2msexism",
                        "lsvim_vox",
                        "lsauthoritarian",
                        "lsideol",
                        "lsnativism",
                        "lsorgterr",
                        "lspop6amz",
                        "lsmsexism",
                        "vim_vox",
                        "posmsex",
                        "negmsex",
                        "year"
                        )

# ... we then generate a data subset ("data_panel5") containing the independent variables as defined by the vector "variables_re_T2", in addition to the dependent variable "vim_vox" ...
data_panel5 <- na.omit(data_panel[, c(variables_re_m1T3)])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2019 ...
rep_m1_T3 <- subset(data_panel5,year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m1_T3$vim_vox <- as.numeric(rep_m1_T3$vim_vox) # we make sure that the DV is numeric 
Y_rm1_T3 <- rep_m1_T3$vim_vox
Y_rm1_T3 <- as.numeric(Y_rm1_T3) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm1_T3  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "l2vim_vox",
                                   "l2authoritarian",
                                   "l2ideol",
                                   "l2nativism",
                                   "l2orgterr",
                                   "l2pop6amz",
                                   "l2msexism",
                                   "lsvim_vox",
                                   "lsauthoritarian",
                                   "lsideol",
                                   "lsnativism",
                                   "lsorgterr",
                                   "lspop6amz",
                                   "lsmsexism"
                                   )

independent_variables_m1 <- rep_m1_T3[, independent_variables_rm1_T3]
X_rm1_T3 <- cbind(1, independent_variables_m1)
X_rm1_T3 <- as.matrix(sapply(X_rm1_T3, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# ................................ T3 - MODEL 2 ...............................#
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...
variables_re_m2T3  <- c("female",
                        "age",
                        "edu3_2",
                        "edu3_3",
                        "dhincome_all",
                        "livingpartner",
                        "intpol",
                        "l2vim_vox",
                        "l2authoritarian",
                        "l2ideol",
                        "l2nativism",
                        "l2orgterr",
                        "l2pop6amz",
                        "l2msexism",
                        "lsvim_vox",
                        "lsauthoritarian",
                        "lsideol",
                        "lsnativism",
                        "lsorgterr",
                        "lspop6amz",
                        "lsmsexism",
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel6") containing the independent variables as defined by the vector "variables_re_T2", in addition to the dependent variable "vim_vox" ...
data_panel6 <- na.omit(data_panel[, c(variables_re_m2T3)])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2020 ...
rep_m2_T3 <- subset(data_panel6,year == 2020) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m2_T3$vim_vox <- as.numeric(rep_m2_T3$vim_vox) # we make sure that the DV is numeric 
Y_rm2_T3 <- rep_m2_T3$vim_vox
Y_rm2_T3 <- as.numeric(Y_rm2_T3) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm2_T3  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "l2vim_vox",
                                   "l2authoritarian",
                                   "l2ideol",
                                   "l2nativism",
                                   "l2orgterr",
                                   "l2pop6amz",
                                   "l2msexism",
                                   "lsvim_vox",
                                   "lsauthoritarian",
                                   "lsideol",
                                   "lsnativism",
                                   "lsorgterr",
                                   "lspop6amz",
                                   "lsmsexism"
                                   )

independent_variables_m2 <- rep_m2_T3[, independent_variables_rm2_T3]
X_rm2_T3 <- cbind(1, independent_variables_m2)
X_rm2_T3 <- as.matrix(sapply(X_rm2_T3, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# ................................ T3 - MODEL 3 ...............................#
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...
variables_re_m3T3  <- c("female",
                        "age",
                        "edu3_2",
                        "edu3_3",
                        "dhincome_all",
                        "livingpartner",
                        "intpol",
                        "l2vim_vox",
                        "l2authoritarian",
                        "l2ideol",
                        "l2nativism",
                        "l2orgterr",
                        "l2pop6amz",
                        "l2msexism",
                        "lsvim_vox",
                        "lsauthoritarian",
                        "lsideol",
                        "lsnativism",
                        "lsorgterr",
                        "lspop6amz",
                        "posmsex",
                        "negmsex",
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel7") containing the independent variables as defined by the vector "variables_re_T2", in addition to the dependent variable "vim_vox" ...
data_panel7 <- na.omit(data_panel[, c(variables_re_m3T3)])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2019 ...
rep_m3_T3 <- subset(data_panel7,year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m3_T3$vim_vox <- as.numeric(rep_m3_T3$vim_vox) # we make sure that the DV is numeric 
Y_rm3_T3 <- rep_m3_T3$vim_vox
Y_rm3_T3 <- as.numeric(Y_rm3_T3) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm3_T3  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "l2vim_vox",
                                   "l2authoritarian",
                                   "l2ideol",
                                   "l2nativism",
                                   "l2orgterr",
                                   "l2pop6amz",
                                   "l2msexism",
                                   "lsvim_vox",
                                   "lsauthoritarian",
                                   "lsideol",
                                   "lsnativism",
                                   "lsorgterr",
                                   "lspop6amz",
                                   "posmsex",
                                   "negmsex"
                                   )

independent_variables_m3 <- rep_m3_T3[, independent_variables_rm3_T3]
X_rm3_T3 <- cbind(1, independent_variables_m3)
X_rm3_T3 <- as.matrix(sapply(X_rm3_T3, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# ................................ T3 - MODEL 4 ...............................#
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...
variables_re_m4T3  <- c("female",
                        "age",
                        "edu3_2",
                        "edu3_3",
                        "dhincome_all",
                        "livingpartner",
                        "intpol",
                        "l2vim_vox",
                        "l2authoritarian",
                        "l2ideol",
                        "l2nativism",
                        "l2orgterr",
                        "l2pop6amz",
                        "l2msexism",
                        "lsvim_vox",
                        "lsauthoritarian",
                        "lsideol",
                        "lsnativism",
                        "lsorgterr",
                        "lspop6amz",
                        "posmsex",
                        "negmsex",
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel8") containing the independent variables as defined by the vector "variables_re_T2", in addition to the dependent variable "vim_vox" ...
data_panel8 <- na.omit(data_panel[, c(variables_re_m4T3)])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2020 ...
rep_m4_T3 <- subset(data_panel8,year == 2020) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m4_T3$vim_vox <- as.numeric(rep_m4_T3$vim_vox) # we make sure that the DV is numeric 
Y_rm4_T3 <- rep_m4_T3$vim_vox
Y_rm4_T3 <- as.numeric(Y_rm4_T3) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_rm4_T3  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "l2vim_vox",
                                   "l2authoritarian",
                                   "l2ideol",
                                   "l2nativism",
                                   "l2orgterr",
                                   "l2pop6amz",
                                   "l2msexism",
                                   "lsvim_vox",
                                   "lsauthoritarian",
                                   "lsideol",
                                   "lsnativism",
                                   "lsorgterr",
                                   "lspop6amz",
                                   "posmsex",
                                   "negmsex"
                                   )

independent_variables_m4 <- rep_m4_T3[, independent_variables_rm4_T3]
X_rm4_T3 <- cbind(1, independent_variables_m4)
X_rm4_T3 <- as.matrix(sapply(X_rm4_T3, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

```

``` {r Optimization of Logit-Log-Likelihood Function}

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm1_T4 <- rep(0,22)
## ... and implement an initial optimization ...
res1_rm1_T4 <- optim(par = startvalues1_rm1_T4,
             fn = LL_logit,
             y = Y_rm1_T3,
             X = X_rm1_T3,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm1_T4 <- round(res1_rm1_T4$par,10)
res2_rm1_T4 <- optim(par= startvalues2_rm1_T4,
             fn = LL_logit,
             y = Y_rm1_T3,
             X = X_rm1_T3,
             control=list(parscale=abs(res1_rm1_T4$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object called ...
point_estimates_rm1_T4 <- res1_rm1_T4$par[1:22]
# ... We proceed with the estimation of the standard errors ...
SE_rm1_T4 <- sqrt(diag(solve(-res1_rm1_T4$hessian)))
# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm1_T4 <- 2 * (1 - pnorm(abs(point_estimates_rm1_T4 / SE_rm1_T4)))
# ... we additionally extract the number of observations ...
N_rm1_T4 <- length(Y_rm1_T3)

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm2_T4 <- rep(0,22)
## ... and implement an initial optimization ...
res1_rm2_T4 <- optim(par = startvalues1_rm2_T4,
             fn = LL_logit,
             y = Y_rm2_T3,
             X = X_rm2_T3,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm2_T4 <- round(res1_rm2_T4$par,10)
res2_rm2_T4 <- optim(par= startvalues2_rm2_T4,
             fn = LL_logit,
             y = Y_rm2_T3,
             X = X_rm2_T3,
             control=list(parscale=abs(res1_rm2_T4$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object called ...
point_estimates_rm2_T4 <- res2_rm2_T4$par[1:22]
# ... We proceed with the estimation of the standard errors ...
SE_rm2_T4 <- sqrt(diag(solve(-res2_rm2_T4$hessian)))
# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm2_T4 <- 2 * (1 - pnorm(abs(point_estimates_rm2_T4 / SE_rm2_T4)))
# ... we additionally extract the number of observations ...
N_rm2_T4 <- length(Y_rm2_T3)

# .............................................................................#
# ................................... MODEL 3 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm3_T4 <- rep(0,23)
## ... and implement an initial optimization ...
res1_rm3_T4 <- optim(par = startvalues1_rm3_T4,
             fn = LL_logit,
             y = Y_rm3_T3,
             X = X_rm3_T3,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm3_T4 <- round(res1_rm3_T4$par,10)
res2_rm3_T4 <- optim(par= startvalues2_rm3_T4,
             fn = LL_logit,
             y = Y_rm3_T3,
             X = X_rm3_T3,
             control=list(parscale=abs(res1_rm3_T4$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object called ...
point_estimates_rm3_T4 <- res2_rm3_T4$par[1:23]
# ... We proceed with the estimation of the standard errors ...
SE_rm3_T4 <- sqrt(diag(solve(-res2_rm3_T4$hessian)))
# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm3_T4 <- 2 * (1 - pnorm(abs(point_estimates_rm3_T4 / SE_rm3_T4)))
# ... we additionally extract the number of observations ...
N_rm3_T4 <- length(Y_rm3_T3)

# .............................................................................#
# ................................... MODEL 4 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm4_T4 <- rep(0,23)
## ... and implement an initial optimization ...
res1_rm4_T4 <- optim(par = startvalues1_rm4_T4,
             fn = LL_logit,
             y = Y_rm4_T3,
             X = X_rm4_T3,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm4_T4 <- round(res1_rm4_T4$par,10)
res2_rm4_T4 <- optim(par= startvalues2_rm4_T4,
             fn = LL_logit,
             y = Y_rm4_T3,
             X = X_rm4_T3,
             control=list(parscale=abs(res1_rm4_T4$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object called ...
point_estimates_rm4_T4 <- res2_rm4_T4$par[1:23]
# ... We proceed with the estimation of the standard errors ...
SE_rm4_T4 <- sqrt(diag(solve(-res2_rm4_T4$hessian)))
# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_rm4_T4 <- 2 * (1 - pnorm(abs(point_estimates_rm4_T4 / SE_rm4_T4)))
# ... we additionally extract the number of observations ...
N_rm4_T4 <- length(Y_rm4_T3)

```

```{r Viualization of Estimation Results (Models 1 - 4) }

library(knitr)

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm1_T3 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (t-2)",
                   "Authoritarianism (t-2)",
                   "Ideological identification (t-2)",
                   "Nativism (t-2)",
                   "Territorial preference (t-2)",
                   "Populism (t-2)",
                   "Sexism (t-2)",
                   "Vox intention (t2 minus t1)",
                   "Authoritarianism (t2 minus t1)",
                   "Ideological identification (t2 minus t1)",
                   "Nativism (t2 minus t1)",
                   "Territorial preference (t2 minus t1)",
                   "Populism (t2 minus t1)",
                   "Sexism (t2 minus t1)"
                   ),
  
  Point_Estimates = point_estimates_rm1_T4,
  Standard_Errors = SE_rm1_T4,
  P_Values = P_Values_rm1_T4,
  Observations = N_rm1_T4 )

# Print formatted table
kable(results_rm1_T3, align = "c", digits = 3, caption = "Results Replication Model 1",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm2_T3 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (t-2)",
                   "Authoritarianism (t-2)",
                   "Ideological identification (t-2)",
                   "Nativism (t-2)",
                   "Territorial preference (t-2)",
                   "Populism (t-2)",
                   "Sexism (t-2)",
                   "Vox intention (t2 minus t1)",
                   "Authoritarianism (t2 minus t1)",
                   "Ideological identification (t2 minus t1)",
                   "Nativism (t2 minus t1)",
                   "Territorial preference (t2 minus t1)",
                   "Populism (t2 minus t1)",
                   "Sexism (t2 minus t1)"
                   ),
  
  Point_Estimates = point_estimates_rm2_T4,
  Standard_Errors = SE_rm2_T4,
  P_Values = P_Values_rm2_T4,
  Observations = N_rm2_T4 )

# Print formatted table
kable(results_rm2_T3, align = "c", digits = 3, caption = "Results Replication Model 2",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ................................... MODEL 3 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm3_T3 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (t-2)",
                   "Authoritarianism (t-2)",
                   "Ideological identification (t-2)",
                   "Nativism (t-2)",
                   "Territorial preference (t-2)",
                   "Populism (t-2)",
                   "Sexism (t-2)",
                   "Vox intention (t2 minus t1)",
                   "Authoritarianism (t2 minus t1)",
                   "Ideological identification (t2 minus t1)",
                   "Nativism (t2 minus t1)",
                   "Territorial preference (t2 minus t1)",
                   "Populism (t2 minus t1)",
                   "Increase in sexism",
                   "Decrease in sexism"
                   ),
  
  Point_Estimates = point_estimates_rm3_T4,
  Standard_Errors = SE_rm3_T4,
  P_Values = P_Values_rm3_T4,
  Observations = N_rm3_T4 )

# Print formatted table
kable(results_rm3_T3, align = "c", digits = 3, caption = "Results Replication Model 3",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

# .............................................................................#
# ................................... MODEL 4 ..................................
# .............................................................................#

# We first define the point estimates, standard errors, and p-values
results_rm4_T3 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (t-2)",
                   "Authoritarianism (t-2)",
                   "Ideological identification (t-2)",
                   "Nativism (t-2)",
                   "Territorial preference (t-2)",
                   "Populism (t-2)",
                   "Sexism (t-2)",
                   "Vox intention (t2 minus t1)",
                   "Authoritarianism (t2 minus t1)",
                   "Ideological identification (t2 minus t1)",
                   "Nativism (t2 minus t1)",
                   "Territorial preference (t2 minus t1)",
                   "Populism (t2 minus t1)",
                   "Increase in sexism",
                   "Decrease in sexism"
                   ),
  
  Point_Estimates = point_estimates_rm4_T4,
  Standard_Errors = SE_rm4_T4,
  P_Values = P_Values_rm4_T4,
  Observations = N_rm4_T4 )

# Print formatted table
kable(results_rm4_T3, align = "c", digits = 3, caption = "Results Replication Model 4",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

```

``` {r Replication of Main Table Using R's built-in GLM Commands}

install.packages("brglm2")
library(brglm2)

t3m1 <- glm(vim_vox ~ female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol + l2vim_vox + l2authoritarian + l2ideol + l2nativism + l2orgterr + l2pop6amz + l2msexism + lsvim_vox + lsauthoritarian + lsideol + lsnativism + lsorgterr + lspop6amz + lsmsexism, family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2019))


## Column 2 (model 2, 2020)
t3m2 <- glm(vim_vox ~ female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol + l2vim_vox + l2authoritarian + l2ideol + l2nativism + l2orgterr + l2pop6amz + l2msexism + lsvim_vox + lsauthoritarian + lsideol + lsnativism + lsorgterr + lspop6amz + lsmsexism, family = binomial(logit), method = "brglmFit", data = data_panel %>% filter(year == 2020))

## Column 3 (model 3, 2019)
t3m3 <- update(t3m1, ~. - lsmsexism + posmsex + negmsex)

## Column 4 (model 4, 2020)
t3m4 <- update(t3m2, ~. - lsmsexism + posmsex + negmsex)

stargazer(t3m1, t3m2, t3m3, t3m4, type = "text", dep.var.caption = "", dep.var.labels.include = F, column.labels = c("2019", "2020", "2019", "2020"), keep.stat = "n", star.char = c("+", "*", "**"), star.cutoffs = c(0.1, 0.05, 0.01),  notes = c("+ p<0.1; * p<0.05; ** p<0.01"), covariate.labels = c("Female", "Age", "Upper secondary", "Tertiary", "Income", "Lives with partner", "Interest in politics", "Vox intention (t-2)", "Authoritarianism (t-2)", "Ideological identification (t-2)", "Nativism (t-2)", "Territorial preference (t-2)", "Populism (t-2)", "Sexism (t-2)", "Vox intention (t-1 minus t-2)", "Authoritarianism (t-1 minus t-2)", "Ideological identification (t-1 minus t-2)", "Nativism (t-1 minus t-2)", "Territorial preference (t-1 minus t-2)", "Populism (t-1 minus t-2)", "Sexism (t-1 minus t-2)", "Increase in sexism (t-1 minus t-2)", "Decrease in sexism (t-1 minus t-2)"), notes.append = F, no.space = T, title = "Table 3. Effect of prior change in attitudes and vote intention on intended vote for Vox")

```

##Analysis Part 4: 

### For Year 2019 
```{r }

# ... we initiate by generating a new variable for the interaction between the variables "female" and "lm1_msexism" ...
data_panel$int_m1E1 <- data_panel$female * data_panel$lm1_msexism

# ... we proceed to define a vector containing the names of all the variables that will be used for the estimation of the model ...
variables_m1E1  <- c("female",                 
                     "age",                  
                     "edu3_2",               
                     "edu3_3",               
                     "dhincome_all",         
                     "livingpartner",        
                     "intpol",               
                     "lm1_vim_vox",          
                     "lm1_authoritarian",    
                     "lm1_ideol",            
                     "lm1_nativism",         
                     "lm1_orgterr",          
                     "lm1_pop6amz",           
                     "lm1_msexism",  
                     "int_m1E1",
                     "vim_vox",
                     "year")

# ... we then generate a data subset ("data_panel3") containing the independent variables as defined by the vector "variables_re_T3", in addition to the dependent variable "vim_vox" ...
data_panel_m1E1 <- na.omit(data_panel[, c(variables_m1E1)])

# ... and subsequently create a subset of the data frame "data_panel3" containing only observations for which the value of "year" is 2019 ...
data_panel_m1E1 <- subset(data_panel_m1E1, year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
data_panel_m1E1$vim_vox <- as.numeric(data_panel_m1E1$vim_vox) 
Y_m1E1 <- data_panel_m1E1$vim_vox
Y_m1E1 <- as.numeric(Y_m1E1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_m1E1  <- c("female",                 
                                 "age",                    
                                 "edu3_2",                 
                                 "edu3_3",                 
                                 "dhincome_all",           
                                 "livingpartner",          
                                 "intpol",   
                                 "lm1_vim_vox",          
                                 "lm1_authoritarian",        
                                 "lm1_ideol",                
                                 "lm1_nativism",             
                                 "lm1_orgterr",              
                                 "lm1_pop6amz",              
                                 "lm1_msexism",
                                 "int_m1E1"
                                 )

independent_variables_m1E1 <- data_panel_m1E1[, independent_variables_m1E1]
X_m1E1 <- cbind(1, independent_variables_m1E1)
X_m1E1 <- as.matrix(sapply(X_m1E1, as.numeric))

```

```{r  }

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_m1E1 <- rep(0,16)

## ... and implement an initial optimization ...
res1_m1E1 <- optim(par = startvalues1_m1E1,
             fn = LL_logit,
             y = Y_m1E1,
             X = X_m1E1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_m1E1 <- round(res1_m1E1$par,10)

res2_m1E1 <- optim(par= startvalues2_m1E1,
             fn = LL_logit,
             y = Y_m1E1,
             X = X_m1E1,
             control=list(parscale=abs(res1_m1E1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_m1E1 <- res2_m1E1$par[1:16]

# ... We proceed with the estimation of the standard errors ...
SE_m1E1 <- sqrt(diag(solve(-res2_m1E1$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_m1E1 <- 2 * (1 - pnorm(abs(point_estimates_m1E1 / SE_m1E1)))

# ... we additionally extract the number of observations ...
N_m1E1 <- length(Y_m1E1)

```

```{r }

# We first define the point estimates, standard errors, and p-values
results_m1E1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Intention to vote for VOX (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)",
                   "Female x Prior Sexism") ,
  
  Point_Estimates = point_estimates_m1E1,
  Standard_Errors = SE_m1E1,
  P_Values = P_Values_m1E1,
  Observations = N_m1E1 )

# Print formatted table
kable(results_m1E1, align = "c", digits = 7, caption = "Results Replication",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

```

### Quantities of Interest Model 1 (2019)


```{r Definition of the Simulation Function}

response_function <- function(x) {
  1 / (1 + exp(-x))
}

stochastic_component <- function(ndraws, p) {
  rbinom(n = ndraws, size = 1, prob = p)
}

sim_function <-
  function(seed = 1234,
           nsim = 1000,
           coefs,
           vcov,
           scenario,
           response_function,
           predicted_values = F,
           stochastic_component) {
    if (is.null(dim(scenario))) {
      stop("The scenario needs to be in a matrix.")
    }
    
    if (length(coefs) != ncol(scenario)) {
      stop("The scenario and the parameter vector don't fit.")
    }
    
    set.seed(seed)
    
    # Set up the sampling distribution
    S <- mvrnorm(nsim, coefs, vcov)
    mu <- S %*% t(scenario)
        ev <- response_function(mu)
    
    if (predicted_values) {
      pv <-
        array(stochastic_component(ndraws = prod(dim(ev)), p = ev),
              dim = dim(ev))
      return(list(ev = ev, pv = pv))
    }
    return(list(ev = ev))
    
  }

```



```{r }

library(MASS)
n_simulations <- 1000 # we define the number of simulations
varcov <- solve(-res2_m1E1$hessian)


# Set up the sampling distribution
S <- mvrnorm(n_simulations, res2_m1E1$par, varcov) # draw from multivariate normal distribution

dim(S) # rows indicate (1000) the number of draws, and the columns the number of coefficients in the model (12)

```

```{r Choose Interesting Scenarios}

sexism_seq <- seq(min(data_panel_m1E1$lm1_msexism[!is.na(data_panel_m1E1$lm1_msexism)]), 1, 
                  length.out = 1000)

scenario_w <- cbind(1,                                       # Intercept
                    1,                                       # Female
                    mean(data_panel_m1E1$age),               # Average age  
                    median(data_panel_m1E1$edu3_2),          # Median for "edu3_2"
                    median(data_panel_m1E1$edu3_3),          # Median for "edu3_3"
                    mean(data_panel_m1E1$dhincome_all),      # Average income 
                    median(data_panel_m1E1$livingpartner),   # Median living situation 
                    mean(data_panel_m1E1$intpol),            # Average Interest in Politics  
                    mean(data_panel_m1E1$lm1_authoritarian), # Average Authoritarianism (Prior)
                    mean(data_panel_m1E1$lm1_ideol),         # Average Ideology (Prior)
                    mean(data_panel_m1E1$lm1_nativism),      # Average Nativism (Prior)
                    mean(data_panel_m1E1$lm1_orgterr),       # Average Territorial (Prior)
                    mean(data_panel_m1E1$lm1_pop6amz),       # Average Populism (Prior)
                    sexism_seq,                              # Sexism-Sequence (Prior)
                    1*sexism_seq                             # Interaction
                    )    

scenario_m <- cbind(1,                                       # Intercept
                    0,                                       # Men
                    mean(data_panel_m1E1$age),               # Average age  
                    median(data_panel_m1E1$edu3_2),          # Median for "edu3_2"
                    median(data_panel_m1E1$edu3_3),          # Median for "edu3_3"
                    mean(data_panel_m1E1$dhincome_all),      # Average income 
                    median(data_panel_m1E1$livingpartner),   # Median living situation 
                    mean(data_panel_m1E1$intpol),            # Average Interest in Politics  
                    mean(data_panel_m1E1$lm1_authoritarian), # Average Authoritarianism (Prior)
                    mean(data_panel_m1E1$lm1_ideol),         # Average Ideology (Prior)
                    mean(data_panel_m1E1$lm1_nativism),      # Average Nativism (Prior)
                    mean(data_panel_m1E1$lm1_orgterr),       # Average Territorial (Prior)
                    mean(data_panel_m1E1$lm1_pop6amz),       # Average Populism (Prior)
                    sexism_seq,                              # Sexism-Sequence (Prior)
                    0*sexism_seq                             # Interaction
                    )   

# this is everything we need for our simulation

sim_women <- sim_function(coefs = res2_m1E1$par, 
                          vcov = solve(-res2_m1E1$hessian), 
                          scenario = scenario_w, 
                          response_function = response_function, 
                          stochastic_component = stochastic_component)$ev

sim_men <- sim_function(coefs = res2_m1E1$par, 
                          vcov = solve(-res2_m1E1$hessian), 
                          scenario = scenario_m, 
                          response_function = response_function, 
                          stochastic_component = stochastic_component)$ev

```




```{r Choose Interesting Scenarios}

par(mfrow = c(1, 2))


# Assuming you have calculated the confidence intervals as below:
lower_women <- apply(sim_women, 2, function(x) quantile(x, probs = 0.025))
upper_women <- apply(sim_women, 2, function(x) quantile(x, probs = 0.975))
lower_men <- apply(sim_men, 2, function(x) quantile(x, probs = 0.025))
upper_men <- apply(sim_men, 2, function(x) quantile(x, probs = 0.975))

# Plot predicted probabilities with confidence intervals
plot(x = sexism_seq,
     y = apply(sim_women, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted probabilities", 
     cex.main = 0.7,
     xlab = "Level of Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.4), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 1, by = 0.05), cex.axis = 0.7)

# Add a background grid
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(0, 1, by = 0.1), col = "grey90")

# Add confidence intervals as shaded areas
polygon(c(sexism_seq, rev(sexism_seq)), c(upper_women, rev(lower_women)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(sexism_seq, rev(sexism_seq)), c(upper_men, rev(lower_men)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = sexism_seq, y = apply(sim_women, 2, mean), lwd = 2, col = "red")
lines(x = sexism_seq, y = apply(sim_men, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel_m1E1$lm1_msexism[data_panel_m1E1$lm1_msexism <= 150], 0.1), ticksize = 0.02, lwd = 1)



# Next, we calculate and plot the first difference
# this time we also want to see the uncertainty

fd <- sim_women - sim_men

plot(x = sexism_seq,
     y = apply(fd, 2, mean),
     type = "n",
     lwd = 2,
     main = "First difference", 
     cex.main = 0.7,
     xlab = "Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.6), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = sexism_seq,
      y = apply(fd, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = sexism_seq,
      y = apply(fd, 2, quantile, 0.025),
      lty = "dashed")
lines(x = sexism_seq,
      y = apply(fd, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

```

```{r }

# More than one scenario in an array.
# 3D array of dim nrow(X), ncol(X), 2
cases <- array(NA, c(dim(X_m1E1), 2))

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases[, ,] <- X_m1E1

# select the columns to adjust for simulation 
sel1 <- which(colnames(X_m1E1) == "female")
sel2 <- which(colnames(X_m1E1) == "int_m1E1")

# assign 0 to "female" column in layer 1
cases[, sel1, 1] <- 0
# assign 1 to female column in layer 2
cases[, sel1, 2] <- 1

# assign 0 to interaction ("int_m1E1") column in layer 1
cases[, sel2, 1] <- 0*X_m1E1[, "female"]
# assign "safety" value to interaction column in layer 2
cases[, sel2, 2] <- 1*X_m1E1[, "female"]

# Loop over the matrices.
val <- matrix(NA, nrow = nsim, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev <- sim_function(
      coefs = res2_m1E1$par,
      vcov = solve(-res2_m1E1$hessian),
      response_function = response_function,
      stochastic_component = stochastic_component,
      scenario = cases[,,i],
      predicted_values = F
    )$ev
  
  tmp_val <- apply(ev, 1, mean)
  val[, i] <- tmp_val
}

fd <- val[, 1] - val[, 2]

###############################
par(mfrow = c(1, 2))


# Plot the histogram
hist(
  fd,
  breaks = 20,
  main = "Histogram of Simulated First Differences",
  xlab = "First Difference",
  las = 1,
  col = "lightpink",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd), 3)), col = "black", pos = 4)
text(quantile(fd, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd, 0.975), 3)), col = "black", pos = 4)


# Assuming fd is a vector of simulated first differences

# Generate the density plot
plot(
  density(fd),
  main = "Density Plot of Simulated First Differences",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightpink",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd), 3)), col = "black", pos = 4)
text(quantile(fd, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd, 0.975), 3)), col = "black", pos = 4)



```



###For Year 2020 
```{r }

# ... we initiate by generating a new variable for the interaction between the variables "female" and "lm1_msexism" ...
data_panel$int_m2E1 <- data_panel$female * data_panel$lm2_msexism

# ... we proceed to define a vector containing the names of all the variables that will be used for the estimation of the model ...
variables_m2E1  <- c("female",                 
                     "age",                  
                     "edu3_2",               
                     "edu3_3",               
                     "dhincome_all",         
                     "livingpartner",        
                     "intpol",               
                     "lm2_vim_vox",          
                     "lm2_authoritarian",    
                     "lm2_ideol",            
                     "lm2_nativism",         
                     "lm2_orgterr",          
                     "lm2_pop6amz",           
                     "lm2_msexism",  
                     "int_m2E1",
                     "vim_vox",
                     "year")

# ... we then generate a data subset ("data_panel3") containing the independent variables as defined by the vector "variables_re_T3", in addition to the dependent variable "vim_vox" ...
data_panel_m2E1 <- na.omit(data_panel[, c(variables_m2E1)])

# ... and subsequently create a subset of the data frame "data_panel3" containing only observations for which the value of "year" is 2019 ...
data_panel_m2E1 <- subset(data_panel_m2E1, year == 2020) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
data_panel_m2E1$vim_vox <- as.numeric(data_panel_m2E1$vim_vox) 
Y_m2E1 <- data_panel_m2E1$vim_vox
Y_m2E1 <- as.numeric(Y_m2E1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_m2E1  <- c("female",                 
                                 "age",                    
                                 "edu3_2",                 
                                 "edu3_3",                 
                                 "dhincome_all",           
                                 "livingpartner",          
                                 "intpol",                 
                                 "lm2_vim_vox",            
                                 "lm2_authoritarian",        
                                 "lm2_ideol",                
                                 "lm2_nativism",             
                                 "lm2_orgterr",              
                                 "lm2_pop6amz",              
                                 "lm2_msexism",
                                 "int_m2E1"
                                 )

independent_variables_m2E1 <- data_panel_m2E1[, independent_variables_m2E1]
X_m2E1 <- cbind(1, independent_variables_m2E1)
X_m2E1 <- as.matrix(sapply(X_m2E1, as.numeric))

```




```{r  }

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_m2E1 <- rep(0,16)

## ... and implement an initial optimization ...
res1_m2E1 <- optim(par = startvalues1_m2E1,
             fn = LL_logit,
             y = Y_m2E1,
             X = X_m2E1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization.
startvalues2_m2E1 <- round(res1_m2E1$par,10)

res2_m2E1 <- optim(par= startvalues2_m2E1,
             fn = LL_logit,
             y = Y_m2E1,
             X = X_m2E1,
             control=list(parscale=abs(res1_m2E1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_m2E1 <- res2_m2E1$par[1:16]

# ... We proceed with the estimation of the standard errors ...
SE_m2E1 <- sqrt(diag(solve(-res2_m2E1$hessian)))

# ... we furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the coefficients) ...
P_Values_m2E1 <- 2 * (1 - pnorm(abs(point_estimates_m2E1 / SE_m2E1)))

# ... we additionally extract the number of observations ...
N_m2E1 <- length(Y_m2E1)

```

```{r }

# We first define the point estimates, standard errors, and p-values
results_m2E1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)",
                   "Female x Sexism (Prior)") ,
  
  Point_Estimates = point_estimates_m2E1,
  Standard_Errors = SE_m2E1,
  P_Values = P_Values_m2E1,
  Observations = N_m2E1 )

# Print formatted table
kable(results_m2E1, align = "c", digits = 7, caption = "Results Replication",
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", "Estimates" = 2, "Statistics" = 2)))

```










