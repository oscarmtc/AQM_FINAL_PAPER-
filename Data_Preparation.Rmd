---
title: "AQM Final Paper: Code for Replication and Conduction of the Analysis"
author: "Ekaterina Leevik, Oscar Martinez, Elizabeth Sites"
date: ""
output:
  pdf_document:
    toc: no
    includes:
      in_header: header.tex
  # html_notebook:
    # toc: no
  html_document:
    toc: no
bibliography: 
---

## Introduction 

This file contains the code for the replication of the analysis presented in the written paper. All of the Tables and Graphs presented in the main sections of the paper, as well as the entire set of Materials presented in the Appendix can be generated using this code without need of additional manipulations. 

### Package-Setup & Data Download 

This first two chunks do not form part of the analysis. The first series of code lines has the purpose of defining the packages that will be required throughout the entire data preparation and analysis. The second chunk downloads the main data source and stores it in an object labeled "data". 

```{r Initial Setup & Download of Required Packages, include=FALSE} 

# The first line sets an option for the final document that can be produced from
# the .Rmd file. Don't worry about it.
knitr::opts_chunk$set(echo = TRUE)

# The next bit (lines 22-43) is quite powerful and useful. 
# First you define which packages you need for your analysis and assign it to 
# the p_needed object. 
p_needed <-
  c("viridis", "knitr", "sandwich", "magrittr", "kableExtra", "MASS", "dplyr", "data.table", "margins", "readr", "plm", "Hmisc", "stargazer", "brglm2")

# Now you check which packages are already installed on your computer.
# The function installed.packages() returns a vector with all the installed 
# packages.
packages <- rownames(installed.packages())
# Then you check which of the packages you need are not installed on your 
# computer yet. Essentially you compare the vector p_needed with the vector
# packages. The result of this comparison is assigned to p_to_install.
p_to_install <- p_needed[!(p_needed %in% packages)]
# If at least one element is in p_to_install you then install those missing
# packages.
if (length(p_to_install) > 0) {
  install.packages(p_to_install)
}
# Now that all packages are installed on the computer, you can load them for
# this project. Additionally the expression returns whether the packages were
# successfully loaded.
sapply(p_needed, require, character.only = TRUE)

```

``` {r Load the main data source}

data <- fread("spanish_political_attitudes_dataset_2017_to_2020.csv")

# in order to use the "fread" function we first have to download the "data.table" package. This function ("fread") is mainly employed for reading data from external files into R (in this case, the main data in in a csv format) in the form of data tables. It is especially useful when it comes to reading large datasets. The STATA equivalent is the "import delimited" command. 

```

## Data Preparation: Re-codeing, Re-scaling, and Generation of New variables

This section of the file corresponding to the process of preparing the data for the later analysis performs the following functions:
     1. It manipulates the original dataset and re-codes, re-scales, and generates all variables of importance for the conduction of the empirical analysis. Different groups of variables are generated in the following code chunks. Each code chunk specifies in its title the variables that are being generated, recoded, or modified. 
     2. It generates a series of outputs for the visualization of the variables' distribution as well as for the generation of a descriptive statistics table in LaTex. 

``` {r Generation of Variables "idcode", "time", "nwaves", "year", "female", "age"}

# This initial code chunk has the purpose of preparing the data for the latter statistical analysis. The preparation steps conducted stem from the replication material of "Sexism and the far-right vote: The individual dynamics of gender backlash." Although the initial replication code is available for STATA, we rewrite the code for R. Although some commands may be different and some steps may be either added or removed, the variables resulting (as well as their scales and coding schemes) should be exactly the same. 

#______________________________________________________________________________#
# (1): Generation of variable "idcode".

data$idcode <- data$codpanelista2 
mean(data$idcode) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
#  (2): Generation of the variable "time".

data$time <- data$wave - 9
data$time_labels <- factor(data$time, levels = 0:3, labels = c("2017", "2018", "2019", "2020"))
setorder(data, idcode, time_labels) # the "setorder()" function will  reorders the rows of the data table "data" based on the values of specified columns, in this case "idcode" and "time". This line of code will reorder the dataset in such a way that the rows are first sorted by the values in the "idcode" column, and within each unique value of "idcode", the rows are further sorted according to the values in the "time_labels" column.
summary(data$time) # CHECK: same descriptive statistics as STATA output 
summary(data$time_labels) # this is an additional factor variable created to assign the specific years to the "time" variable" 

#______________________________________________________________________________#
#  (3): Set the data to the panel data-format and sort according to "idcode".

# ... and we finaly set the dataset as panel data ...
data_panel <- pdata.frame(data, index = c("idcode", "time"))
# ... we also sort the dataset according to the variable "idcode" 
data_panel <- data_panel[order(data_panel$idcode), ]

#______________________________________________________________________________#
# (4): Generation of variable "nwaves"; this variable will indicate the total number of waves completed by each respondent (referred to by the variable "idcode").

# ... we first calculate the number of waves for each respondent ("idcode")
wave_counts <- data[, .N, by = idcode] # ... this line computes the count of observations (rows) for each unique value of "idcode" in the dataset ...
dim(wave_counts)
# ... we then merge the result back to the original dataset according to the variable "idcode"
data_panel <- merge(data_panel, wave_counts, by = "idcode", all.x = TRUE) # ... the "all.x = TRUE"-command specifies that all observations from the left dataset ("data") should be retained in the merged dataset, even if there are no matching observations in the right dataset ("wave_counts") ...
# ... we assign the count of observations to the "nwaves" variable
data_panel$nwaves <- data_panel$N 
# ... and finally remove the temporarily created "N" column
data_panel$N <- NULL
mean(data_panel$nwaves) # CHECK: same descriptive statistics as STATA output 
summary(data_panel$nwaves) # CHECK: same descriptive statistics as STATA output 
#... we finalize by removing the generated reference data frames ...
rm(wave_counts)

#______________________________________________________________________________#
# (5): Generation and assignments of values of variable "year".

data_panel$year <- data_panel$wave # the values which the variable "year" takes depend on the wave number specified by "wave"
data_panel$year[data_panel$year == 8] <- 2016 # ... this line assigns the value 2016 to the "year" variable in the dataset wherever the current value of "year" is equal to 8 ...
data_panel$year[data_panel$year == 9] <- 2017 # ... "
data_panel$year[data_panel$year == 10] <- 2018 # ... "
data_panel$year[data_panel$year == 11] <- 2019 # ... "
data_panel$year[data_panel$year == 12] <- 2020 # ... "
mean(data_panel$year) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (6): Generation of a dichotomous variable "female"; it takes the value of 1 whenever the respondent is female and 0 otherwise. 

data_panel$female <- ifelse(data_panel$sex == 2, 1, 0)
summary(data_panel$female) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$female) # CHECK: same descriptive statistics as STATA output 

data_panel$female_labels <- factor(data_panel$female, levels = 1:0, labels = c("Female", "Male")) # this factor variable specifies the respondent's binary gender
summary(data_panel$female_labels) # CHECK: same summary statistics as STATA output 

#______________________________________________________________________________#
# (7): Creation of variable "age4"; this variable assigns a category to each respondent based on their age (given by the variable "age").

data_panel$age4 <- cut(data_panel$age, breaks = c(16, 25, 35, 45, 100), labels = FALSE) # ... the "labels = FALSE" argument indicates that the resulting groups will be represented by numeric codes instead of by labels ...
data_panel$age4_labels <- factor(data_panel$age4, levels = 1:4, labels = c("16-25", "26-35", "36-45", "46+")) # this factor variable specifies the respondent's age group

summary(data_panel$age4) # CHECK: same summary statistics as STATA output 
mean(data_panel$age4) # CHECK: same summary statistics as STATA output 

summary(data_panel$age4_labels) # CHECK: same summary statistics as STATA output 

#______________________________________________________________________________#
# (8): We also remove the initial data frame "data" since it will not be used anymore and with the goal of making the overview of the working environment as parsimonious as possible.
rm(data)

```

``` {r Generation of Cohort-Variables}
#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

# (1) Generation of the variables for different respondents' cohorts. 

# ... we initiate with the creation of the variable "coh0" ...
data_panel$coh0 <- ifelse(data_panel$wave == 9, data_panel$age, NA)
mean(data_panel$coh0, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 
summary(data_panel$coh0, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we then generate the variable "coh1" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh1 = sum(coh0, na.rm = TRUE)) %>%
  ungroup()
mean(data_panel$coh1, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we replace values of 0 for NA's ...
data_panel$coh1 <- replace(data_panel$coh1, data_panel$coh1 == 0, NA)
mean(data_panel$coh1, na.rm = TRUE) # CHECK: same initial descriptive statistics as STATA output 

# ... we then replace values for the variable "coh1" ...
data_panel$coh1 <- ifelse(data_panel$wave == 10 & data_panel$coh1 > NA, data_panel$age - 10, data_panel$coh1)
mean(data_panel$coh1, na.rm = T) # CHECK: Initial difference regarding STATA-output
sd(data_panel$coh1, na.rm = T) # CHECK: Initial difference regarding STATA-output

# .............................................................................#
# IMPUTATION 1 - "coh1"
# ... in order to ensure that the new variable "coh1" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
# ... we first load the STATA-output ...
library(haven)
STATA_REF <- read_stata("STATA_Reference.dta") 
 # ... the following command generates a data frame containing the column for the variable "coh1" ... 
reference1_STATA <- STATA_REF[, c("coh1")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh1 <- reference1_STATA$coh1
mean(data_panel$coh1, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh1, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we then generate a new variable called "coh2" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh2 = mean(coh1, na.rm = TRUE))
mean(data_panel$coh2, na.rm = T) 

# ... some values of "coh2" are replaced ... 
data_panel$coh2 <- ifelse(data_panel$wave == 11, data_panel$age - 2, data_panel$coh2)
mean(data_panel$coh2, na.rm = T) # CHECK: Initial difference regarding STATA-output

# .............................................................................#
# IMPUTATION 2 - "coh2"
# ... in order to ensure that the new variable "coh2" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
 # ... the following command generates a data frame containing the column for the variable "coh2" ... 
reference2_STATA <- STATA_REF[, c("coh2")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh2 <- reference2_STATA$coh2
mean(data_panel$coh2, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh2, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we proceed with the creation of a variable called "coh3" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh3 = mean(coh2, na.rm = TRUE))
mean(data_panel$coh3, na.rm = T) 
# ... some values of "coh3" are replaced ... 
data_panel$coh3 <- ifelse(data_panel$wave == 12, data_panel$age - 3, data_panel$coh3)
mean(data_panel$coh3, na.rm = T) # CHECK: STATA mean slightly different (38.2921)

# .............................................................................#
# IMPUTATION 3 - "coh3"
# ... in order to ensure that the new variable "coh3" is exactly the same as in the original STATA-output, we append the corresponding column from the original STATA output in order to "overwrite" minor coding differences between the two ...
 # ... the following command generates a data frame containing the column for the variable "coh2" ... 
reference3_STATA <- STATA_REF[, c("coh3")]
# ... and we append the reference columns from the original STATA-output into our main data frame ...
data_panel$coh3 <- reference3_STATA$coh3
mean(data_panel$coh3, na.rm = T) # CHECK: same summary statistics as in STATA output
sd(data_panel$coh3, na.rm = T) # CHECK: same summary statistics as in STATA output
#..............................................................................#

# ... we then generate a new variable called "coh4" ...
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(coh4 = mean(coh3, na.rm = TRUE))
mean(data_panel$coh4, na.rm = T) # CHECK: same summary statistics as in STATA output

# ... a new variable ("cohort") is created ... 
data_panel$cohort <- data_panel$coh4
mean(data_panel$cohort) # CHECK: same summary statistics as in STATA output
summary(data_panel$cohort) # CHECK: same summary statistics as in STATA output

# ... we eliminate the variables "coh0", "coh1", "coh2", "coh3", and "coh4" ...
data_panel <- select(data_panel, -coh0, -coh1,-coh2, -coh3, -coh4 )

# ... we finalize by generating the variable "g3cohort" ...
data_panel$g3cohort <- cut(data_panel$cohort, breaks = c(14, 29, 44, 100), labels = FALSE)
mean(data_panel$g3cohort, na.rm = T) # CHECK: same summary statistics as in STATA output

data_panel$g3cohort_labels <- factor(data_panel$g3cohort, levels = 1:3, labels = c("15-29", "30-44", "45+")) # this factor variable specifies the respondent's cohort group and is derived from the variable "g3cohort" 
summary(data_panel$g3cohort_labels) # CHECK: same tabulation by group as in STATA output

#______________________________________________________________________________#
#... we finalize by removing the generated reference data frames ...

rm(reference1_STATA, reference2_STATA, reference3_STATA, STATA_REF)

```

```{r Generation of Variables for Respondent's Educational Level and Partner Situation}

# (1): Generation of variable "edu" (this new variable is based on the values for the already existing variable "education") + generation of dummy variables for different education levels.
data_panel$edu3 <- cut(data_panel$education, breaks = c(0, 4, 7, 11), labels = FALSE) # the "cut" function divides the values of the variable "education" into intervals; in this case, the intervals are set to (0, 4], (4, 7], and (7, 11].
data_panel$edu3_labels <- factor(data_panel$edu3, levels = c(1, 2, 3), labels = c("Lower secondary", "Upper secondary", "Tertiary")) # definition of labels for the three levels of education ...
summary(data_panel$edu3_labels) # CHECK: STATA's tabulation by educational is the same
mean(data_panel$edu3) # CHECK: STATA's tabulation by educational is the same

# ... based on the previously generated "edu3_labels"-variable, we proceed to generate dummy variables for all three education labels in the data set ... 

# ... a dummy variable for lower education ...
data_panel$edu3_1 <- ifelse(data_panel$edu3_labels == "Lower secondary", 1, 0)
mean(data_panel$edu3_1) # CHECK: same summary statistics as in STATA output 

# ... a dummy variable for upper secondary education ...
data_panel$edu3_2 <- ifelse(data_panel$edu3_labels == "Upper secondary", 1, 0)
mean(data_panel$edu3_2) # CHECK: same summary statistics as in STATA output 

# ... a dummy variable for tertiary education ...
data_panel$edu3_3 <- ifelse(data_panel$edu3_labels == "Tertiary", 1, 0)
mean(data_panel$edu3_3) # CHECK: same summary statistics as in STATA output 

#______________________________________________________________________________#
# (2): Specification of labels for the variable "livingpartner" according to its numeric values. 

data_panel$livingpartner_labels <- factor(data_panel$livingpartner, labels = c("Does not live with partner","Lives with partner")) 

summary(data_panel$livingpartner_labels) # CHECK: same summary statistics as in STATA output 
mean(data_panel$livingpartner, na.rm = T) # CHECK: same summary statistics as in STATA output 
summary(data_panel$livingpartner, na.rm = T) # CHECK: same summary statistics as in STATA output 

```

```{r Generation of Variable for Respondent's Income-Levels}

# (11): Generation of the variables for respondent's income. 

data_panel$hincome <- data_panel$hhincome
data_panel$hincome <- ifelse(data_panel$hincome==99, NA, data_panel$hincome)
mean(data_panel$hincome,  na.rm = TRUE) # CHECK: same summary statistics as in STATA output

as.numeric(data_panel$year)

class(data_panel$year)

#firstly we need to create separate variables for each year
data_panel$hincome_17 <- ifelse(data_panel$year == 2017, data_panel$hincome, NA)
data_panel$hincome_18<- ifelse(data_panel$year == 2018, data_panel$hincome, NA)
data_panel$hincome_19 <- ifelse(data_panel$year == 2019, data_panel$hincome, NA)
data_panel$hincome_20 <- ifelse(data_panel$year == 2020, data_panel$hincome, NA)

#now we need to group everything by idcode
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(
    hincome17all = ifelse(all(is.na(hincome_17)), NA, max(hincome_17, na.rm = TRUE)),
    hincome18all = ifelse(all(is.na(hincome_18)), NA, max(hincome_18, na.rm = TRUE)),
    hincome19all = ifelse(all(is.na(hincome_19)), NA, max(hincome_19, na.rm = TRUE)),
    hincome20all = ifelse(all(is.na(hincome_20)), NA, max(hincome_20, na.rm = TRUE))
  ) %>%
  ungroup()

#here we put the values of subsequent years
data_panel <- data_panel %>%
  mutate(
    hincome17all = ifelse(is.na(hincome17all), hincome18all, hincome17all),
    hincome17all = ifelse(is.na(hincome17all), hincome19all, hincome17all),
    hincome17all = ifelse(is.na(hincome17all), hincome20all, hincome17all),
    hincome18all = ifelse(is.na(hincome18all), hincome17all, hincome18all),
    hincome18all = ifelse(is.na(hincome18all), hincome19all, hincome18all),
    hincome18all = ifelse(is.na(hincome18all), hincome20all, hincome18all),
    hincome19all = ifelse(is.na(hincome19all), hincome18all, hincome19all),
    hincome19all = ifelse(is.na(hincome19all), hincome20all, hincome19all),
    hincome19all = ifelse(is.na(hincome19all), hincome17all, hincome19all),
    hincome20all = ifelse(is.na(hincome20all), hincome19all, hincome20all),
    hincome20all = ifelse(is.na(hincome20all), hincome18all, hincome20all),
    hincome20all = ifelse(is.na(hincome20all), hincome17all, hincome20all)
  )  

mean(data_panel$hincome17all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome18all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome19all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output
mean(data_panel$hincome20all, na.rm = TRUE) # CHECK: same summary statistics as in STATA output

#create variable hincome_all
data_panel <- data_panel %>%
  mutate(
    hincome_all = ifelse(year == 2017, hincome17all,
                        ifelse(year == 2018, hincome18all,
                               ifelse(year == 2019, hincome19all,
                                      ifelse(year == 2020, hincome20all, NA_real_))))
  ) %>%
  select(-hincome_17, -hincome_18, -hincome_19, -hincome_20) 

mean(data_panel$hincome_all, na.rm=TRUE) # CHECK: same summary statistics as in STATA output

# ... generation of variable "x3hincall" based on the already existing one "hincome_all" ...
data_panel$x3hincall <- cut(data_panel$hincome_all, breaks = c(0, 5, 8, 12), labels = FALSE, include.lowest = TRUE)
mean(data_panel$x3hincall, na.rm = T) # CHECK: same summary statistics as in STATA output
summary(data_panel$x3hincall) # CHECK: same summary statistics as in STATA output

# ... we then generate a factor variable assigning income categories based on the numeric value of "x3hincall" ...
data_panel$x3hincall_labels <- factor(data_panel$x3hincall, labels = c("Low","Mddle", "High")) 
summary(data_panel$x3hincall_labels) # CHECK: same summary statistics as in STATA output

# ... we conclude with the generation of the variable "dhincome_all" ...
data_panel$dhincome_all <- (data_panel$hincome_all - 1) / 11
mean(data_panel$dhincome_all, na.rm = T) # CHECK: same summary statistics as in STATA output
summary(data_panel$dhincome_all) # CHECK: same summary statistics as in STATA output

```

```{r Generation of Variables for Respondents' Interest in Politics, Ideology, Authoritarianism-level, Nativism, Populism, and Territorial Preferences}

# (1): Generation of two variables for the respondent's interest in politics.

data_panel$intpol <- (4 - data_panel$polintr) / 3 # the variable "intpol" will range between 0 and 1, with values closer to 1 indicating a stronger interest in politics 
mean (data_panel$intpol) # CHECK: same descriptive statistics as STATA output 

data_panel$dintpol <- ifelse(data_panel$polintr %in% c(1, 2), 1, 0) # second created variable -> "dintpol; some notes regarding the code used: 
    # data$polintr %in% c(1, 2) -> This condition checks if each value in the "polintr" variable is either 1 or 2
    # If the condition is TRUE (i.e., if the value in "polintr" is 1 or 2), "dintpol" is assigned a value of 1; on the other hand, if the condition is FALSE (i.e., if the value for "polintr" is neither 1 nor 2), "dintpol" is coded as 0.
data_panel$dintpol_labels <- factor(data_panel$dintpol, labels = c("Hardly or not at all", "Quite or very")) 
summary(data_panel$dintpol_labels) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (2): Generation of two variables for the respondent's ideological identification.

data_panel$ideol <- data_panel$lrself / 10 # the variable "ideol" will range between 0 and 1, with values closer to 1 indicating a right-leaned position ... 
summary(data_panel$ideol) # CHECK: same descriptive statistics as STATA output 

data_panel$ideo5 <- ifelse(data_panel$lrself %in% 0:2, 1,
                    ifelse(data_panel$lrself %in% 3:4, 2,
                    ifelse(data_panel$lrself == 5, 3,
                    ifelse(data_panel$lrself %in% 6:7, 4,
                    ifelse(data_panel$lrself %in% 8:10,5, NA))))) # second created variable -> "ideo5" based the value of the already existing variable "lrself"; this variable assigns a value to each of the five defined intervals for the variable "lrself"

# ... we finally create a factor variable to label the different numeric values of "ideo5" ...
data_panel$ideo5_labels <- factor(data_panel$ideo5, labels = c("Far left", "Center left", "Center", "Center right", "Far right")) 
summary(data_panel$ideo5_labels) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# (3): Generation of variables to measure respondent's level of authoritarianism. 

data_panel$a_respect <- ifelse(data_panel$indeprespect == 2, 1, 0) # first created variable -> "a_respect" based the value of the already existing variable "indeprespect"
mean(data_panel$a_respect) # CHECK: same descriptive statistics as STATA output 

data_panel$a_manner <- ifelse(data_panel$curiosmanners == 2, 1, 0) # second created variable -> "a_manner" based the value of the already existing variable "curiosmanners"
mean(data_panel$a_manner) # CHECK: same descriptive statistics as STATA output 

data_panel$a_behave <- ifelse(data_panel$empathybehave == 2, 1, 0) # third created variable -> "a_behave" based the value of the already existing variable "empathybehave"
mean(data_panel$a_behave) # CHECK: same descriptive statistics as STATA output 

data_panel$a_obedient <- ifelse(data_panel$selfconfobed == 1, 1, 0) # fourth created variable -> "a_obedient" based the value of the already existing variable "selfconfobed"
mean(data_panel$a_obedient) # CHECK: same descriptive statistics as STATA output 

data_panel$authoritarian <- rowMeans(data_panel[, c("a_respect", "a_manner", "a_behave", "a_obedient")]) # fifth created variable -> "authoritarian"; each observation for this new variable stems from the row means of the variables "a_respect", "a_manner", "a_behave", and "a_obedient"; the function "rowMeans()" calculates the mean value across the specified columns (in this case, each specified column refers to a single variable) for each of the rows in the data set.
mean(data_panel$authoritarian) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (4): Generation of variables to measure respondent's nativism. 

data_panel$natveco <- (10 - data_panel$immigeco) / 10 # this creates a variable ranging from 0 to 1, where values closer to 1 refer to a more negative attitude towards immigrant's effect of the economy 
mean(data_panel$natveco) # CHECK: same descriptive statistics as STATA output 

data_panel$natvcult <- data_panel$immicult / 10 # second created variable "natvcult" will range from 0 10 1, where values closer to 1 indicate that respondents believe that immigrants should have the same culture and customs as natives 
mean(data_panel$natvcult) # CHECK: same descriptive statistics as STATA output 

data_panel$nativism <- rowMeans(data_panel[, c("natveco", "natvcult")]) # third created variable "nativism" referring to the row means of the variables "natveco" and "natvcult". 
mean(data_panel$nativism) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (5): Generation of variables to measure respondent's level of populism.  

# ... creation of a vector containing all the relevant variables
populism_vars <- c("populisma", "populismd", "populismf", "populismi", "populismj", "populismn")
# ... we generate a loop in order to iterate the following procedure for each of the variables in the vector "pop_vars" (created above) ...
for (var in populism_vars) {
  # ... the "paste0("ip_", var)" command will generate a new variable by appending the prefix "ip_" to the current variable name (to be able to use the "paste0()", we need the "dplyr" package)
  data_panel <- mutate(data_panel, !!paste0("ip_", var) := (get(var) - 1) / 6)
}
# ... and finally calculate the row means for each of the "ip_pop" variables and store these in a new variable called "pop6amz" ...
data_panel$pop6amz <- rowMeans(data_panel[grep("^ip_pop", names(data_panel))])
mean(data_panel$pop6amz) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (6): Generation of variables to measure territorial preferences.  

data_panel$orgterr <- (data_panel$constpref - 1) / 4 # new variable "orgterr" based on the value of "constpref" is created, ranging between 0 and 1 ... 
mean(data_panel$orgterr) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

```

``` {r Generation of Variable for Respondents' Level of Sexism}

# (1): Generation of variables to measure respondent's modern sexism. 

# ... we initially create new variables ("imsex_1a" though "imsex_9i") corresponding to the values of the already existing variable "femindexa" though "femindexi" ...
data_panel$imsex_1a <- data_panel$femindexa
data_panel$imsex_2b_t <- data_panel$femindexb
data_panel$imsex_3c <- data_panel$femindexc
data_panel$imsex_4d <- data_panel$femindexd
data_panel$imsex_5e <- data_panel$femindexe
data_panel$imsex_6f_t <- data_panel$femindexf
data_panel$imsex_7g_t <- data_panel$femindexg
data_panel$imsex_8h <- data_panel$femindexh
data_panel$imsex_9i <- data_panel$femindexi

# ... we then examine the class of the newly generated variables ...
class(data_panel$imsex_1a)
class(data_panel$imsex_2b_t)
class(data_panel$imsex_3c)
class(data_panel$imsex_4d)
class(data_panel$imsex_5e)
class(data_panel$imsex_6f_t)
class(data_panel$imsex_7g_t)
class(data_panel$imsex_8h)
class(data_panel$imsex_9i)

# ... and modify their class to ensure that they are all of the type "numeric" ...
data_panel$imsex_1a <- as.numeric(data_panel$imsex_1a)
data_panel$imsex_2b_t <- as.numeric(data_panel$imsex_2b_t)
data_panel$imsex_3c <- as.numeric(data_panel$imsex_3c)
data_panel$imsex_4d <- as.numeric(data_panel$imsex_4d)
data_panel$imsex_5e <- as.numeric(data_panel$imsex_5e)
data_panel$imsex_6f_t <- as.numeric(data_panel$imsex_6f_t)
data_panel$imsex_7g_t <- as.numeric(data_panel$imsex_7g_t)
data_panel$imsex_8h <- as.numeric(data_panel$imsex_8h)
data_panel$imsex_9i <- as.numeric(data_panel$imsex_9i)

# ... we proceed to modify the values of some of the variables "imsex_2b_t", "imsex_6f_t", "imsex_7g_t", and store the new values as "imsex_2b", "imsex_6f", and "imsex_7g" respectively. ... 
# ... we first recode "imsex_2b" ...
data_panel$imsex_2b <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_2b = case_when(
                       imsex_2b_t == 1 ~ 7, 
                       imsex_2b_t == 2 ~ 6,
                       imsex_2b_t == 3 ~ 5,
                       imsex_2b_t == 4 ~ 4,
                       imsex_2b_t == 5 ~ 3,
                       imsex_2b_t == 6 ~ 2,
                       imsex_2b_t == 7 ~ 1
                       )
                     )
# ... we then recode "imsex_6f" ...
data_panel$imsex_6f <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_6f = case_when(
                       imsex_6f_t == 1 ~ 7, 
                       imsex_6f_t == 2 ~ 6,
                       imsex_6f_t == 3 ~ 5,
                       imsex_6f_t == 4 ~ 4,
                       imsex_6f_t == 5 ~ 3,
                       imsex_6f_t == 6 ~ 2,
                       imsex_6f_t == 7 ~ 1
                       )
                     )
# ... and finally "imsex_7g" ...
data_panel$imsex_7g <- NA # we first generate an "empty" variable 
data_panel <- mutate(data_panel,
                     imsex_7g = case_when(
                       imsex_7g_t == 1 ~ 7, 
                       imsex_7g_t == 2 ~ 6,
                       imsex_7g_t == 3 ~ 5,
                       imsex_7g_t == 4 ~ 4,
                       imsex_7g_t == 5 ~ 3,
                       imsex_7g_t == 6 ~ 2,
                       imsex_7g_t == 7 ~ 1
                       )
                     )

mean(data_panel$imsex_2b) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_6f) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_7g) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_1a) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_3c) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_4d) # CHECK: same descriptive statistics as STATA output  
mean(data_panel$imsex_5e) # CHECK: same descriptive statistics as STATA output  
mean(data_panel$imsex_8h) # CHECK: same descriptive statistics as STATA output 
mean(data_panel$imsex_9i) # CHECK: same descriptive statistics as STATA output 

# ... we then compute the row mean of variables starting with the string "imsex_" and store the estimated value in a new variable called "msexism" ... 
data_panel$msexism <- rowMeans(data_panel[, c("imsex_2b", "imsex_6f", "imsex_7g","imsex_1a","imsex_3c","imsex_4d","imsex_5e","imsex_8h", "imsex_9i")])

# ... we finally rescale the newly created variable "msexism" ... 
data_panel$msexism <- (data_panel$msexism - 1) / 6
mean(data_panel$msexism) # CHECK: same descriptive statistics as STATA output 

#______________________________________________________________________________#
# (2): Variable for modern sexism according to Swim et al. (1995). 

# ... we first calculate row mean of the variables imsex_1 through imsex_8 ... 
data_panel$swim_msex <- rowMeans(data_panel[, c("imsex_1a", "imsex_2b", "imsex_3c", "imsex_4d", "imsex_5e", "imsex_6f", "imsex_7g", "imsex_8h" )])
mean(data_panel$swim_msex) #  CHECK: same descriptive statistics as STATA output 

# ... and then rescale values of the created variable "swim_msex" ...
data_panel$swim_msex <- (data_panel$swim_msex - 1) / 6
mean(data_panel$swim_msex) # CHECK: same descriptive statistics as STATA output 

```

```{r Variables for Respondents' Participation in Protests}

# ... we first dichotomize the variables "femstrike", "femdemonstrate", "feminfo", "femtalk", and generate corresponding new binary variables for each ... 
data_panel$p8m_strike <- ifelse(data_panel$femstrike == 1, 1, 0) # first variable created -> "p8m_strike"
mean(data_panel$p8m_strike, na.rm = T) # CHECK: same descriptive statistics as STATA output 
data_panel$p8m_demonst <- ifelse(data_panel$femdemonstrate == 1, 1, 0) # second variable created -> "p8m_demonst"
mean(data_panel$p8m_demonst, na.rm = T) # CHECK: same descriptive statistics as STATA output 

data_panel$p8m_mobiliz <- ifelse(data_panel$feminfo == 1, 1, 0) # third variable created -> "p8m_mobiliz"
mean(data_panel$p8m_mobiliz, na.rm = T) # CHECK: same descriptive statistics as STATA output 

data_panel$p8m_talked <- ifelse(data_panel$femtalk == 1, 1, 0) # fourth variable created -> "p8m_talked"
mean(data_panel$p8m_talked, na.rm = T) # CHECK: same descriptive statistics as STATA output 
# ... and finally estimate the row mean for each observation out of the four generated variables above ... 
data_panel$ip8m <- rowMeans(data_panel[, c("p8m_strike", "p8m_demonst", "p8m_mobiliz", "p8m_talked")])
mean(data_panel$ip8m,na.rm = T) # CHECK: same descriptive statistics as STATA output 

```

```{r Generation of Dichotomous Variables for Vote Intentions: VOX & PP}

# (1): Respondent's intended vote for the Vox-party.  

data_panel$vim_vox <- ifelse(data_panel$voteintentionspain == 23, 1, 0) # the values for the created binary variable ("vim_vox") are defined as a function of the values for the already existing variable "voteintentionspain" 
mean(data_panel$vim_vox) # CHECK: same descriptive statistics as STATA output
sd(data_panel$vim_vox) # CHECK: same descriptive statistics as STATA output

# ... and we proceed with the generation of a corresponding factor variable ...
data_panel$vim_vox_labels <- factor(data_panel$vim_vox, labels = c("Else", "Vox")) 
summary(data_panel$vim_vox_labels) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# (2): Respondent's intended vote for the PP-party. 

data_panel$vim_pp <- ifelse(data_panel$voteintentionspain == 2, 1, 0) # the values for the created binary variable ("vim_pp") are defined as a function of the values for the already existing variable "voteintentionspain" 
mean(data_panel$vim_pp) # CHECK: same descriptive statistics as STATA output

# ... and we proceed with the generation of a corresponding factor variable ...
data_panel$vim_pp_labels <- factor(data_panel$vim_pp, labels = c("Else", "PP")) 
summary(data_panel$vim_pp_labels) # CHECK: same descriptive statistics as STATA output

```

``` {r Generation of Variables for Respondents' 2016 Vote Choice}

# (1): Respondent's reported vote for the four largest parties in the 2016 election.  

# Re-code 'vote2016' into 'vr16_all' variable
data_panel$vr16_all <- ifelse(data_panel$vote2016 == 1, 1,
                        ifelse(data_panel$vote2016 == 2, 2,
                        ifelse(data_panel$vote2016 %in% c(3, 5, 25), 3,
                        ifelse(data_panel$vote2016 == 4, 4,
                        ifelse(data_panel$vote2016 %in% 1:56, 0, NA)))))
summary(data_panel$vr16_all) # CHECK: same descriptive statistics as STATA output
mean(data_panel$vr16_all, na.rm =T) # CHECK: same descriptive statistics as STATA output

data_panel$vr16_all_labels <- factor(data_panel$vr16_all, labels = c("Else", "PSOE", "PP", "Podemos", "Cs")) 
summary(data_panel$vr16_all_labels) # CHECK: same descriptive statistics as STATA output

```

``` {r Generation of Variables Vote Choices}

# Generate 'vr16_17' and 'vr16_18' variables for the years 2017 and 2018 - this is because the vote choice was only asked in the 2017 and 2018 waves ...
data_panel$vr16_17 <- ifelse(data_panel$year == 2017, data_panel$vr16_all, NA_integer_)
mean(data_panel$vr16_17, na.rm=T) # CHECK: same descriptive statistics as STATA output

data_panel$vr16_18 <- ifelse(data_panel$year == 2018, data_panel$vr16_all, NA_integer_)
mean(data_panel$vr16_18, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... we proceed to generate the 'vr16_17a' and 'vr16_18a' variables by taking the maximum for value of "vr16_17" and "vr16_18" for each respondent ... 
data_panel <- data_panel %>%
  group_by(idcode) %>%
  mutate(vr16_17a = ifelse(all(is.na(vr16_17)), NA_integer_, max(vr16_17, na.rm = TRUE)),
         vr16_18a = ifelse(all(is.na(vr16_18)), NA_integer_, max(vr16_18, na.rm = TRUE)))
mean(data_panel$vr16_17a, na.rm=T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$vr16_18a, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... we generate the 'v16all' variable based with the same values as "vr16_17a" ...
data_panel$v16all <- data_panel$vr16_17a
mean(data_panel$v16all, na.rm=T) # CHECK: same descriptive statistics as STATA output

# ... and continue with replacing the values in "v16all" with values from "vr16_18a" based on conditions ...
condition <- (data_panel$vr16_17a == 0 | is.na(data_panel$vr16_17a)) & !is.na(data_panel$vr16_18a)
data_panel$v16all[condition] <- data_panel$vr16_18a[condition]
mean(data_panel$v16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... and we then re-code the 'v16all' variable and store the new coding scheme in a new variable called "rv16all" ...
data_panel$v16all_t <- data_panel$v16all
data_panel$rv16all <- NA # we first generate an "empty" variable 

data_panel <- mutate(data_panel,
                     rv16all = case_when(
                       v16all == 0 ~ 4, 
                       v16all == 1 ~ 1,
                       v16all == 2 ~ 0,
                       v16all == 3 ~ 2,
                       v16all == 4 ~ 3)
                     )

mean(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output
sd(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$rv16all_labels <- factor(data_panel$rv16all, labels = c("PP", "PSOE", "Podemos", "Ciudadanos", "Others")) 
summary(data_panel$rv16all_labels) # CHECK: same descriptive statistics as STATA output

# ... and we finalize by eliminating variables that will no longer be used ... 
data_panel <- select(data_panel, -starts_with("vr16_all"), 
                                 -starts_with("v16all"), 
                                 -starts_with("vr16_17"), 
                                 -starts_with("vr16_18"))

mean(data_panel$rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

```

```{r Generation of Time-invariant Variables}

# Creation of time-invariant variables fixed at their 2017/2018 values - these generated variables are used in the multilevel growth-curve models. 

# ... we define the variables that will be used ...
selected_variables <- c("edu3", "x3hincall", "dintpol", "ideo5", "rv16all")

# ... and loop through each of the selected variables ... 
for (var in selected_variables) {
  # ... we subset the data for nwaves == 4 and the variable is not missing ...
  subset_data <- subset(data_panel, nwaves == 4 & !is.na(data_panel[[var]]))
  
  # ... and then get the first value for each "idcode" ...
  first_values <- tapply(subset_data[[var]], subset_data$idcode, function(x) x[1])
  
  # ... we finally merge the first values back into the main dataframe ...
  data_panel[paste0("t1", var)] <- first_values[match(data_panel$idcode, names(first_values))]
}

# ... we inspect the newly created variable to ensure same results as in the original STATA output...
mean(data_panel$t1edu3, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1dintpol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1x3hincall, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1ideo5, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$t1rv16all, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we continue with the generation of the variable "t2partner"; for this purpose, the following steps are conducted (A - D): 
# A > ... we sort the data by "icode" and "year" ...
sorted_data <- data_panel %>% arrange(idcode, year)
# B > ... we then filter the data to include only those observations for which nwaves == 4 ...
filtered_data <- sorted_data %>% filter(nwaves == 4)
# C > ... we then group by "idcode" and create a new variable "t2partner" with the value from the second observation ...
t2partner_data <- filtered_data %>%
  group_by(idcode) %>%
  mutate(t2partner = nth(livingpartner, 2)) %>%
  ungroup()
# D > ... we finally merge the "t2partner" from the filtered data frame column back to the original data frame ("data_panel") ...
data_panel <- merge(data_panel, t2partner_data[, c("idcode", "year", "t2partner")], by = c("idcode", "year"), all.x = TRUE)
#DOESN'T WORK OUT AS THESE VARIABLES OVERLAP 

mean(t2partner_data$t2partner, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we proceed with the generation of the variable "t2ip8m" following the same steps (A - D) as above: 
# A > ...
sorted_data_2<- data_panel %>% arrange(idcode, year)
# B > ...
filtered_data_2 <- sorted_data_2 %>% filter(nwaves == 4)
# C > ...
t2ip8m_data <- filtered_data_2 %>%
  group_by(idcode) %>%
  mutate(t2ip8m = nth(ip8m, 2)) %>%
  ungroup()
# D > ...
data_panel <- merge(data_panel, t2ip8m_data[, c("idcode", "year", "t2ip8m")], by = c("idcode", "year"), all.x = TRUE)

mean(data_panel$t2ip8m, na.rm = T) # CHECK: same descriptive statistics as STATA output

#______________________________________________________________________________#
# ... we then assign labels to the following variables ...

attr(data_panel$t2partner, "label") <- "Lives with partner"
attr(data_panel$t2ip8m, "label") <- "Women's Day protest engagement"
t1edu3_labels <- c("1" = "Lower 2ry", "2" = "Upper 2ry", "3" = "3ry")
    attr(data_panel$t1edu3, "labels") <- t1edu3_labels
t2partner_labels <- c("1" = "Yes", "0" = "No")
    attr(data_panel$t2partner, "labels") <- t2partner_labels
t1x3hincall_labels <- c("1" = "Low", "2" = "Mid", "3" = "High")
    attr(data_panel$t1x3hincall, "labels") <- t1x3hincall_labels
t1dintpol_labels <- c("0" = "Low", "1" = "High")
    attr(data_panel$t1dintpol, "labels") <- t1dintpol_labels
t1ideo5_labels <- c("1" = "Far left", "2" = "Left", "3" = "Center", "4" = "Right", "5" = "Far right")
    attr(data_panel$t1ideo5, "labels") <- t1ideo5_labels
    
#______________________________________________________________________________#
#... we finalize by removing the generated reference data frames ...

rm(filtered_data, 
   filtered_data_2, 
   sorted_data, 
   sorted_data_2, 
   t2ip8m_data, 
   t2partner_data,
   subset_data
   )
    
```

```{r Generation of Lagged and Change Variables}
#______________________________________________________________________________#
data_panel <- data_panel[order(data_panel$idcode), ]
#______________________________________________________________________________#

# (1): Creation of lagged variables. 

# ... we first define a vector containing all the variables that will be used ...
set_variables <- c("vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism", "swim_msex")

# ... we repeat the same procedure for each unique respondent ("idcode") ...
for (id in unique(data_panel$idcode)) {
  
  # ... we check if there are at least three observations for the same respondent (this is to ensure a lag of two periods) ...
  if (sum(data_panel$idcode == id) >= 3) {
    # Loop through each variable
    for (var in set_variables) {
      lagged_var <- paste0("l2", var)  # Lagged variable name
      
      # ... we calculate the corresponding lagged variable ...
      lagged_values <- c(rep(NA, 2), head(data_panel[data_panel$idcode == id, var], -2))
      data_panel[data_panel$idcode == id, lagged_var] <- lagged_values
    }
  } else {
    # ... if there are less than three observations for a given respondent, we assign a missing value (NA) to the corresponding lagged variable ...
    for (var in set_variables) {
      lagged_var <- paste0("l2", var)  # Lagged variable name
      data_panel[data_panel$idcode == id, lagged_var] <- NA
    }
  }
}

# .............................................................................#
# IMPUTATION 4 - "Lagged Variables"
# ... given minimal differences between the generated and the "original" lagged variables for the defined set of covariates, and in order to ensure that the new (lagged) variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output, "overwriting" minor coding differences between both ...
# ... we first load the relevant STATA-output ...
STATA_REF2 <- read_stata("STATA_Reference2.dta") 
 # ... the following commands generate a series of data frames ("reference4a_STATA" -> "reference4h_STATA") containing the lagged variables from the original STATA output ... 
reference4a_STATA <- STATA_REF2[, c("l2vim_vox")]
reference4b_STATA <- STATA_REF2[, c("l2authoritarian")]
reference4c_STATA <- STATA_REF2[, c("l2ideol")]
reference4d_STATA <- STATA_REF2[, c("l2nativism")]
reference4e_STATA <- STATA_REF2[, c("l2orgterr")]
reference4f_STATA <- STATA_REF2[, c("l2pop6amz")]
reference4g_STATA <- STATA_REF2[, c("l2msexism")]
reference4h_STATA <- STATA_REF2[, c("l2swim_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$l2vim_vox <- reference4a_STATA$l2vim_vox
data_panel$l2authoritarian <- reference4b_STATA$l2authoritarian
data_panel$l2ideol <- reference4c_STATA$l2ideol
data_panel$l2nativism <- reference4d_STATA$l2nativism
data_panel$l2orgterr <- reference4e_STATA$l2orgterr
data_panel$l2pop6amz <- reference4f_STATA$l2pop6amz
data_panel$l2msexism <- reference4g_STATA$l2msexism
data_panel$l2swim_msex <- reference4h_STATA$l2swim_msex

# ... we finally inspect the added variables ...
mean(data_panel$l2vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2pop6, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$l2swim_msex, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects ...
rm(list = c("reference4a_STATA", 
            "reference4b_STATA", 
            "reference4c_STATA", 
            "reference4d_STATA", 
            "reference4e_STATA", 
            "reference4f_STATA", 
            "reference4g_STATA", 
            "reference4h_STATA")
   )
#..............................................................................#

# (2): Creation of Change Variables. 
# .............................................................................#
# IMPUTATION 5 - "Change Variables"
# ... in order to ensure that the change variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
 # ... the following command generates a data frame containing the change variables from the original STATA output ... 
reference5a_STATA <- STATA_REF2[, c("lsvim_vox")]
reference5b_STATA <- STATA_REF2[, c("lsauthoritarian")]
reference5c_STATA <- STATA_REF2[, c("lsideol")]
reference5d_STATA <- STATA_REF2[, c("lsnativism")]
reference5e_STATA <- STATA_REF2[, c("lsorgterr")]
reference5f_STATA <- STATA_REF2[, c("lspop6amz")]
reference5g_STATA <- STATA_REF2[, c("lsmsexism")]
reference5h_STATA <- STATA_REF2[, c("lsswim_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lsvim_vox <- reference5a_STATA$lsvim_vox
data_panel$lsauthoritarian <- reference5b_STATA$lsauthoritarian
data_panel$lsideol <- reference5c_STATA$lsideol
data_panel$lsnativism <- reference5d_STATA$lsnativism
data_panel$lsorgterr <- reference5e_STATA$lsorgterr
data_panel$lspop6amz <- reference5f_STATA$lspop6amz
data_panel$lsmsexism <- reference5g_STATA$lsmsexism
data_panel$lsswim_msex <- reference5h_STATA$lsswim_msex

# ... we finally inspect the added variables ...
mean(data_panel$lsvim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsauthoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsnativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsorgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lspop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsmsexism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lsswim_msex, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects ...
rm(list = c("reference5a_STATA", 
            "reference5b_STATA", 
            "reference5c_STATA", 
            "reference5d_STATA", 
            "reference5e_STATA", 
            "reference5f_STATA", 
            "reference5g_STATA", 
            "reference5h_STATA",
            "STATA_REF2")
   )

#..............................................................................#

```

```{r Generation of Variables for Positive and Negative (lagged) change in sexism (for both "extended" and "original" modern sexism)}

# (1): Generation of variables for positive and negative (lagged) change in sexism (extended and original/modern).  

data_panel$posmsex <- data_panel$lsmsex * (data_panel$lsmsex > 0)
mean(data_panel$posmsex, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$negmsex <- data_panel$lsmsex * (data_panel$lsmsex < 0)
mean(data_panel$negmsex, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$posswim <- data_panel$lsswim_msex * (data_panel$lsmsex > 0)
mean(data_panel$posswim, na.rm = T) # CHECK: same descriptive statistics as STATA output

data_panel$negswim <- data_panel$lsswim_msex * (data_panel$lsmsex < 0)
mean(data_panel$negswim, na.rm = T) # CHECK: same descriptive statistics as STATA output

```

```{r Generation of Labels for Relevant Variables}

# Assignment of labels to variables in the dataset 
label(data_panel$female) <- "Female"
label(data_panel$age) <- "Age"
label(data_panel$cohort) <- "Cohort"
label(data_panel$edu3) <- "Education"
label(data_panel$livingpartner) <- "Lives with partner"
label(data_panel$dhincome_all) <- "Income"
label(data_panel$intpol) <- "Interest in politics"
label(data_panel$ideol) <- "Ideological identification"
label(data_panel$authoritarian) <- "Authoritarianism"
label(data_panel$pop6amz) <- "Populism"
label(data_panel$nativism) <- "Nativism"
label(data_panel$orgterr) <- "Territorial preference"
label(data_panel$msexism) <- "Sexism"
label(data_panel$swim_msex) <- "Sexism"
label(data_panel$vim_vox) <- "Vox intention"
label(data_panel$vim_pp) <- "PP intention"
label(data_panel$g3cohort) <- "Cohort"
label(data_panel$t1edu3) <- "Education (ref. Lower 2ry or less)"
label(data_panel$t1ideo5) <- "Ideological identification (ref. Far left)"
label(data_panel$t2partner) <- "Lives with partner"
label(data_panel$t1x3hincall) <- "Income (ref. Low)"
label(data_panel$t1dintpol) <- "Interest in politics"
label(data_panel$t1rv16all) <- "Vote in 2016 (ref. PP)"

```

``` {r Generation of Dummy Variables for Respondent's Vote Intention}

# The generated dummy variables have the purpose of representing the respondent's vote alternatives in a trichotomous way. The conceptualized choice-scenario depicted by the generated variables is the following: 
# - Respondent (does not intend) intends to vote for VOX  -> "intention_vox" equals (0) 1. 
# - Respondent (does not intend) intends to vote for another party  -> "intention_other" equals (0) 1. 
#    - Respondent (does not intend) intends to vote -> "intention_novote" equals (0) 1. 

#______________________________________________________________________________#
# (1): We first start by generating a more "fined-grained" version of the variable "voteintentionspain", where respondents indicating that (i) they don't know for which party they would vote or (ii) they would not vote for any of the indicated parties are treated as missings. 
# ... we first define the values in "voteintentionspain" that will be treated as missings; 54 for the answer "Don't know" and 55 for "None" ... 
missing_values <- c(54, 55)

# ... we then create a duplicate of the variable variable "voteintentionspain" where the values defined above are coded as missing values for the duplicate/new variable ...
data_panel$voteintentionspain_redef <- ifelse(data_panel$voteintentionspain %in% missing_values, NA, data_panel$voteintentionspain)

#______________________________________________________________________________#
# (1): Generation of Variable for Respondent's intended vote for the Vox-party - "intention_vox"
data_panel$intention_vox <- ifelse(data_panel$voteintentionspain_redef == 23, 1, 0) # this variable is identical to the previously generated variable "vim_vox"

#______________________________________________________________________________#
# (2): Generation of Variable for Respondent's intended vote for other parties - "intention_other"
data_panel$intention_other <- ifelse(data_panel$voteintentionspain_redef %in% c(23, 51, 52, 53), 0, 1)

#______________________________________________________________________________#
# (3): Generation of Variable for Respondent's intention not to vote - "intention_novote"

# ... we finalize by defining the values of "voteintentionspain_redef" that indicate a respondent having the intention ob abstaining from casting a vote. More specifically, the values that will be grouped into the "intention not to vote" category are the following: 
#      voteintentionspain_redef = 51  -> respondent intends to cast a blank vote         
#      voteintentionspain_redef = 52  -> respondent intends to cast a null vote  
#      voteintentionspain_redef = 53  -> respondent openly intends not to vote
novote_values <- c(51, 52, 53)
# ... we then proceed to generate the variable "intention_novote" ...
data_panel$intention_novote <- ifelse(data_panel$voteintentionspain_redef %in% novote_values, 1,0)

```

## Replication of the Paper's Original Results 

This section has the main purpose of replicating the original findings of the presented in the paper "Sexism and the far-right vote: The individual dynamics of gender backlash". Even though the original results will not form part of our contribution, the replication of these will allow us to assess the following aspects: 
                 1. Inspect the correctness of the conducted data preparation 
                 2. Ensure the functionality of the written log-likelihood functions 

This part consists of two sub-sections. The first sub-section replicates the paper's original findings reported in Table 1. The second sub-section replicates the paper's Table 2. 

### Replication of the Paper's Original Results: Table 1

This initial part has the following sub-sections: 
    - Part 1.1: Defines the Log-Likelihood Function that will be used to estimate the models
    - Part 1.2: Defines the dependent and independent variables for the replication of Table 1 (Models 1 and 2)
    - Part 1.3: Optimization of the corresponding Log-Likelihood Functions given the defined inputs (dependent and independent variables)
    - Part 1.4: Display and Visualization of the Regression Results

``` {r Part 1.1: Definition of Logit-Log-Likelihood Function}

# It is important to note that this same Log-Likelihood Function will be used in the replication of Table 1 as well as in that of Table 2. 

# ... we then define the Log-Likelihood function, which will be named "LL_logit" ...
LL_logit <- function(theta, y, X) {            # definition of the function's inputs 

    beta <- theta[1:ncol(X)]
    # definition of linear predictor "mu" ...
    mu <- X %*% beta
    # definition of logit-link function ...
    p <- 1/(1 + exp(-mu)) 
    # we conclude by defining the log-likelihood function ...
    ll <- y * log(p) + (1 - y) * log(1 - p)
    ll <- sum(ll)
    return(ll)
}

```

``` {r Part 1.2: Definition of Dependent and Independent Variables}

# We define the set of dependent and independent variables needed to replicate Table 1's findings; we apply a separate procedure for each of the two models ...

# .............................................................................#
# .............................. MODEL 1 (2019) .............................. #
# .............................................................................#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...

variables_re_T1  <- c("female",                  
                      "age",                    
                      "edu3_2",                 
                      "edu3_3",                 
                      "dhincome_all",           
                      "livingpartner",          
                      "intpol",                 
                      "authoritarian",          
                      "ideol",                  
                      "nativism",               
                      "orgterr",                
                      "pop6amz",                
                      "msexism",                
                      "vim_vox",
                      "year")

# ... we then generate a data subset ("data_panel2") containing the independent variables as defined by the vector "variables_re_T1", in addition to the dependent variable "vim_vox" ...
data_panel2 <- na.omit(data_panel[, c(variables_re_T1, "vim_vox")])

# ... and subsequently create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2019 ...
rep_m1_T1 <- subset(data_panel2,year == 2019) 

# ... we first define the dependent variable (intended vote for Vox at time "t" - "vim_vox") ...
rep_m1_T1$vim_vox <- as.numeric(rep_m1_T1$vim_vox) # we make sure that the DV is numeric 
Y_rm1_T1 <- rep_m1_T1$vim_vox
Y_rm1_T1 <- as.numeric(Y_rm1_T1) # we store the resulting Y-vector as a numeric vector

# ... and proceed to define the set of independent variables ...
independent_variables_rm1_T1  <- c("female",
                                   "age",
                                   "edu3_2",
                                   "edu3_3",
                                   "dhincome_all",
                                   "livingpartner",
                                   "intpol",
                                   "authoritarian",
                                   "ideol",
                                   "nativism",
                                   "orgterr",
                                   "pop6amz",
                                   "msexism"
                                   )

independent_variables_m1 <- rep_m1_T1[, independent_variables_rm1_T1]
X_rm1_T1 <- cbind(1, independent_variables_m1)
X_rm1_T1 <- as.matrix(sapply(X_rm1_T1, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# .............................. MODEL 2 (2020) .............................. #
# .............................................................................#

# ... repeating the same procedure from above, we create a subset of the data frame "data_panel2" containing only observations for which the value of "year" is 2020 ...
rep_m2_T1 <- subset(data_panel2,year == 2020) 

# ... we then define the dependent variable (intended vote for Vox) ...
rep_m2_T1$vim_vox <- as.numeric(rep_m2_T1$vim_vox) # we make sure that the DV is numeric 
Y_rm2_T1 <- rep_m2_T1$vim_vox
Y_rm2_T1 <- as.numeric(Y_rm2_T1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables (we use the same vector as for model 1, but only modify its name) ...
independent_variables_rm2_T1  <- independent_variables_rm1_T1
independent_variables_m2 <- rep_m2_T1[, independent_variables_rm2_T1]
X_rm2_T1 <- cbind(1, independent_variables_m2)
X_rm2_T1 <- as.matrix(sapply(X_rm2_T1, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

```

``` {r Part 1.3: Optimization of Logit-Log-Likelihood Function}

# Using the Log-Likelihood Function we defined earlier, we now proceed to conduct the appropriate optimization procedures using the y-Vectors and Covariate matrices generated in the previous steps. The results will correspond to the value of the parameters that maximize the value of the Log-Likelihood function and are thus more likely to have produced the given data. 

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm1_T1 <- rep(0,14) # Covariates + Intercept yields a total of 14 parameter 

# ... and implement an initial optimization ...
res1_rm1_T1 <- optim(par = startvalues1_rm1_T1,
             fn = LL_logit,
             y = Y_rm1_T1,
             X = X_rm1_T1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization of the Logit-Log-Likelihood function; the starting values are now set to the rounded values obtained as a result of the first optimization. The purpose of this second optimization is to ensure that the parameters yielded are indeed maximizing the Log-Likelihood function ...
startvalues2_rm1_T1 <- round(res1_rm1_T1$par,10) # ... we define the starting values ...

# ... and implement an initial optimization ...
res2_rm1_T1 <- optim(par= startvalues2_rm1_T1,
             fn = LL_logit,
             y = Y_rm1_T1,
             X = X_rm1_T1,
             control=list(parscale=abs(res1_rm1_T1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... having conducted the second optimization, we return the point estimates and store these in an object ...
point_estimates_rm1_T1 <- res2_rm1_T1$par[1:14]

# ... we proceed with the estimation of the standard errors ...
SE_rm1_T1 <- sqrt(diag(solve(-res2_rm1_T1$hessian)))

# ... and furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the obtained coefficients) ...
P_Values_rm1_T1 <- 2 * (1 - pnorm(abs(point_estimates_rm1_T1 / SE_rm1_T1)))

# ... we additionally extract the number of observations for the model...
N_rm1_T1 <- length(Y_rm1_T1)

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... for Model 2, the same procedure as for Model 1 is conducted. The only difference is that a different Y-vector and X-Matrix are used as inputs for the optimization of the Log-Likelihood function. 

# ... we initiate by defining the starting values ...
startvalues1_rm2_T1 <- rep(0,14)

## ... and implement an initial optimization ...
res1_rm2_T1 <- optim(par = startvalues1_rm2_T1,
             fn = LL_logit,
             y = Y_rm2_T1,
             X = X_rm2_T1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm2_T1 <- round(res1_rm2_T1$par,10) # ... we define the starting values ...

# ... and carry out the second optimization procedure ...
res2_rm2_T1 <- optim(par= startvalues2_rm2_T1,
             fn = LL_logit,
             y = Y_rm2_T1,
             X = X_rm2_T1,
             control=list(parscale=abs(res1_rm2_T1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we then return the point estimates...
point_estimates_rm2_T1 <- res2_rm2_T1$par[1:14]

# ... and also estimate the standard errors ...
SE_rm2_T1 <- sqrt(diag(solve(-res2_rm2_T1$hessian)))

# ... we furthermore include the calculation of the corresponding p-values ...
P_Values_rm2_T1 <- 2 * (1 - pnorm(abs(point_estimates_rm2_T1 / SE_rm2_T1)))

# ... and the number of observations ...
N_rm2_T1 <- length(Y_rm2_T1)

```

```{r Part 1.4: Display and Visualization of Regression Results}

# Having obtained the values for the parameters of interest, this part generates a nice-looking table to display the results of the two logistic regressions. Together, the two presented models constitute the final replication of Table 1. 

library(knitr) # ... we need the "knitr" to be able to generate the tables ...

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we first define the point estimates, standard errors, and p-values for Model 1 ...
results_rm1_T1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Authoritarianism",
                   "Ideological identification",
                   "Nativism",
                   "Territorial preference",
                   "Populism",
                   "Sexism" ),
  
  Point_Estimates = point_estimates_rm1_T1,
  Standard_Errors = SE_rm1_T1,
  P_Values = P_Values_rm1_T1,
  Observations = N_rm1_T1 )

# ... we finally print the formatted table ...
kable(results_rm1_T1, 
      align = "c", 
      digits = 3, 
      caption = "Results Replication Model 1 (Table 1)", 
      col.names = c("Variables", "Point Estimates", "Standard Errors", "P-Values", "N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... we now proceed with generating a table to display the results for Model 2 ...
# ... we first define the point estimates, standard errors, and p-values ...
results_rm2_T1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Authoritarianism",
                   "Ideological identification",
                   "Nativism",
                   "Territorial preference",
                   "Populism",
                   "Sexism" ),
  
  Point_Estimates = point_estimates_rm2_T1,
  Standard_Errors = SE_rm2_T1,
  P_Values = P_Values_rm2_T1,
  Observations = N_rm2_T1 )

# ... we then print the table ...
kable(results_rm2_T1, 
      align = "c", 
      digits = 3, 
      caption = "Results Replication Model 2 (Table 1)",
      col.names = c("Variables", 
                    "Point Estimates", 
                    "Standard Errors", 
                    "P-Values", 
                    "N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ........................ Joint Display MODELS 1 & 2 .........................#
# .............................................................................#

# ... we define a function to append significance stars based on the estimated P-values ...
add_stars <- function(coef, pval) {
  if (pval < 0.01) {
    return(paste0(coef, "***"))
  } else if (pval < 0.05) {
    return(paste0(coef, "**"))
  } else if (pval < 0.1) {
    return(paste0(coef, "*"))
  } else {
    return(as.character(coef))
  }
}

# ... we proceed to add the corresponding stars to coefficients ...
Point_Estimates_rm1_T1_stars <- mapply(add_stars, round(point_estimates_rm1_T1, 3), P_Values_rm1_T1)
Point_Estimates_rm2_T1_stars <- mapply(add_stars, round(point_estimates_rm2_T1, 3), P_Values_rm2_T1)

# we thn combine point estimates with SE ...
output_1 <- cbind(Point_Estimates_rm1_T1_stars, round(SE_rm1_T1, 3))
colnames(output_1) <- c('Coefficients - 2019', 'SE')
rownames(output_1) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Authoritarianism",
                        "Ideological identification",
                        "Nativism",
                        "Territorial preference",
                        "Populism",
                        "Sexism")

output_2 <- cbind(Point_Estimates_rm2_T1_stars, round(SE_rm2_T1, 3))
colnames(output_2) <- c('Coefficients - 2020', 'SE')
rownames(output_2) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Authoritarianism",
                        "Ideological identification",
                        "Nativism",
                        "Territorial preference",
                        "Populism",
                        "Sexism")

# ... we then combine the two columns ...
unified_table_1 <- cbind(output_1, output_2)

# ... create a row for the number of observations for each model ...
n_observations <- c(N_rm1_T1, "", N_rm2_T1, "")

# ... and append the number of observations row to the unified table ...
unified_table_1 <- rbind(unified_table_1, "N" = n_observations)

# ... we finalize by printing the generated table...
kable(unified_table_1, 
      digits = 3, 
      align = "ccrl",
      booktabs = TRUE,
      caption = "Predictors of Intention to Vote for Vox in 2019 and 2020") %>%
  kable_styling(full_width = FALSE)

#______________________________________________________________________________#
# ... this last section generates the La-Tex corresponding to Table 1 ...
Replication_Table_1 <- kable(unified_table_1, 
                             digits = 3, 
                             align = "ccrl",
                             booktabs = TRUE, 
                             format = "latex",
                             caption = "Predictors of Intention to Vote for Vox in 2019 and 2020") %>%
  kable_styling(full_width = FALSE)

# ... print the La-TeX code to the console ...
cat(Replication_Table_1)
#______________________________________________________________________________#

```

### Replication of the Paper's Original Results: Table 2

This initial part has the following sub-sections: 
    - Part 2.1: Defines the dependent and independent variables for the replication of Table 2 (Models 1 and 2)
    - Part 2.2: Optimization of the corresponding Log-Likelihood Functions given the defined inputs (dependent and independent variables)
    - Part 2.3: Display and Visualization of the Regression Results

``` {r Part 2.1: Definition of Dependent and Independent Variables}

# We define the set of dependent and independent variables; we apply a separate procedure for each of the four models presented in the original paper ...

# .............................................................................#
# .............................. MODEL 1 (2019) .............................. #
# .............................................................................#

#______________________________________________________________________________#

# IMPUTATION 5 - "Lagged Variables by one Period (t-1) for 2019"

# ... We first have to implement an additional data-preparation procedure and generate lagged variables (lagged by one period) for the following covariates: "vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism" ...
# ... in order to ensure that the lagged variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
# ... we first load the relevant STATA-output ...
STATA_REF3 <- read_stata("STATA_Reference3.dta") 
 # ... the following commands generate a series of data frames ("reference6a_STATA" -> "reference6g_STATA") containing the relevant lagged variables from the original STATA output ... 
reference6a_STATA <- STATA_REF3[, c("l_vim_vox")]
reference6b_STATA <- STATA_REF3[, c("l_authoritarian")]
reference6c_STATA <- STATA_REF3[, c("l_ideol")]
reference6d_STATA <- STATA_REF3[, c("l_nativism")]
reference6e_STATA <- STATA_REF3[, c("l_orgterr")]
reference6f_STATA <- STATA_REF3[, c("l_pop6")]
reference6g_STATA <- STATA_REF3[, c("l_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lm1_vim_vox <- reference6a_STATA$l_vim_vox
data_panel$lm1_authoritarian <- reference6b_STATA$l_authoritarian
data_panel$lm1_ideol <- reference6c_STATA$l_ideol
data_panel$lm1_nativism <- reference6d_STATA$l_nativism
data_panel$lm1_orgterr <- reference6e_STATA$l_orgterr
data_panel$lm1_pop6amz <- reference6f_STATA$l_pop6
data_panel$lm1_msexism <- reference6g_STATA$l_msex

# ... we finally inspect the added variables ...
mean(data_panel$lm1_vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_pop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm1_msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output
#______________________________________________________________________________#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...
variables_re_m1T2  <- c("female",                
                        "age",                  
                        "edu3_2",               
                        "edu3_3",               
                        "dhincome_all",         
                        "livingpartner",        
                        "intpol",               
                        "lm1_vim_vox",          
                        "lm1_authoritarian",    
                        "lm1_ideol",            
                        "lm1_nativism",         
                        "lm1_orgterr",          
                        "lm1_pop6amz",          
                        "lm1_msexism",          
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel3") containing the independent variables as defined by the vector "variables_re_m1T2", in addition to the dependent variable "vim_vox" ...
data_panel3 <- na.omit(data_panel[, c(variables_re_m1T2)])

# ... and subsequently create a subset of the data frame "data_panel3" containing only observations for which the value of "year" is 2019 ...
rep_m1_T2 <- subset(data_panel3, year == 2019) 

# ... we first a vector containing the dependent variable ("vim_vox") ...
rep_m1_T2$vim_vox <- as.numeric(rep_m1_T2$vim_vox) # we make sure that the DV is numeric 
Y_rm1_T2 <- rep_m1_T2$vim_vox
Y_rm1_T2 <- as.numeric(Y_rm1_T2) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables...
independent_variables_rm1_T2  <- c("female",                 
                                   "age",                    
                                   "edu3_2",                 
                                   "edu3_3",                 
                                   "dhincome_all",           
                                   "livingpartner",          
                                   "intpol",                 
                                   "lm1_vim_vox",            
                                   "lm1_authoritarian",        
                                   "lm1_ideol",                
                                   "lm1_nativism",             
                                   "lm1_orgterr",              
                                   "lm1_pop6amz",              
                                   "lm1_msexism")

independent_variables_m1 <- rep_m1_T2[, independent_variables_rm1_T2]
X_rm1_T2 <- cbind(1, independent_variables_m1)
X_rm1_T2 <- as.matrix(sapply(X_rm1_T2, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

# .............................................................................#
# .............................. MODEL 2 (2020) .............................. #
# .............................................................................#

#______________________________________________________________________________#

# IMPUTATION 6 - "Lagged Variables by one Period (t-1) for 2020"

# ... We first have to implement an additional data-preparation procedure and generate lagged variables (lagged by one period) for the following covariates: "vim_vox", "authoritarian", "ideol", "nativism", "orgterr", "pop6amz", "msexism" ...
# ... in order to ensure that the lagged variables are exactly the same as in the original STATA-output, we append the corresponding columns from the original STATA output ...
 # ... the following commands generate a series of data frames ("reference7a_STATA" -> "reference7g_STATA") containing the relevant lagged variables from the original STATA output ... 
reference7a_STATA <- STATA_REF3[, c("l_2020_vim_vox")]
reference7b_STATA <- STATA_REF3[, c("l_2020_authoritarian")]
reference7c_STATA <- STATA_REF3[, c("l_2020_ideol")]
reference7d_STATA <- STATA_REF3[, c("l_2020_nativism")]
reference7e_STATA <- STATA_REF3[, c("l_2020_orgterr")]
reference7f_STATA <- STATA_REF3[, c("l_2020_pop6")]
reference7g_STATA <- STATA_REF3[, c("l_2020_msex")]

# ... we then append the columns from the original STATA-output into our main data frame ...
data_panel$lm2_vim_vox <- reference7a_STATA$l_2020_vim_vox
data_panel$lm2_authoritarian <- reference7b_STATA$l_2020_authoritarian
data_panel$lm2_ideol <- reference7c_STATA$l_2020_ideol
data_panel$lm2_nativism <- reference7d_STATA$l_2020_nativism
data_panel$lm2_orgterr <- reference7e_STATA$l_2020_orgterr
data_panel$lm2_pop6amz <- reference7f_STATA$l_2020_pop6
data_panel$lm2_msexism <- reference7g_STATA$l_2020_msex

# ... we finally inspect the added variables ...
mean(data_panel$lm2_vim_vox, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_authoritarian, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_ideol, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_nativism, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_orgterr, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_pop6amz, na.rm = T) # CHECK: same descriptive statistics as STATA output
mean(data_panel$lm2_msexism, na.rm = T) # CHECK: same descriptive statistics as STATA output

# ... we finalize the procedure by eliminating the created reference objects. The purpose of this step is to "clean" the working environment by getting rid of objects that will, not be used anymore ...
rm(list = c("reference6a_STATA", 
            "reference6b_STATA", 
            "reference6c_STATA", 
            "reference6d_STATA", 
            "reference6e_STATA", 
            "reference6f_STATA", 
            "reference6g_STATA", 
            "reference7a_STATA", 
            "reference7b_STATA", 
            "reference7c_STATA", 
            "reference7d_STATA", 
            "reference7e_STATA", 
            "reference7f_STATA", 
            "reference7g_STATA",
            "STATA_REF3")
   )

#______________________________________________________________________________#

# ... we define a vector containing the names of all the variables (as stored in the main data frame) that will be used for the estimation of the model ...
variables_re_m2T2  <- c("female",                 
                        "age",                  
                        "edu3_2",               
                        "edu3_3",               
                        "dhincome_all",         
                        "livingpartner",        
                        "intpol",               
                        "lm2_vim_vox",          
                        "lm2_authoritarian",    
                        "lm2_ideol",            
                        "lm2_nativism",         
                        "lm2_orgterr",          
                        "lm2_pop6amz",          
                        "lm2_msexism",          
                        "vim_vox",
                        "year")

# ... we then generate a data subset ("data_panel4") containing the independent variables as defined by the vector "variables_re_m2T2", in addition to the dependent variable ...
data_panel4 <- na.omit(data_panel[, c(variables_re_m2T2)])

# ... and subsequently create a subset of the data frame "data_panel4" containing only observations for which the value of "year" is 2020 ...
rep_m2_T2 <- subset(data_panel4, year == 2020) 

# ... we then define the dependent variable ...
rep_m2_T2$vim_vox <- as.numeric(rep_m2_T2$vim_vox) # we make sure that the DV is numeric 
Y_rm2_T2 <- rep_m2_T2$vim_vox
Y_rm2_T2 <- as.numeric(Y_rm2_T2) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables ...
independent_variables_rm2_T2  <- c("female",                 
                                   "age",                    
                                   "edu3_2",                 
                                   "edu3_3",                 
                                   "dhincome_all",           
                                   "livingpartner",          
                                   "intpol",                 
                                   "lm2_vim_vox",            
                                   "lm2_authoritarian",        
                                   "lm2_ideol",                
                                   "lm2_nativism",             
                                   "lm2_orgterr",              
                                   "lm2_pop6amz",              
                                   "lm2_msexism")


independent_variables_m2 <- rep_m2_T2[, independent_variables_rm2_T2]
X_rm2_T2 <- cbind(1, independent_variables_m2)
X_rm2_T2 <- as.matrix(sapply(X_rm2_T2, as.numeric)) # we make sure that the matrix X is indeed saved as a matrix

```

``` {r Part 2.2: Optimization of Logit-Log-Likelihood Function}

# Using the Log-Likelihood Function we defined earlier, we now proceed to conduct the appropriate optimization procedures using the y-Vectors and Covariate matrices generated in the previous steps. 

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_rm1_T2 <- rep(0,15) # Covariates + Intercept yields a total of 15 parameter 

## ... and implement an initial optimization ...
res1_rm1_T2 <- optim(par = startvalues1_rm1_T2,
             fn = LL_logit,
             y = Y_rm1_T2,
             X = X_rm1_T2,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... as before, we conduct a second optimization of the Logit-Log-Likelihood function ...
startvalues2_rm1_T2 <- round(res1_rm1_T2$par,10) # ... we define the starting values ...

# ... and implement an initial optimization ...
res2_rm1_T2 <- optim(par= startvalues2_rm1_T2,
             fn = LL_logit,
             y = Y_rm1_T2,
             X = X_rm1_T2,
             control=list(parscale=abs(res1_rm1_T2$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... having conducted the second optimization, we return the point estimates and store these in an object ...
point_estimates_rm1_T2 <- res2_rm1_T2$par[1:15]

# ... we proceed with the estimation of the standard errors ...
SE_rm1_T2 <- sqrt(diag(solve(-res2_rm1_T2$hessian)))

# ... and furthermore include the calculation of the corresponding p-values (for a better evaluation of the significance level of the obtained coefficients) ...
P_Values_rm1_T2 <- 2 * (1 - pnorm(abs(point_estimates_rm1_T2 / SE_rm1_T2)))

# ... we additionally extract the number of observations for the model ...
N_rm1_T2 <- length(Y_rm1_T2)

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... for Model 2, the same procedure as for Model 1 is conducted. A different Y-vector and X-Matrix are used as inputs for the optimization of the Log-Likelihood function. 

# ... we initiate by defining the starting values ...
startvalues1_rm2_T2 <- rep(0,15)

# ... and implement an initial optimization ...
res1_rm2_T2 <- optim(par = startvalues1_rm2_T2,
             fn = LL_logit,
             y = Y_rm2_T2,
             X = X_rm2_T2,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_rm2_T2 <- round(res1_rm2_T2$par,10) # ... we define the starting values ...

# ... and carry out the second optimization procedure ...
res2_rm2_T2 <- optim(par= startvalues2_rm2_T2,
             fn = LL_logit,
             y = Y_rm2_T2,
             X = X_rm2_T2,
             control=list(parscale=abs(res1_rm2_T2$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we then return the point estimates ...
point_estimates_rm2_T2 <- res2_rm2_T2$par[1:15]

# ... and also estimate the standard errors ...
SE_rm2_T2 <- sqrt(diag(solve(-res2_rm2_T2$hessian)))

# ... we furthermore include the calculation of the corresponding p-values ...
P_Values_rm2_T2 <- 2 * (1 - pnorm(abs(point_estimates_rm2_T2 / SE_rm2_T2)))

# ... and the number of observations ...
N_rm2_T2 <- length(Y_rm2_T2)

```

```{r Part 2.3: Display and Visualization of Regression Results}

# Having obtained the values for the parameters of interest, this part generates a nice-looking table to display the results of the two logistic regressions. Together, the two presented models constitute the final replication of Table 2. 

library(knitr) # ... we need the "knitr" to be able to generate the tables ...

# .............................................................................#
# ................................... MODEL 1 ..................................
# .............................................................................#

# ... we first define the point estimates, standard errors, and p-values for Model 1 ...
results_rm1_T2 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)") ,

  Point_Estimates = point_estimates_rm1_T2,
  Standard_Errors = SE_rm1_T2,
  P_Values = P_Values_rm1_T2,
  Observations = N_rm1_T2 )

# ... we finally print the formatted table ...
kable(results_rm1_T2, 
      align = "c", 
      digits = 3, 
      caption = "Results Replication Model 1 (Table 2)",
      col.names = c("Variables", 
                    "Point Estimates", 
                    "Standard Errors", 
                    "P-Values", "N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ................................... MODEL 2 ..................................
# .............................................................................#

# ... we first define the point estimates, standard errors, and p-values for Model 2 ...
results_rm2_T2 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Vox intention (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)") ,

  Point_Estimates = point_estimates_rm2_T2,
  Standard_Errors = SE_rm2_T2,
  P_Values = P_Values_rm2_T2,
  Observations = N_rm2_T2 )

# ... we finally print the formatted table ...
kable(results_rm2_T2, 
      align = "c", 
      digits = 3, 
      caption = "Results Replication Model 2 (Table 2)",
      col.names = c("Variables", 
                    "Point Estimates", 
                    "Standard Errors", 
                    "P-Values", 
                    "N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ........................ Joint Display MODELS 1 & 2 .........................#
# .............................................................................#

# ... we initiate adding the corresponding stars to coefficients using the function "add_stars" ...
Point_Estimates_rm1_T2_stars <- mapply(add_stars, round(point_estimates_rm1_T2, 3), P_Values_rm1_T2)
Point_Estimates_rm2_T2_stars <- mapply(add_stars, round(point_estimates_rm2_T2, 3), P_Values_rm2_T2)

# we then combine point estimates with SE ...
output_1 <- cbind(Point_Estimates_rm1_T2_stars, round(SE_rm1_T2, 3))
colnames(output_1) <- c('Coefficients - 2019', 'SE')
rownames(output_1) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Vox intention (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)")

output_2 <- cbind(Point_Estimates_rm2_T2_stars, round(SE_rm2_T2, 3))
colnames(output_2) <- c('Coefficients - 2020', 'SE')
rownames(output_2) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Vox intention (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)")

# ... we then combine the two columns ...
unified_table_2 <- cbind(output_1, output_2)

# ... create a row for the number of observations for each model ...
n_observations <- c(N_rm1_T2, "", N_rm2_T2, "")

# ... and append the number of observations row to the unified table ...
unified_table_2 <- rbind(unified_table_2, "N" = n_observations)

# ... we finalize by printing the generated table...
kable(unified_table_2, 
      digits = 3, 
      align = "ccrl",
      booktabs = TRUE,
      caption = "Effect of Prior Attitudes on Intended Vote for Vox") %>%
  kable_styling(full_width = FALSE)

#______________________________________________________________________________#
# ... this last section generates the La-Tex corresponding to Table 2 ...
Replication_Table_2 <- kable(unified_table_2, 
                             digits = 3, 
                             align = "ccrl",
                             booktabs = TRUE, 
                             format = "latex",
                             caption = "Effect of Prior Attitudes on Intended Vote for Vox") %>%
  kable_styling(full_width = FALSE)

# ... print the La-TeX code to the console ...
cat(Replication_Table_2)
#______________________________________________________________________________#

```

### Replication of the Paper's Original Results: Table 3

This initial part has the following sub-sections: 
    - Part 3.1: Estimation of the Regression Coefficients using the built-in GLM commands 
    - Part 3.2: Display and Visualization of the Regression Results

``` {r Part 3.1: Replication of Main Table Using R's built-in GLM Commands}

# This section replicates the results presented in Table 3 (Models 1, 2, 3, and 4) ...
library(brglm2) # we first require the package "brglm2" ...

# We first fir the regression for Model 1 ...
m1_T3 <- glm(vim_vox ~ female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol + l2vim_vox + l2authoritarian + l2ideol + l2nativism + l2orgterr + l2pop6amz + l2msexism + lsvim_vox + lsauthoritarian + lsideol + lsnativism + lsorgterr + lspop6amz + lsmsexism, family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2019))

# ... then for Model 2 ...
m2_T3 <- glm(vim_vox ~ female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol + l2vim_vox + l2authoritarian + l2ideol + l2nativism + l2orgterr + l2pop6amz + l2msexism + lsvim_vox + lsauthoritarian + lsideol + lsnativism + lsorgterr + lspop6amz + lsmsexism, family = binomial(logit), method = "brglmFit", data = data_panel %>% filter(year == 2020))

## ... we continue with Model 3 ...
m3_T3 <- update(m1_T3, ~. - lsmsexism + posmsex + negmsex)

## ... and finalize with Modl 4 ...
m4_T3 <- update(m2_T3, ~. - lsmsexism + posmsex + negmsex)

```

``` {r Part 3.2: Display and Visualization of the Regression Results}

stargazer(m1_T3, m2_T3, m3_T3, m4_T3, type = "text", dep.var.caption = "", dep.var.labels.include = F, column.labels = c("2019", "2020", "2019", "2020"), keep.stat = "n", star.char = c("+", "*", "**"), star.cutoffs = c(0.1, 0.05, 0.01),  notes = c("+ p<0.1; * p<0.05; ** p<0.01"), covariate.labels = c("Female", "Age", "Upper secondary", "Tertiary", "Income", "Lives with partner", "Interest in politics", "Vox intention (t-2)", "Authoritarianism (t-2)", "Ideological identification (t-2)", "Nativism (t-2)", "Territorial preference (t-2)", "Populism (t-2)", "Sexism (t-2)", "Vox intention (t-1 minus t-2)", "Authoritarianism (t-1 minus t-2)", "Ideological identification (t-1 minus t-2)", "Nativism (t-1 minus t-2)", "Territorial preference (t-1 minus t-2)", "Populism (t-1 minus t-2)", "Sexism (t-1 minus t-2)", "Increase in sexism (t-1 minus t-2)", "Decrease in sexism (t-1 minus t-2)"), notes.append = F, no.space = T, title = "Table 3. Effect of prior change in attitudes and vote intention on intended vote for Vox")

#______________________________________________________________________________#
# ... this last section generates the La-Tex corresponding to Table 1 ...
Replication_Table_3 <- capture.output(
  stargazer(m1_T3, m2_T3, m3_T3, m4_T3,
            type = "latex",
            dep.var.caption = "",
            dep.var.labels.include = FALSE,
            column.labels = c("2019", "2020", "2019", "2020"),
            keep.stat = "n",
            star.char = c("+", "*", "**"),
            star.cutoffs = c(0.1, 0.05, 0.01),
            notes = c("+ p<0.1; * p<0.05; ** p<0.01"),
            covariate.labels = c("Female", "Age", "Upper secondary", "Tertiary", "Income", "Lives with partner", "Interest in politics", "Vox intention (t-2)", "Authoritarianism (t-2)", "Ideological identification (t-2)", "Nativism (t-2)", "Territorial preference (t-2)", "Populism (t-2)", "Sexism (t-2)", "Vox intention (t-1 minus t-2)", "Authoritarianism (t-1 minus t-2)", "Ideological identification (t-1 minus t-2)", "Nativism (t-1 minus t-2)", "Territorial preference (t-1 minus t-2)", "Populism (t-1 minus t-2)", "Sexism (t-1 minus t-2)", "Increase in sexism (t-1 minus t-2)", "Decrease in sexism (t-1 minus t-2)"),
            notes.append = FALSE,
            no.space = TRUE,
            title = "Table 3. Effect of prior change in attitudes and vote intention on intended vote for Vox")
)

# ... print the La-TeX code to the console ...
cat(Replication_Table_3)

```

## Analysis Part 1: Dichotomous Dependent Variable

This initial part of our analysis examines whether the effect of sexism on support for the VOX party (operationalized as a respondent's intention to vote for this party) varies between women and men. For this initial part of our empirical analysis, we employ a dichotomous dependent variable measuring whether a respondent intends to cast a vote in favor of vox (coded as "1"), or in favor of another party (coded as "0"). 

However, the binary dependent variable we use for our analysis differs from the one used by Anduiza & Rico (2022) in one major way. While Anduiza & Rico (2022) employ a variable taking the value of 1 for respondents intending to vote for VOX and a value of 0 otherwise, their measurement fails to distinguish between instances where respondents actually intend to cast a valid vote (either for VOX or for another party) and cases where respondents do not intend to either cast a valid vote or to vote at all. 

To account for possible nonvoters (and to limit our analysis exclusively to potential voters), we refine the measurement used by Anduiza & Rico (2022) and generate the binary variable "affirmative_vox" coded as 1 for respondents intending to vote for VOX and 0 otherwise. However, for cases in which respondents intend to cast a blank or null vote, not to cast any vote, not to vote for any of the suggested parties, or do not know for which party to vote, the variable takes a missing value. The purpose of this finer operationalization of vote intention is to distinguish between voters with an intention to cast a vote (regardless of the direction of their intended support) and potential nonvoters. 

Before starting with the analysis, the dependent variable "affirmative_vox" is generated. 

```{r Generation of Dependent Variable - "affirmative_vox"}

nonvoter_values <- c(51, 52, 53, 54, 55) # ... we define the values for the variable "voteintentionspain" which we regard (potential) nonvoter values ...

# ... we then create a duplicate of the variable variable "voteintentionspain" where the values defined above are coded as missing values ...
data_panel$pre_DV <- ifelse(data_panel$voteintentionspain %in% nonvoter_values, NA, data_panel$voteintentionspain)

# ... we finalize by re-coding the variable "pre_DV" to distinguish between vote intentions for VOX (1) and for other parties (0) ...
data_panel$affirmative_vox <- ifelse(data_panel$pre_DV == 23, 1, 0) 

# ... we inspect the newly generated dependent variable ...
mean(data_panel$affirmative_vox, na.rm = T)
summary(data_panel$affirmative_vox)

```

Having generated the dependent variable, we proceed with the conduction of our empirical analysis. We initiate by using the model specifications presented in the original paper's Table 2 ("Analysis Part 1.1"), and then proceed to employ the extended model specifications from Table 3 as the basis of our analysis ("Analysis Part 1.2"). 

### Analysis Part 1.1: Specification from Table 2

This initial part of the analysis consists of the following sub-section: 
     1.1.1: We initiate by defining the dependent and independent variables (both models). 
     1.1.2: We then optimize the log-likelihood functions given the inputs defined in step 1.1 (both models).
     1.1.3: We display the results in a nice-formatted table (both models).
     1.1.4: We define the Simulation Function for the estimation of the Quantities of Interest. 
     1.1.5: Definition of the Number of Simulations.
     1.1.6: Definition of Scenarios.
     1.1.7: Estimation of Predicted Probabilities Using the Average Value Approach.
     1.1.8: Estimation of First Differences.
     1.1.9: Estimation of First Differences Using the Observed Value Approach

```{r Part 1.1.1: Definition of Dependent and Independent Variables}

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

#______________________________________________________________________________#
# ... we initiate by generating a new variable for the interaction between the variables "female" and "lm1_msexism" ...
data_panel$int_m1E1 <- data_panel$female * data_panel$lm1_msexism
#______________________________________________________________________________#

# ... we proceed to define a vector containing the names of all the variables that will be used for the estimation of the model ...
variables_m1E1  <- c("female",                 
                     "age",                  
                     "edu3_2",               
                     "edu3_3",               
                     "dhincome_all",         
                     "livingpartner",        
                     "intpol",               
                     "lm1_vim_vox",          
                     "lm1_authoritarian",    
                     "lm1_ideol",            
                     "lm1_nativism",         
                     "lm1_orgterr",          
                     "lm1_pop6amz",           
                     "lm1_msexism",  
                     "int_m1E1",
                     "affirmative_vox",
                     "year")

# ... we then generate a data subset ("data_m1E1") containing the dependent and independent variables as defined by the vector "variables_m1E1" ...
data_m1E1 <- na.omit(data_panel[, c(variables_m1E1)])

# ... and subsequently create a subset of the data frame "data_panel_E1" containing only observations for which the value of "year" is 2019 ...
data_panel_m1E1 <- subset(data_m1E1, year == 2019) 

# ... we then define the dependent variable "affirmative_vox" ...
data_panel_m1E1$affirmative_vox <- as.numeric(data_panel_m1E1$affirmative_vox) 
Y_m1E1 <- data_panel_m1E1$affirmative_vox
Y_m1E1 <- as.numeric(Y_m1E1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_m1E1  <- c("female",                 
                                 "age",                    
                                 "edu3_2",                 
                                 "edu3_3",                 
                                 "dhincome_all",           
                                 "livingpartner",          
                                 "intpol",   
                                 "lm1_vim_vox",          
                                 "lm1_authoritarian",        
                                 "lm1_ideol",                
                                 "lm1_nativism",             
                                 "lm1_orgterr",              
                                 "lm1_pop6amz",              
                                 "lm1_msexism",
                                 "int_m1E1"
                                 )

independent_variables_m1E1 <- data_panel_m1E1[, independent_variables_m1E1]
X_m1E1 <- cbind(1, independent_variables_m1E1)
X_m1E1 <- as.matrix(sapply(X_m1E1, as.numeric))

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

#______________________________________________________________________________#
# ... we initiate by generating a new variable for the interaction between the variables "female" and "lm1_msexism" ...
data_panel$int_m2E1 <- data_panel$female * data_panel$lm2_msexism
#______________________________________________________________________________#

# ... we define a vector containing the names of all the variables that will be used for the estimation of the model ...
variables_m2E1  <- c("female",                 
                     "age",                  
                     "edu3_2",               
                     "edu3_3",               
                     "dhincome_all",         
                     "livingpartner",        
                     "intpol",               
                     "lm2_vim_vox",          
                     "lm2_authoritarian",    
                     "lm2_ideol",            
                     "lm2_nativism",         
                     "lm2_orgterr",          
                     "lm2_pop6amz",           
                     "lm2_msexism",  
                     "int_m2E1",
                     "affirmative_vox",
                     "year")

# ... we then generate a data subset ("data_m2E1") containing the dependent and independent variables as defined by the vector "variables_m2E1" ...
data_m2E1 <- na.omit(data_panel[, c(variables_m2E1)])

# ... and create a subset of the data frame "data_panel_E1" (created above) containing only observations for which the value of "year" is 2020 ...
data_panel_m2E1 <- subset(data_m2E1, year == 2020) 

# ... we then define the dependent variable "affirmative_vox" ...
data_panel_m2E1$affirmative_vox <- as.numeric(data_panel_m2E1$affirmative_vox) 
Y_m2E1 <- data_panel_m2E1$affirmative_vox
Y_m2E1 <- as.numeric(Y_m2E1) # we store the y-vector as a numeric vector

# ... and proceed to define the set of independent variables
independent_variables_m2E1  <- c("female",                 
                                 "age",                    
                                 "edu3_2",                 
                                 "edu3_3",                 
                                 "dhincome_all",           
                                 "livingpartner",          
                                 "intpol",   
                                 "lm2_vim_vox",          
                                 "lm2_authoritarian",        
                                 "lm2_ideol",                
                                 "lm2_nativism",             
                                 "lm2_orgterr",              
                                 "lm2_pop6amz",              
                                 "lm2_msexism",
                                 "int_m2E1"
                                 )

independent_variables_m2E1 <- data_panel_m2E1[, independent_variables_m2E1]
X_m2E1 <- cbind(1, independent_variables_m2E1)
X_m2E1 <- as.matrix(sapply(X_m2E1, as.numeric))

```

```{r Part 1.1.2: Optimization of Logit-Log-Likelihood Functions}

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_m1E1 <- rep(0,16) 

## ... and implement an initial optimization ...
res1_m1E1 <- optim(par = startvalues1_m1E1,
             fn = LL_logit,
             y = Y_m1E1,
             X = X_m1E1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_m1E1 <- round(res1_m1E1$par,10)

res2_m1E1 <- optim(par= startvalues2_m1E1,
             fn = LL_logit,
             y = Y_m1E1,
             X = X_m1E1,
             control=list(parscale=abs(res1_m1E1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_m1E1 <- res2_m1E1$par[1:16]

# ... We proceed with the estimation of the standard errors ...
SE_m1E1 <- sqrt(diag(solve(-res2_m1E1$hessian)))

# ... we furthermore include the calculation of the p-values ...
P_Values_m1E1 <- 2 * (1 - pnorm(abs(point_estimates_m1E1 / SE_m1E1)))

# ... we additionally extract the number of observations ...
N_m1E1 <- length(Y_m1E1)

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... we initiate by defining the starting values (one for each covariate plus one for the intercept) ...
startvalues1_m2E1 <- rep(0,16) 

## ... and implement an initial optimization ...
res1_m2E1 <- optim(par = startvalues1_m2E1,
             fn = LL_logit,
             y = Y_m2E1,
             X = X_m2E1,
             control = list(fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we subsequently conduct a second optimization ...
startvalues2_m2E1 <- round(res1_m2E1$par,10)

res2_m2E1 <- optim(par= startvalues2_m2E1,
             fn = LL_logit,
             y = Y_m2E1,
             X = X_m2E1,
             control=list(parscale=abs(res1_m2E1$par), fnscale = -1),
             hessian = TRUE,
             method = "BFGS"
             )

# ... we return the point estimates and store these in an object ...
point_estimates_m2E1 <- res2_m2E1$par[1:16]

# ... We proceed with the estimation of the standard errors ...
SE_m2E1 <- sqrt(diag(solve(-res2_m2E1$hessian)))

# ... we furthermore include the calculation of the p-values ...
P_Values_m2E1 <- 2 * (1 - pnorm(abs(point_estimates_m2E1 / SE_m2E1)))

# ... we additionally extract the number of observations ...
N_m2E1 <- length(Y_m2E1)

```

```{r Part 1.1.3: Display and Visualization of Regression Results}

# Having obtained the values for the parameters of interest, this part generates a nice-looking table to display the results of the two logistic regressions. 

library(knitr) # ... we need the "knitr" to be able to generate the tables ...

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... we first define the point estimates, standard errors, and p-values for Model 1 ...
results_m1E1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Intention to vote for VOX (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)",
                   "Female x Prior Sexism") ,
  
  Point_Estimates = point_estimates_m1E1,
  Standard_Errors = SE_m1E1,
  P_Values = P_Values_m1E1,
  Observations = N_m1E1 )

# ... and we then print the formatted table ...
kable(results_m1E1, 
      align = "c", 
      digits = 3, 
      caption = "Results Model 1 (2019)",
      col.names = c("Variables", 
                    "Point Estimates", 
                    "Standard Errors", 
                    "P-Values", "
                    N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... we first define the point estimates, standard errors, and p-values for Model 1 ...
results_m2E1 <- data.frame(
  Coefficients = c("Intercept",
                   "Female",
                   "Age",
                   "High school / Vocational",
                   "College",
                   "Income",
                   "Lives with partner",
                   "Interest in politics",
                   "Intention to vote for VOX (Prior)",
                   "Authoritarianism (Prior)",
                   "Ideological identification (Prior)",
                   "Nativism (Prior)",
                   "Territorial preference (Prior)",
                   "Populism (Prior)",
                   "Sexism (Prior)",
                   "Female x Prior Sexism") ,
  
  Point_Estimates = point_estimates_m2E1,
  Standard_Errors = SE_m2E1,
  P_Values = P_Values_m2E1,
  Observations = N_m2E1 )

# ... and we then print the formatted table ...
kable(results_m2E1, 
      align = "c", 
      digits = 3, 
      caption = "Results Model 2 (2020)",
      col.names = c("Variables", 
                    "Point Estimates", 
                    "Standard Errors", 
                    "P-Values", "
                    N"),
      add_header_above = list(c("", 
                                "Estimates" = 2, 
                                "Statistics" = 2
                                )
                              )
      )

# .............................................................................#
# ................ Joint Display MODELS 1 & 2 (2019 and 2020) .................#
# .............................................................................#

# ... we initiate adding the corresponding stars to coefficients using the function "add_stars" ...
Point_Estimates_m1E1_stars <- mapply(add_stars, round(point_estimates_m1E1, 3), P_Values_m1E1)
Point_Estimates_m2E1_stars <- mapply(add_stars, round(point_estimates_m2E1, 3), P_Values_m2E1)

# we then combine point estimates with SE ...
output_1 <- cbind(Point_Estimates_m1E1_stars, round(SE_m1E1, 3))
colnames(output_1) <- c('Coefficients - 2019', 'SE')
rownames(output_1) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Intention to vote for VOX (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)",
                        "Female x Prior Sexism")

output_2 <- cbind(Point_Estimates_m2E1_stars, round(SE_m2E1, 3))
colnames(output_2) <- c('Coefficients - 2020', 'SE')
rownames(output_2) <- c("Intercept",
                        "Female",
                        "Age",
                        "High school / Vocational",
                        "College",
                        "Income",
                        "Lives with partner",
                        "Interest in politics",
                        "Intention to vote for VOX (Prior)",
                        "Authoritarianism (Prior)",
                        "Ideological identification (Prior)",
                        "Nativism (Prior)",
                        "Territorial preference (Prior)",
                        "Populism (Prior)",
                        "Sexism (Prior)",
                        "Female x Prior Sexism")

# ... we then combine the two columns ...
unified_table_3 <- cbind(output_1, output_2)

# ... create a row for the number of observations for each model ...
n_observations <- c(N_m1E1, "", N_m2E1, "")

# ... and append the number of observations row to the unified table ...
unified_table_3 <- rbind(unified_table_3, "N" = n_observations)

# ... we finalize by printing the generated table...
kable(unified_table_3, 
      digits = 3, 
      align = "ccrl",
      booktabs = TRUE,
      caption = "Effect of Prior Attitudes on Intended Vote for Vox - Interaction Term Included") %>%
  kable_styling(full_width = FALSE)

#______________________________________________________________________________#
# ... this last section generates the La-Tex corresponding to Table 2 ...
Analysis_Table_2 <- kable(unified_table_3, 
                             digits = 3, 
                             align = "ccrl",
                             booktabs = TRUE, 
                             format = "latex",
                             caption = "Effect of Prior Attitudes on Intended Vote for Vox - Interaction Term Included") %>%
  kable_styling(full_width = FALSE)

# ... print the La-TeX code to the console ...
cat(Analysis_Table_2)

```

```{r Part 1.1.4: Definition of the Simlation Function}

# ... before defining the Simulation Function, we initiate by defining the "response function" ...
response_function <- function(x) {
  1 / (1 + exp(-x))
}

# ... we proceed to define an appropriate function for the stochastic component ...
stochastic_component <- function(ndraws, p) {
  rbinom(n = ndraws, size = 1, prob = p)
}

# ... and finalize by defining the Simulation Function for the estimation of the Quantities of Interest (QoI's) ...
sim_function <-
  function(seed = 1234,
           nsim = 1000,
           coefs,
           vcov,
           scenario,
           response_function,
           predicted_values = F,
           stochastic_component) {
    if (is.null(dim(scenario))) {
      stop("The scenario needs to be in a matrix.")
    }
    
    if (length(coefs) != ncol(scenario)) {
      stop("The scenario and the parameter vector don't fit.")
    }
    
    set.seed(seed)
    
    # Set up the sampling distribution
    S <- mvrnorm(nsim, coefs, vcov)
    mu <- S %*% t(scenario)
        ev <- response_function(mu)
    
    if (predicted_values) {
      pv <-
        array(stochastic_component(ndraws = prod(dim(ev)), p = ev),
              dim = dim(ev))
      return(list(ev = ev, pv = pv))
    }
    return(list(ev = ev))
  }

```

```{r Part 1.1.5: Definition of the Number of Simlations}

# Before initiating the conduction of the simulations, we first define a series of key quantities and distributions.

library(MASS) # ... we require the package "MASS" to conduct the draws from the multivariate normal distribution ...

# ... we define the number of simulations that will be carried out ...
n_simulations <- 1000 # 

```
```{r Part 1.1.6: Definition of Scenarios}

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... we initiate by defining a sequence of the variable "lm1_msexism" ranging from its minimum value (0) to its maximum (1) with a total of 1000 intervals in between ... 
sexism_seq_m1E1 <- seq(min(data_panel_m1E1$lm1_msexism[!is.na(data_panel_m1E1$lm1_msexism)]),
                       1, length.out = 1000)

# ... we then define the scenario. The order of the covariates is determined by the order in which they appear in the vector "independent_variables_m1E1" ...
scenario_w_m1E1 <- cbind(1,                                       # Intercept 
                         1,                                       # Female = 1 
                         mean(data_panel_m1E1$age),               # ...  
                         median(data_panel_m1E1$edu3_2),          # ...
                         median(data_panel_m1E1$edu3_3),          # ...
                         mean(data_panel_m1E1$dhincome_all),      # ... 
                         median(data_panel_m1E1$livingpartner),   # ... 
                         mean(data_panel_m1E1$intpol),            # ...
                         median(data_panel_m1E1$lm1_vim_vox),     # ...
                         mean(data_panel_m1E1$lm1_authoritarian), # ...
                         mean(data_panel_m1E1$lm1_ideol),         # ...
                         mean(data_panel_m1E1$lm1_nativism),      # ...
                         mean(data_panel_m1E1$lm1_orgterr),       # ...
                         mean(data_panel_m1E1$lm1_pop6amz),       # ...
                         sexism_seq_m1E1,                         # Sexism-Sequence 
                         1 * sexism_seq_m1E1                      # Interaction 
                         )    

scenario_m_m1E1 <- cbind(1,                                       # Intercept 
                         0,                                       # Female = 0 
                         mean(data_panel_m1E1$age),               # ...  
                         median(data_panel_m1E1$edu3_2),          # ...
                         median(data_panel_m1E1$edu3_3),          # ...
                         mean(data_panel_m1E1$dhincome_all),      # ... 
                         median(data_panel_m1E1$livingpartner),   # ... 
                         mean(data_panel_m1E1$intpol),            # ...
                         median(data_panel_m1E1$lm1_vim_vox),     # ...
                         mean(data_panel_m1E1$lm1_authoritarian), # ...
                         mean(data_panel_m1E1$lm1_ideol),         # ...
                         mean(data_panel_m1E1$lm1_nativism),      # ...
                         mean(data_panel_m1E1$lm1_orgterr),       # ...
                         mean(data_panel_m1E1$lm1_pop6amz),       # ...
                         sexism_seq_m1E1,                         # Sexism-Sequence 
                         0*sexism_seq_m1E1                        # Interaction 
                         )    

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m1E1 <- sim_function(coefs = res2_m1E1$par, 
                              vcov = solve(-res2_m1E1$hessian), 
                              scenario = scenario_w_m1E1, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m1E1 <- sim_function(coefs = res2_m1E1$par, 
                             vcov = solve(-res2_m1E1$hessian), 
                             scenario = scenario_m_m1E1, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... we initiate by defining a sequence of the variable "lm1_msexism" ranging from its minimum value (0) to its maximum (1) with a total of 1000 intervals in between ... 
sexism_seq_m2E1 <- seq(min(data_panel_m2E1$lm2_msexism[!is.na(data_panel_m2E1$lm2_msexism)]),
                       1, length.out = 1000)

# ... we then define the scenario. The order of the covariates is determined by the order in which they appear in the vector "independent_variables_m1E1" ...
scenario_w_m2E1 <- cbind(1,                                       # Intercept 
                         1,                                       # Female = 1 
                         mean(data_panel_m2E1$age),               # ...  
                         median(data_panel_m2E1$edu3_2),          # ...
                         median(data_panel_m2E1$edu3_3),          # ...
                         mean(data_panel_m2E1$dhincome_all),      # ... 
                         median(data_panel_m2E1$livingpartner),   # ... 
                         mean(data_panel_m2E1$intpol),            # ...
                         median(data_panel_m2E1$lm2_vim_vox),     # ...
                         mean(data_panel_m2E1$lm2_authoritarian), # ...
                         mean(data_panel_m2E1$lm2_ideol),         # ...
                         mean(data_panel_m2E1$lm2_nativism),      # ...
                         mean(data_panel_m2E1$lm2_orgterr),       # ...
                         mean(data_panel_m2E1$lm2_pop6amz),       # ...
                         sexism_seq_m2E1,                         # Sexism-Sequence 
                         1 * sexism_seq_m2E1                      # Interaction 
                         )    

scenario_m_m2E1 <- cbind(1,                                       # Intercept 
                         0,                                       # Female = 0 
                         mean(data_panel_m2E1$age),               # ...  
                         median(data_panel_m2E1$edu3_2),          # ...
                         median(data_panel_m2E1$edu3_3),          # ...
                         mean(data_panel_m2E1$dhincome_all),      # ... 
                         median(data_panel_m2E1$livingpartner),   # ... 
                         mean(data_panel_m2E1$intpol),            # ...
                         median(data_panel_m2E1$lm2_vim_vox),     # ...
                         mean(data_panel_m2E1$lm2_authoritarian), # ...
                         mean(data_panel_m2E1$lm2_ideol),         # ...
                         mean(data_panel_m2E1$lm2_nativism),      # ...
                         mean(data_panel_m2E1$lm2_orgterr),       # ...
                         mean(data_panel_m2E1$lm2_pop6amz),       # ...
                         sexism_seq_m2E1,                         # Sexism-Sequence 
                         0 * sexism_seq_m2E1                      # Interaction 
                         )    

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m2E1 <- sim_function(coefs = res2_m2E1$par, 
                              vcov = solve(-res2_m2E1$hessian), 
                              scenario = scenario_w_m2E1, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m2E1 <- sim_function(coefs = res2_m2E1$par, 
                             vcov = solve(-res2_m2E1$hessian), 
                             scenario = scenario_m_m2E1, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

```

```{r Part 1.1.7: Estimation of Predicted Probabilities Using the Average Value Approach}

par(mfrow = c(1, 2)) # This will allow us to display the predicted probabilities for the two models side by side ...

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m1E1 <- apply(sim_women_m1E1, 2, function(x) quantile(x, probs = 0.025))
upper_women_m1E1 <- apply(sim_women_m1E1, 2, function(x) quantile(x, probs = 0.975))
lower_men_m1E1 <- apply(sim_men_m1E1, 2, function(x) quantile(x, probs = 0.025))
upper_men_m1E1 <- apply(sim_men_m1E1, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = sexism_seq_m1E1,
     y = apply(sim_women_m1E1, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2019)", 
     cex.main = 0.7,
     xlab = "Level of Individual Prior Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.6), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 1, by = 0.05), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(0, 1, by = 0.1), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(sexism_seq_m1E1, rev(sexism_seq_m1E1)), c(upper_women_m1E1, rev(lower_women_m1E1)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(sexism_seq_m1E1, rev(sexism_seq_m1E1)), c(upper_men_m1E1, rev(lower_men_m1E1)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = sexism_seq_m1E1, y = apply(sim_women_m1E1, 2, mean), lwd = 2, col = "red")
lines(x = sexism_seq_m1E1, y = apply(sim_men_m1E1, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel_m1E1$lm1_msexism[data_panel_m1E1$lm1_msexism <= 150], 0.1), ticksize = 0.02, lwd = 1)

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... as before, We initiate by calculating the confidence ...
lower_women_m2E1 <- apply(sim_women_m2E1, 2, function(x) quantile(x, probs = 0.025))
upper_women_m2E1 <- apply(sim_women_m2E1, 2, function(x) quantile(x, probs = 0.975))
lower_men_m2E1 <- apply(sim_men_m2E1, 2, function(x) quantile(x, probs = 0.025))
upper_men_m2E1 <- apply(sim_men_m2E1, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = sexism_seq_m2E1,
     y = apply(sim_women_m2E1, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2020)", 
     cex.main = 0.7,
     xlab = "Level of Individual Prior Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.3), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 1, by = 0.05), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(0, 1, by = 0.1), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(sexism_seq_m2E1, rev(sexism_seq_m2E1)), c(upper_women_m2E1, rev(lower_women_m2E1)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(sexism_seq_m2E1, rev(sexism_seq_m2E1)), c(upper_men_m2E1, rev(lower_men_m2E1)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = sexism_seq_m2E1, y = apply(sim_women_m2E1, 2, mean), lwd = 2, col = "red")
lines(x = sexism_seq_m2E1, y = apply(sim_men_m2E1, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel_m2E1$lm2_msexism[data_panel_m2E1$lm2_msexism <= 150], 0.1), ticksize = 0.02, lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("Predicted_Probabilities_E1.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

```{r Part 1.1.8: Estimation of First Differences}

par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... we initiate by estimating the first differences ...
fd_m1E1 <- sim_women_m1E1 - sim_men_m1E1

# ... we then generate the display plot ...
plot(x = sexism_seq_m1E1,
     y = apply(fd_m1E1, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2019)", 
     cex.main = 0.7,
     xlab = "Level of Individual Prior Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.6), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = sexism_seq_m1E1,
      y = apply(fd_m1E1, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = sexism_seq_m1E1,
      y = apply(fd_m1E1, 2, quantile, 0.025),
      lty = "dashed")
lines(x = sexism_seq_m1E1,
      y = apply(fd_m1E1, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... we initiate by estimating the first differences ...
fd_m2E1 <- sim_women_m2E1 - sim_men_m2E1

# ... we then generate the disply plot ...
plot(x = sexism_seq_m2E1,
     y = apply(fd_m2E1, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2020)", 
     cex.main = 0.7,
     xlab = "Level of Individual Prior Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.6), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = sexism_seq_m2E1,
      y = apply(fd_m1E1, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = sexism_seq_m2E1,
      y = apply(fd_m2E1, 2, quantile, 0.025),
      lty = "dashed")
lines(x = sexism_seq_m2E1,
      y = apply(fd_m2E1, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_AVA_E1.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

```{r Part 1.1.9: Estimation of First Differences Using the Observed Value Approach}

# .............................................................................#
# ............................... MODEL 1 (2019) ..............................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m1E1 <- array(NA, c(dim(X_m1E1), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m1E1[, ,] <- X_m1E1

# select the columns to adjust for simulation 
sel1_m1E1 <- which(colnames(X_m1E1) == "female")
sel2_m1E1 <- which(colnames(X_m1E1) == "int_m1E1")

# assign 0 to "female" column in layer 1
cases_m1E1[, sel1_m1E1, 1] <- 0
# assign 1 to female column in layer 2
cases_m1E1[, sel1_m1E1, 2] <- 1

# assign 0 to interaction ("int_m1E1") column in layer 1
cases_m1E1[, sel2_m1E1, 1] <- 0*X_m1E1[, "female"]
# assign "female" value to interaction column in layer 2
cases_m1E1[, sel2_m1E1, 2] <- 1*X_m1E1[, "female"]

# Loop over the matrices.
val_m1E1 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m1E1 <- sim_function(coefs = res2_m1E1$par,
                          vcov = solve(-res2_m1E1$hessian),
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m1E1[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m1E1 <- apply(ev_m1E1, 1, mean)
  val_m1E1[, i] <- tmp_val_m1E1
}

# ... we then estimate the first differences and store these in an object called "fd_m1E1" ...
fd_m1E1 <- val_m1E1[, 1] - val_m1E1[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# ... we first plot the histogram ...
hist(
  fd_m1E1,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2019)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m1E1), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m1E1, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m1E1), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m1E1), 3)), col = "black", pos = 4)
text(quantile(fd_m1E1, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m1E1, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m1E1, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m1E1, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m1E1),
  main = "Density Plot of Simulated First Differences (2019)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m1E1), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m1E1, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m1E1), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m1E1), 3)), col = "black", pos = 4)
text(quantile(fd_m1E1, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m1E1, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m1E1, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m1E1, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m1E1.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# ............................... MODEL 2 (2020) ..............................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m2E1 <- array(NA, c(dim(X_m2E1), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m2E1[, ,] <- X_m2E1

# select the columns to adjust for simulation 
sel1_m2E1 <- which(colnames(X_m2E1) == "female")
sel2_m2E1 <- which(colnames(X_m2E1) == "int_m2E1")

# assign 0 to "female" column in layer 1
cases_m2E1[, sel1_m2E1, 1] <- 0
# assign 1 to female column in layer 2
cases_m2E1[, sel1_m2E1, 2] <- 1

# assign 0 to interaction ("int_m1E1") column in layer 1
cases_m2E1[, sel2_m2E1, 1] <- 0*X_m2E1[, "female"]
# assign "female" value to interaction column in layer 2
cases_m2E1[, sel2_m2E1, 2] <- 1*X_m2E1[, "female"]

# Loop over the matrices.
val_m2E1 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m2E1 <- sim_function(coefs = res2_m2E1$par,
                          vcov = solve(-res2_m2E1$hessian),
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m2E1[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m2E1 <- apply(ev_m2E1, 1, mean)
  val_m2E1[, i] <- tmp_val_m2E1
}

# ... we then estimate the first differences and store these in an object called "fd_m1E1" ...
fd_m2E1 <- val_m2E1[, 1] - val_m2E1[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
# ... we first plot the histogram ...
hist(
  fd_m2E1,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2020)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m2E1), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m2E1, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m2E1), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m2E1), 3)), col = "black", pos = 4)
text(quantile(fd_m2E1, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m2E1, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m2E1, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m2E1, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m2E1),
  main = "Density Plot of Simulated First Differences (2020)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m2E1), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m2E1, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m2E1), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m2E1), 3)), col = "black", pos = 4)
text(quantile(fd_m2E1, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m2E1, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m2E1, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m2E1, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m2E1.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

### Analysis Part 1.2: Specification from Table 3

The second part of the analysis consists of the following sub-section: 
     1.2.1: We initiate by generating the interaction variables for each of the models
     1.2.2: Estimation of the models including the generated interaction variables
     1.2.3: We display the results in a nice-formatted table (all four models)
     1.2.4: Definition of Scenarios
     1.2.5: Estimation of Predicted Probabilities Using the Average Value Approach
     1.2.6: Estimation of First Differences
     1.2.7: Estimation of First Differences Using the Observed Value Approach

``` {r Part 1.2.1: Generation of Interaction Variables}

# ... This section generates the interaction variables for each of the four specifications that will be taken into account. Since the interaction variables for models 1 and 2, 3 and 4, and 5 and 6 are respectively the same, we only generate three interaction variables ...

#______________________________________________________________________________#
# ... interaction variable "int_m12E2" for Models 1 and 2 ...
data_panel$int_m12E2 <- data_panel$female * data_panel$lsmsexism
#______________________________________________________________________________#

#______________________________________________________________________________#
# ... interaction variable "int_m34E2" for Models 3 and 4 ...
data_panel$int_m34E2 <- data_panel$female * data_panel$posmsex
#______________________________________________________________________________#

#______________________________________________________________________________#
# ... interaction variable "int_m34E2" for Models 5 and 6 ...
data_panel$int_m56E2 <- data_panel$female * data_panel$negmsex
#______________________________________________________________________________#

```

``` {r Part 1.2.2: Estimation of the Models with Interaction Variables}

library(brglm2) # we first require the package "brglm2" ...
library(dplyr)

# .............................................................................#
# .................................. MODEL 1 ..................................#
# .............................................................................#
# ... we first fit the regression for Model 1 ("m1_E2") ...
m1_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               lsmsexism +                  # Constitutive Term "lsmsexism" 
               int_m12E2,                    # Interaction Term "int_m12E2"
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2019))


# ... we extract the estimated coefficients ...
coefficients_m1_E2 <- coef(m1_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m1_E2 <- summary(m1_E2)
vcov_m1_E2 <- summary_m1_E2$cov.unscaled

# .............................................................................#
# .................................. MODEL 2 ..................................#
# .............................................................................#
# ... then for Model 2 ("m2_E2") ...
m2_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               lsmsexism +                  # Constitutive Term "lsmsexism" 
               int_m12E2,                    # Interaction Term "int_m12E2"
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2020))

# ... we extract the estimated coefficients ...
coefficients_m2_E2 <- coef(m2_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m2_E2 <- summary(m2_E2)
vcov_m2_E2 <- summary_m2_E2$cov.unscaled

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#
## ... we continue with Model 3 ("m3_E2") ..
m3_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               posmsex +                    # Constitutive Term "posmsex" 
               int_m34E2 +                   # Interaction Term "int_m34E2"
               negmsex,                    
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2019))

# ... we extract the estimated coefficients ...
coefficients_m3_E2 <- coef(m3_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m3_E2 <- summary(m3_E2)
vcov_m3_E2 <- summary_m3_E2$cov.unscaled

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#
## ... and finalize with Model 4 ("m4_E2") ...
m4_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               posmsex +                    # Constitutive Term "posmsex" 
               int_m34E2 +                   # Interaction Term "int_m34E2"
               negmsex,                    
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2020))

# ... we extract the estimated coefficients ...
coefficients_m4_E2 <- coef(m4_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m4_E2 <- summary(m4_E2)
vcov_m4_E2 <- summary_m4_E2$cov.unscaled

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#
## ... we continue with Model 5 ("m5_E2") ..
m5_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               posmsex +                    # 
               negmsex+                     # Constitutive Term "negmsex"
               int_m56E2,                   # Interaction Term "int_m56E2" 
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2019))

# ... we extract the estimated coefficients ...
coefficients_m5_E2 <- coef(m5_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m5_E2 <- summary(m5_E2)
vcov_m5_E2 <- summary_m5_E2$cov.unscaled

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#
## ... and finalize with Model 6 ("m6_E2") ...
m6_E2 <- glm(affirmative_vox ~              # Dependent Variable 
               female +                     # Constitutive Term "female" 
               age +                        #
               edu3_2 +                     #
               edu3_3 +                     #
               dhincome_all +               #
               livingpartner +              #
               intpol +                     #
               l2vim_vox +                  #
               l2authoritarian +            #
               l2ideol +                    #
               l2nativism +                 #
               l2orgterr +                  #
               l2pop6amz +                  #
               l2msexism +                  #
               lsvim_vox +                  #
               lsauthoritarian +            #
               lsideol +                    #
               lsnativism +                 #
               lsorgterr +                  #
               lspop6amz +                  #
               posmsex +                    # 
               negmsex+                     # Constitutive Term "negmsex"
               int_m56E2,                   # Interaction Term "int_m56E2" 
             family = binomial(logit), method = "brglmFit",  data = data_panel %>% filter(year == 2020))

# ... we extract the estimated coefficients ...
coefficients_m6_E2 <- coef(m6_E2)
# ... as well as the resulting variance-covariance matrix ...
summary_m6_E2 <- summary(m6_E2)
vcov_m6_E2 <- summary_m6_E2$cov.unscaled

```

``` {r Part 1.2.3: Display and Visualization of the Regression Results}

# Load the stargazer library
library(stargazer)

# Generate the stargazer command
stargazer(m1_E2, m2_E2, m3_E2, m4_E2, m5_E2,m6_E2, type = "text",
          dep.var.caption = "", 
          dep.var.labels.include = TRUE, 
          column.labels = c("2019", "2020", "2019", "2020", "2019", "2020"), 
          keep.stat = "n", 
          star.char = c("+", "*", "**"), 
          star.cutoffs = c(0.1, 0.05, 0.01),  
          notes = c("+ p<0.1", 
                    "* p<0.05", 
                    "** p<0.01"), 
          covariate.labels = c("Female", 
                               "Age", 
                               "Upper secondary", 
                               "Tertiary", 
                               "Income", 
                               "Lives with partner", 
                               "Interest in politics", 
                               "Vox intention (t-2)", 
                               "Authoritarianism (t-2)", 
                               "Ideological identification (t-2)", 
                               "Nativism (t-2)", 
                               "Territorial preference (t-2)", 
                               "Populism (t-2)", 
                               "Sexism (t-2)", 
                               "Vox intention (t-1 minus t-2)", 
                               "Authoritarianism (t-1 minus t-2)", 
                               "Ideological identification (t-1 minus t-2)", 
                               "Nativism (t-1 minus t-2)", 
                               "Territorial preference (t-1 minus t-2)", 
                               "Populism (t-1 minus t-2)", 
                               "Sexism (t-1 minus t-2)", 
                               "Sexism (t-1 minus t-2) x Female",
                               "Increase in sexism (t-1 minus t-2)", 
                               "Increase in sexism (t-1 minus t-2) x Female",
                               "Decrease in sexism (t-1 minus t-2)",
                               "Decrease in sexism (t-1 minus t-2) x Female",
                               "Intercept"), 
          notes.append = FALSE, 
          no.space = TRUE, 
          title = "Effect of prior change in attitudes and vote intention on intended vote for Vox - interactions included")

#______________________________________________________________________________#
# ... this last section generates the La-Tex corresponding to Table 1 ...
Table_E2 <- capture.output(
  stargazer(m1_E2, m2_E2, m3_E2, m4_E2, m5_E2,m6_E2, type = "latex",
          dep.var.caption = "", 
          dep.var.labels.include = TRUE, 
          column.labels = c("2019", "2020", "2019", "2020", "2019", "2020"), 
          keep.stat = "n", 
          star.char = c("+", "*", "**"), 
          star.cutoffs = c(0.1, 0.05, 0.01),  
          notes = c("+ p<0.1", 
                    "* p<0.05", 
                    "** p<0.01"), 
          covariate.labels = c("Female", 
                               "Age", 
                               "Upper secondary", 
                               "Tertiary", 
                               "Income", 
                               "Lives with partner", 
                               "Interest in politics", 
                               "Vox intention (t-2)", 
                               "Authoritarianism (t-2)", 
                               "Ideological identification (t-2)", 
                               "Nativism (t-2)", 
                               "Territorial preference (t-2)", 
                               "Populism (t-2)", 
                               "Sexism (t-2)", 
                               "Vox intention (t-1 minus t-2)", 
                               "Authoritarianism (t-1 minus t-2)", 
                               "Ideological identification (t-1 minus t-2)", 
                               "Nativism (t-1 minus t-2)", 
                               "Territorial preference (t-1 minus t-2)", 
                               "Populism (t-1 minus t-2)", 
                               "Sexism (t-1 minus t-2)", 
                               "Sexism (t-1 minus t-2) x Female",
                               "Increase in sexism (t-1 minus t-2)", 
                               "Increase in sexism (t-1 minus t-2) x Female",
                               "Decrease in sexism (t-1 minus t-2)",
                               "Decrease in sexism (t-1 minus t-2) x Female",
                               "Intercept"), 
          notes.append = FALSE, 
          no.space = TRUE, 
          title = "Effect of prior change in attitudes and vote intention on intended vote for Vox - interactions included"))

# ... print the La-TeX code to the console ...
cat(Table_E2)

```

```{r Part 1.2.4: Definition of Scenarios}

# .............................................................................#
# .................................. MODEL 1 ..................................#
# .............................................................................#

# ... we initiate by defining a sequence of the variable "lsmsexism" ranging from its minimum value to its maximum with a total of 1000 intervals in between. This same sequence will be used for the Model-1 as well as for the Model-2 simulations ... 
lsmsexism_seq_m12E2 <- seq(min(data_panel$lsmsexism[!is.na(data_panel$lsmsexism)]),
                          max(data_panel$lsmsexism[!is.na(data_panel$lsmsexism)]),
                          length.out = 1000)

# ... we then define the corresponding scenario ...
scenario_w_m1E2 <- cbind(1,                                              # Intercept 
                         0,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         lsmsexism_seq_m12E2,                            # Sexism-Sequence 
                         1 * lsmsexism_seq_m12E2                         # Interaction 
                         )   

scenario_m_m1E2 <- cbind(1,                                              # Intercept 
                         0,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         lsmsexism_seq_m12E2,                            # Sexism-Sequence 
                         0 * lsmsexism_seq_m12E2                         # Interaction 
                         )    

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m1E2 <- sim_function(coefs = coefficients_m1_E2, 
                              vcov = vcov_m1_E2, 
                              scenario = scenario_w_m1E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m1E2 <- sim_function(coefs = coefficients_m1_E2, 
                             vcov = vcov_m1_E2, 
                             scenario = scenario_m_m1E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# .................................. MODEL 2 ..................................#
# .............................................................................#

# ... we then define the corresponding scenario ...
scenario_w_m2E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         lsmsexism_seq_m12E2,                            # Sexism-Sequence 
                         1 * lsmsexism_seq_m12E2                         # Interaction 
                         )   

scenario_m_m2E2 <- cbind(1,                                              # Intercept 
                         0,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         lsmsexism_seq_m12E2,                            # Sexism-Sequence 
                         0 * lsmsexism_seq_m12E2                          # Interaction 
                         )    

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m2E2 <- sim_function(coefs = coefficients_m2_E2, 
                              vcov = vcov_m2_E2, 
                              scenario = scenario_w_m2E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m2E2 <- sim_function(coefs = coefficients_m2_E2, 
                             vcov = vcov_m2_E2, 
                             scenario = scenario_m_m2E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#

# ... we initiate by defining a sequence of the variable "posmsex" ranging from its minimum value to its maximum with a total of 1000 intervals in between. This same sequence will be used for the Model-3 as well as for the Model-4 simulations ... 
posmsex_seq_m34E2 <- seq(min(data_panel$posmsex[!is.na(data_panel$posmsex)]),
                          max(data_panel$posmsex[!is.na(data_panel$posmsex)]),
                          length.out = 1000)

# ... we then define the corresponding scenario ...
scenario_w_m3E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...  
                         posmsex_seq_m34E2,                              # posmsex-sequence
                         1 * posmsex_seq_m34E2,                          # Interaction
                         mean(data_panel$negmsex, na.rm = T)             # ...
                         )   

scenario_m_m3E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...  
                         posmsex_seq_m34E2,                              # posmsex-sequence
                         0 * posmsex_seq_m34E2,                          # Interaction
                         mean(data_panel$negmsex, na.rm = T)             # ...
                         ) 

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m3E2 <- sim_function(coefs = coefficients_m3_E2, 
                              vcov = vcov_m3_E2, 
                              scenario = scenario_w_m3E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m3E2 <- sim_function(coefs = coefficients_m3_E2, 
                             vcov = vcov_m3_E2, 
                             scenario = scenario_m_m3E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#

# ... we then define the corresponding scenario ...
scenario_w_m4E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...  
                         posmsex_seq_m34E2,                              # posmsex-sequence
                         1 * posmsex_seq_m34E2,                          # Interaction
                         mean(data_panel$negmsex, na.rm = T)             # ...
                         )   

scenario_m_m4E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...  
                         posmsex_seq_m34E2,                              # posmsex-sequence
                         0 * posmsex_seq_m34E2,                          # Interaction
                         mean(data_panel$negmsex, na.rm = T)             # ...
                         ) 

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m4E2 <- sim_function(coefs = coefficients_m4_E2, 
                              vcov = vcov_m4_E2, 
                              scenario = scenario_w_m4E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m4E2 <- sim_function(coefs = coefficients_m4_E2, 
                             vcov = vcov_m4_E2, 
                             scenario = scenario_m_m4E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#

# ... we initiate by defining a sequence of the variable "negmsex" ranging from its minimum value to its maximum with a total of 1000 intervals in between. This same sequence will be used for the Model-5 as well as for the Model-6 simulations ... 
negmsex_seq_m56E2 <- seq(min(data_panel$negmsex[!is.na(data_panel$negmsex)]),
                          max(data_panel$negmsex[!is.na(data_panel$negmsex)]),
                          length.out = 1000)

# ... we then define the corresponding scenario ...
scenario_w_m5E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         mean(data_panel$posmsex , na.rm = T),           # ...
                         negmsex_seq_m56E2,                              # negmsex-sequence
                         1 * negmsex_seq_m56E2                           # Interaction  
                         )   

scenario_m_m5E2 <- cbind(1,                                              # Intercept 
                         0,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         mean(data_panel$posmsex , na.rm = T),           # ...
                         negmsex_seq_m56E2,                              # negmsex-sequence
                         0 * negmsex_seq_m56E2                          # Interaction  
                         )   

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
sim_women_m5E2 <- sim_function(coefs = coefficients_m5_E2, 
                              vcov = vcov_m5_E2, 
                              scenario = scenario_w_m5E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m5E2 <- sim_function(coefs = coefficients_m5_E2, 
                             vcov = vcov_m5_E2, 
                             scenario = scenario_m_m5E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#

# ... we then define the corresponding scenario ...
scenario_w_m6E2 <- cbind(1,                                              # Intercept 
                         1,                                              # Female = 1 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         mean(data_panel$posmsex , na.rm = T),           # ...
                         negmsex_seq_m56E2,                              # negmsex-sequence
                         1 * negmsex_seq_m56E2                           # Interaction  
                         )   

scenario_m_m6E2 <- cbind(1,                                              # Intercept 
                         0,                                              # Female = 0 
                         mean(data_panel$age),                           # ...  
                         median(data_panel$edu3_2),                      # ...
                         median(data_panel$edu3_3),                      # ...
                         mean(data_panel$dhincome_all, na.rm = T),       # ... 
                         median(data_panel$livingpartner, na.rm = T),    # ... 
                         mean(data_panel$intpol, na.rm = T),             # ... 
                         median(data_panel$l2vim_vox , na.rm = T),       # ...
                         mean(data_panel$l2authoritarian  , na.rm = T),  # ...
                         mean(data_panel$l2ideol, na.rm = T),            # ...
                         mean(data_panel$l2nativism, na.rm = T),         # ...
                         mean(data_panel$l2orgterr, na.rm = T),          # ...
                         mean(data_panel$l2pop6amz, na.rm = T),          # ...
                         mean(data_panel$l2msexism, na.rm = T),          # ...
                         median(data_panel$lsvim_vox, na.rm = T),        # ...
                         mean(data_panel$lsauthoritarian, na.rm = T),    # ...
                         mean(data_panel$lsideol, na.rm = T),            # ...
                         mean(data_panel$lsnativism, na.rm = T),         # ...
                         mean(data_panel$lsorgterr, na.rm = T),          # ...
                         mean(data_panel$lspop6amz, na.rm = T),          # ...
                         mean(data_panel$posmsex , na.rm = T),           # ...
                         negmsex_seq_m56E2,                              # negmsex-sequence
                         0 * negmsex_seq_m56E2                           # Interaction  
                         )   

# ... having defined he scenarios, we proceed to implement the Simulation Function, specifying the appropriate inputs for each of the two scenarios specified above ...
library(MASS)
sim_women_m6E2 <- sim_function(coefs = coefficients_m6_E2, 
                              vcov = vcov_m6_E2, 
                              scenario = scenario_w_m6E2, 
                              response_function = response_function, 
                              stochastic_component = stochastic_component)$ev

sim_men_m6E2 <- sim_function(coefs = coefficients_m6_E2, 
                             vcov = vcov_m6_E2, 
                             scenario = scenario_m_m6E2, 
                             response_function = response_function, 
                             stochastic_component = stochastic_component)$ev

```


```{r 1.2.5: Estimation of Predicted Probabilities Using the Average Value Approach}

# .............................................................................#
# .................................. MODEL 1 ..................................#
# .............................................................................#

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m1E2 <- apply(sim_women_m1E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m1E2 <- apply(sim_women_m1E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m1E2 <- apply(sim_men_m1E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m1E2 <- apply(sim_men_m1E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = lsmsexism_seq_m12E2,
     y = apply(sim_women_m1E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2019)", 
     cex.main = 0.7,
     xlab = "Prior Change in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.7), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(min(lsmsexism_seq_m12E2), max(lsmsexism_seq_m12E2), length.out = 20), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(min(lsmsexism_seq_m12E2), max(lsmsexism_seq_m12E2), by = (max(lsmsexism_seq_m12E2) - min(lsmsexism_seq_m12E2)) / 10), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(lsmsexism_seq_m12E2, rev(lsmsexism_seq_m12E2)), c(upper_women_m1E2, rev(lower_women_m1E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(lsmsexism_seq_m12E2, rev(lsmsexism_seq_m12E2)), c(upper_men_m1E2, rev(lower_men_m1E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = lsmsexism_seq_m12E2, y = apply(sim_women_m1E2, 2, mean), lwd = 2, col = "red")
lines(x = lsmsexism_seq_m12E2, y = apply(sim_men_m1E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel$lsmsexism[data_panel$lsmsexism <= 150], 0.1), ticksize = 0.02, lwd = 1)

# .............................................................................#
# .................................. MODEL 2 ..................................#
# .............................................................................#

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m2E2 <- apply(sim_women_m2E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m2E2 <- apply(sim_women_m2E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m2E2 <- apply(sim_men_m2E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m2E2 <- apply(sim_men_m2E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = lsmsexism_seq_m12E2,
     y = apply(sim_women_m1E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2020)", 
     cex.main = 0.7,
     xlab = "Prior Change in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.7), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(min(lsmsexism_seq_m12E2), max(lsmsexism_seq_m12E2), length.out = 20), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(min(lsmsexism_seq_m12E2), max(lsmsexism_seq_m12E2), by = (max(lsmsexism_seq_m12E2) - min(lsmsexism_seq_m12E2)) / 10), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(lsmsexism_seq_m12E2, rev(lsmsexism_seq_m12E2)), c(upper_women_m1E2, rev(lower_women_m1E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(lsmsexism_seq_m12E2, rev(lsmsexism_seq_m12E2)), c(upper_men_m1E2, rev(lower_men_m1E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = lsmsexism_seq_m12E2, y = apply(sim_women_m1E2, 2, mean), lwd = 2, col = "red")
lines(x = lsmsexism_seq_m12E2, y = apply(sim_men_m1E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel$lsmsexism[data_panel$lsmsexism <= 150], 0.1), ticksize = 0.02, lwd = 1)

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#

par(mfrow = c(1, 2)) # This will allow us to display the Predicted Probabilities for Models 3 and 4 side by side ...

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m3E2 <- apply(sim_women_m3E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m3E2 <- apply(sim_women_m3E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m3E2 <- apply(sim_men_m3E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m3E2 <- apply(sim_men_m3E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = posmsex_seq_m34E2,
     y = apply(sim_women_m3E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2019)", 
     cex.main = 0.7,
     xlab = "Prior Increase in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 1), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 1, by = 0.05), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(0, 1, by = 0.1), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(posmsex_seq_m34E2, rev(posmsex_seq_m34E2)), c(upper_women_m3E2, rev(lower_women_m3E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(posmsex_seq_m34E2, rev(posmsex_seq_m34E2)), c(upper_men_m3E2, rev(lower_men_m3E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = posmsex_seq_m34E2, y = apply(sim_women_m3E2, 2, mean), lwd = 2, col = "red")
lines(x = posmsex_seq_m34E2, y = apply(sim_men_m3E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel$posmsex[data_panel$posmsex <= 150], 0.1), ticksize = 0.02, lwd = 1)

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m4E2 <- apply(sim_women_m4E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m4E2 <- apply(sim_women_m4E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m4E2 <- apply(sim_men_m4E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m4E2 <- apply(sim_men_m4E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = posmsex_seq_m34E2,
     y = apply(sim_women_m4E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2020)", 
     cex.main = 0.7,
     xlab = "Prior Increase in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.5), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 1, by = 0.05), cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(0, 1, by = 0.1), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(posmsex_seq_m34E2, rev(posmsex_seq_m34E2)), c(upper_women_m4E2, rev(lower_women_m4E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(posmsex_seq_m34E2, rev(posmsex_seq_m34E2)), c(upper_men_m4E2, rev(lower_men_m4E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = posmsex_seq_m34E2, y = apply(sim_women_m4E2, 2, mean), lwd = 2, col = "red")
lines(x = posmsex_seq_m34E2, y = apply(sim_men_m4E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = c(0.5, 0.5), y = c(0.25, 0.28), labels = c("Women", "Men"), cex = 0.7, pos = 4, col = c("red", "blue"))

# Add distribution of actual observations
rug(jitter(data_panel$posmsex[data_panel$posmsex <= 150], 0.1), ticksize = 0.02, lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("Predicted_Probabilities_m3m4E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#

par(mfrow = c(1, 2)) # This will allow us to display the Predicted Probabilities for Models 3 and 4 side by side ...

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m5E2 <- apply(sim_women_m5E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m5E2 <- apply(sim_women_m5E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m5E2 <- apply(sim_men_m5E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m5E2 <- apply(sim_men_m5E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = negmsex_seq_m56E2,
     y = apply(sim_women_m5E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2019)", 
     cex.main = 0.7,
     xlab = "Prior Decrease in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.4), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), length.out = 10), 
     labels = round(seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), length.out = 10), 2), 
     cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), by = (max(negmsex_seq_m56E2) - min(negmsex_seq_m56E2)) / 10), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(negmsex_seq_m56E2, rev(negmsex_seq_m56E2)), c(upper_women_m5E2, rev(lower_women_m5E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(negmsex_seq_m56E2, rev(negmsex_seq_m56E2)), c(upper_men_m5E2, rev(lower_men_m5E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = negmsex_seq_m56E2, y = apply(sim_women_m5E2, 2, mean), lwd = 2, col = "red")
lines(x = negmsex_seq_m56E2, y = apply(sim_men_m5E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = -0.5, y = 0.35, labels = "Women", cex = 0.8, pos = 4, col = "red")
text(x = -0.5, y = 0.32, labels = "Men", cex = 0.8, pos = 4, col = "blue")

# Add distribution of actual observations
rug(jitter(data_panel$negmsex[data_panel$negmsex <= 150], 0.1), ticksize = 0.02, lwd = 1)

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#

# ... We initiate by calculating the confidence intervals as below ...
lower_women_m6E2 <- apply(sim_women_m6E2, 2, function(x) quantile(x, probs = 0.025))
upper_women_m6E2 <- apply(sim_women_m6E2, 2, function(x) quantile(x, probs = 0.975))
lower_men_m6E2 <- apply(sim_men_m6E2, 2, function(x) quantile(x, probs = 0.025))
upper_men_m6E2 <- apply(sim_men_m6E2, 2, function(x) quantile(x, probs = 0.975))

# ... and then plot the estimated predicted probabilities using the confidence intervals we obtained above ...
plot(x = negmsex_seq_m56E2,
     y = apply(sim_women_m6E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "Predicted Probabiity of Intention to Vote for VOX (Year 2020)", 
     cex.main = 0.7,
     xlab = "Prior Decrease in Individual Sexism",
     ylab = "Pr(Intention to Vote for VOX)", 
     ylim = c(0, 0.5), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), length.out = 10), 
     labels = round(seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), length.out = 10), 2), 
     cex.axis = 0.7)

# ... we add a background grid ...
abline(h = seq(0, 1, by = 0.1), col = "grey90")
abline(v = seq(min(negmsex_seq_m56E2), max(negmsex_seq_m56E2), by = (max(negmsex_seq_m56E2) - min(negmsex_seq_m56E2)) / 10), col = "grey90")

# ... and add confidence intervals as shaded areas ...
polygon(c(negmsex_seq_m56E2, rev(negmsex_seq_m56E2)), c(upper_women_m6E2, rev(lower_women_m6E2)), col = rgb(1, 0, 0, 0.2), border = NA)
polygon(c(negmsex_seq_m56E2, rev(negmsex_seq_m56E2)), c(upper_men_m6E2, rev(lower_men_m6E2)), col = rgb(0, 0, 1, 0.2), border = NA)

# Predicted probabilities for treatment and control group
lines(x = negmsex_seq_m56E2, y = apply(sim_women_m6E2, 2, mean), lwd = 2, col = "red")
lines(x = negmsex_seq_m56E2, y = apply(sim_men_m6E2, 2, mean), lwd = 2, col = "blue")

# Some annotations
text(x = -0.5, y = 0.35, labels = "Women", cex = 0.8, pos = 4, col = "red")
text(x = -0.5, y = 0.32, labels = "Men", cex = 0.8, pos = 4, col = "blue")

# Add distribution of actual observations
rug(jitter(data_panel$negmsex[data_panel$negmsex <= 150], 0.1), ticksize = 0.02, lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("Predicted_Probabilities_m5m6E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

```{r Part 1.2.6: Estimation of First Differences}

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#

par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the models 3 and 4 side by side ...

# ... we initiate by estimating the first differences ...
fd_m3E2 <- sim_women_m3E2 - sim_men_m3E2

# ... we then generate the display plot ...
plot(x = posmsex_seq_m34E2,
     y = apply(fd_m3E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2019)", 
     cex.main = 0.7,
     xlab = "Prior Increase in Individual Sexism",
     ylab = "FD", 
     ylim=c(-0.8, 0.6), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m3E2, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m3E2, 2, quantile, 0.025),
      lty = "dashed")
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m3E2, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#

# ... we initiate by estimating the first differences ...
fd_m4E2 <- sim_women_m4E2 - sim_men_m4E2

# ... we then generate the display plot ...
plot(x = posmsex_seq_m34E2,
     y = apply(fd_m4E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2020)", 
     cex.main = 0.7,
     xlab = "Prior Increase in Individual Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.4), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m4E2, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m4E2, 2, quantile, 0.025),
      lty = "dashed")
lines(x = posmsex_seq_m34E2,
      y = apply(fd_m4E2, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_AVA_m3m4E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#

par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the models 5 and 6 side by side ...

# ... we initiate by estimating the first differences ...
fd_m5E2 <- sim_women_m5E2 - sim_men_m5E2

# ... we then generate the display plot ...
plot(x = negmsex_seq_m56E2,
     y = apply(fd_m5E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2019)", 
     cex.main = 0.7,
     xlab = "Prior Decrease in Individual Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.2), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m5E2, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m5E2, 2, quantile, 0.025),
      lty = "dashed")
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m5E2, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#

# ... we initiate by estimating the first differences ...
fd_m6E2 <- sim_women_m6E2 - sim_men_m6E2

# ... we then generate the display plot ...
plot(x = negmsex_seq_m56E2,
     y = apply(fd_m6E2, 2, mean),
     type = "n",
     lwd = 2,
     main = "First Difference Women - Men (2020)", 
     cex.main = 0.7,
     xlab = "Prior Decrease in Individual Sexism",
     ylab = "FD", 
     ylim=c(-0.4, 0.4), 
     cex.axis = 0.7, 
     cex.lab = 0.7,
     xaxt = "n")
axis(1, at = seq(0, 150, by = 25),
     cex.axis = 0.7)

# Background Raster
abline(h = seq(-0.4, 0.6, by = 0.2), 
       col = "grey90")
abline(v = seq(0, 150, by = 25), 
       col = "grey90")

# FD
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m6E2, 2, mean),
      lwd = 2)

# Confidence Intervals
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m6E2, 2, quantile, 0.025),
      lty = "dashed")
lines(x = negmsex_seq_m56E2,
      y = apply(fd_m6E2, 2, quantile, 0.975),
      lty = "dashed")

# vertical line at y = 0
abline(h = 0, 
       lwd = 1)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_AVA_m5m6E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

```{r Part 1.2.7: Generation of Model Matrices for OVA}

# Before estimating the First Differences using the Observed Value Approach (OVA), we first have to generate the matrices containing the independent variables + the intercept for each of the models under consideration ...

# We first generate two temporary data subsets ...
# ... one to include only rows where year == 2019 ...
data_panel_2019 <- data_panel %>% filter(year == 2019)
# ... and the second to only include rows where year == 2020 ...
data_panel_2020 <- data_panel %>% filter(year == 2020)

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#

# ... we define the specification used in the corresponding model ...
formula_m3_E2 <- affirmative_vox ~ 
                 female +                     
                 age +                        
                 edu3_2 +                     
                 edu3_3 +                     
                 dhincome_all +               
                 livingpartner +              
                 intpol +                     
                 l2vim_vox +                  
                 l2authoritarian +            
                 l2ideol +                    
                 l2nativism +                 
                 l2orgterr +                  
                 l2pop6amz +                  
                 l2msexism +                  
                 lsvim_vox +                  
                 lsauthoritarian +            
                 lsideol +                    
                 lsnativism +                 
                 lsorgterr +                  
                 lspop6amz +                  
                 posmsex +                    
                 int_m34E2 +                   
                 negmsex

# Create the design matrix
X_m3E2 <- model.matrix(formula_m3_E2, data = data_panel_2019)
X_m3E2 <- as.matrix(X_m3E2)

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#

# ... we define the specification used in the corresponding model ...
formula_m4_E2 <- affirmative_vox ~ 
                 female +                      
                 age +                        
                 edu3_2 +                     
                 edu3_3 +                     
                 dhincome_all +               
                 livingpartner +              
                 intpol +                     
                 l2vim_vox +                  
                 l2authoritarian +            
                 l2ideol +                    
                 l2nativism +                 
                 l2orgterr +                  
                 l2pop6amz +                  
                 l2msexism +                  
                 lsvim_vox +                  
                 lsauthoritarian +            
                 lsideol +                    
                 lsnativism +                 
                 lsorgterr +                  
                 lspop6amz +                  
                 posmsex +                    
                 int_m34E2 +                   
                 negmsex    

# Create the design matrix
X_m4E2 <- model.matrix(formula_m4_E2, data = data_panel_2020)
X_m4E2 <- as.matrix(X_m4E2)

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#

# ... we define the specification used in the corresponding model ...
formula_m5_E2 <- affirmative_vox ~ 
                 female +                     
                 age +                        
                 edu3_2 +                     
                 edu3_3 +                     
                 dhincome_all +               
                 livingpartner +              
                 intpol +                     
                 l2vim_vox +                  
                 l2authoritarian +            
                 l2ideol +                    
                 l2nativism +                 
                 l2orgterr +                  
                 l2pop6amz +                  
                 l2msexism +                  
                 lsvim_vox +                  
                 lsauthoritarian +            
                 lsideol +                    
                 lsnativism +                 
                 lsorgterr +                  
                 lspop6amz +                  
                 posmsex +                     
                 negmsex+                     
                 int_m56E2

# Create the design matrix
X_m5E2 <- model.matrix(formula_m5_E2, data = data_panel_2019)
X_m5E2 <- as.matrix(X_m5E2)

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#

# ... we define the specification used in the corresponding model ...
formula_m6_E2 <- affirmative_vox ~ 
                  female +                      
               age +                        
               edu3_2 +                     
               edu3_3 +                     
               dhincome_all +               
               livingpartner +              
               intpol +                     
               l2vim_vox +                  
               l2authoritarian +            
               l2ideol +                    
               l2nativism +                 
               l2orgterr +                  
               l2pop6amz +                  
               l2msexism +                  
               lsvim_vox +                  
               lsauthoritarian +            
               lsideol +                    
               lsnativism +                 
               lsorgterr +                  
               lspop6amz +                  
               posmsex +                     
               negmsex+                     
               int_m56E2    

# Create the design matrix
X_m6E2 <- model.matrix(formula_m6_E2, data = data_panel_2020)
X_m6E2 <- as.matrix(X_m6E2)

```

```{r Part 1.2.8: Estimation of First Differences Using the Observed Value Approach}

# .............................................................................#
# .................................. MODEL 3 ..................................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m3E2 <- array(NA, c(dim(X_m3E2), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m3E2[, ,] <- X_m3E2

# select the columns to adjust for simulation 
sel1_m3E2 <- which(colnames(X_m3E2) == "female")
sel2_m3E2 <- which(colnames(X_m3E2) == "int_m34E2")

# assign 0 to "female" column in layer 1
cases_m3E2[, sel1_m3E2, 1] <- 0
# assign 1 to female column in layer 2
cases_m3E2[, sel1_m3E2, 2] <- 1

# assign 0 to interaction ("int_m34E2") column in layer 1
cases_m3E2[, sel2_m3E2, 1] <- 0*X_m3E2[, "female"]
# assign "female" value to interaction column in layer 2
cases_m3E2[, sel2_m3E2, 2] <- 1*X_m3E2[, "female"]

# Loop over the matrices.
val_m3E2 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m3E2 <- sim_function(coefs = coefficients_m3_E2 ,
                          vcov = vcov_m3_E2 ,
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m3E2[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m3E2 <- apply(ev_m3E2, 1, mean)
  val_m3E2[, i] <- tmp_val_m3E2
}

# ... we then estimate the first differences and store these in an object called "fd_m1E1" ...
fd_m3E2 <- val_m3E2[, 1] - val_m3E2[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# ... we first plot the histogram ...
hist(
  fd_m3E2,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2019)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m3E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m3E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m3E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m3E2), 3)), col = "black", pos = 4)
text(quantile(fd_m3E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m3E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m3E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m3E2, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m3E2),
  main = "Density Plot of Simulated First Differences (2019)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m3E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m3E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m3E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m3E2), 3)), col = "black", pos = 4)
text(quantile(fd_m3E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m3E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m3E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m3E2, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m3_E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# .................................. MODEL 4 ..................................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m4E2 <- array(NA, c(dim(X_m4E2), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m4E2[, ,] <- X_m4E2

# select the columns to adjust for simulation 
sel1_m4E2 <- which(colnames(X_m4E2) == "female")
sel2_m4E2 <- which(colnames(X_m4E2) == "int_m34E2")

# assign 0 to "female" column in layer 1
cases_m4E2[, sel1_m4E2, 1] <- 0
# assign 1 to female column in layer 2
cases_m4E2[, sel1_m4E2, 2] <- 1

# assign 0 to interaction ("int_m34E2") column in layer 1
cases_m4E2[, sel2_m4E2, 1] <- 0*X_m4E2[, "female"]
# assign "female" value to interaction column in layer 2
cases_m4E2[, sel2_m4E2, 2] <- 1*X_m4E2[, "female"]

# Loop over the matrices.
val_m4E2 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m4E2 <- sim_function(coefs = coefficients_m4_E2 ,
                          vcov = vcov_m4_E2 ,
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m4E2[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m4E2 <- apply(ev_m4E2, 1, mean)
  val_m4E2[, i] <- tmp_val_m4E2
}

# ... we then estimate the first differences and store these in an object called "fd_m4E2" ...
fd_m4E2 <- val_m4E2[, 1] - val_m4E2[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# ... we first plot the histogram ...
hist(
  fd_m4E2,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2020)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m4E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m4E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m4E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m4E2), 3)), col = "black", pos = 4)
text(quantile(fd_m4E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m4E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m4E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m4E2, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m4E2),
  main = "Density Plot of Simulated First Differences (2020)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m4E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m4E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m4E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m4E2), 3)), col = "black", pos = 4)
text(quantile(fd_m4E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m4E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m4E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m4E2, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m4_E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# .................................. MODEL 5 ..................................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m5E2 <- array(NA, c(dim(X_m5E2), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m5E2[, ,] <- X_m5E2

# select the columns to adjust for simulation 
sel1_m5E2 <- which(colnames(X_m5E2) == "female")
sel2_m5E2 <- which(colnames(X_m5E2) == "int_m56E2")

# assign 0 to "female" column in layer 1
cases_m5E2[, sel1_m5E2, 1] <- 0
# assign 1 to female column in layer 2
cases_m5E2[, sel1_m5E2, 2] <- 1

# assign 0 to interaction ("int_m56E2") column in layer 1
cases_m5E2[, sel2_m5E2, 1] <- 0*X_m5E2[, "female"]
# assign "female" value to interaction column in layer 2
cases_m5E2[, sel2_m5E2, 2] <- 1*X_m5E2[, "female"]

# Loop over the matrices.
val_m5E2 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m5E2 <- sim_function(coefs = coefficients_m5_E2 ,
                          vcov = vcov_m5_E2 ,
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m5E2[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m5E2 <- apply(ev_m5E2, 1, mean)
  val_m5E2[, i] <- tmp_val_m5E2
}

# ... we then estimate the first differences and store these in an object called "fd_m4E2" ...
fd_m5E2 <- val_m5E2[, 1] - val_m5E2[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# ... we first plot the histogram ...
hist(
  fd_m5E2,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2019)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m5E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m5E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m5E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m5E2), 3)), col = "black", pos = 4)
text(quantile(fd_m5E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m5E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m5E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m5E2, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m5E2),
  main = "Density Plot of Simulated First Differences (2019)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m5E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m5E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m5E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m5E2), 3)), col = "black", pos = 4)
text(quantile(fd_m5E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m5E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m5E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m5E2, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m5_E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

# .............................................................................#
# .................................. MODEL 6 ..................................#
# .............................................................................#

# ... we generate a 3D array with as many rows as there are observations (nrow(X)), as many columns as there are covariates in the X-matrix (ncol(X)), and a depth of 2 for each of the two scenarios that will be taken into account ...
cases_m6E2 <- array(NA, c(dim(X_m6E2), 2))  

# assign X values to all dimensions of cases 
# ie we get two identical layers of X matrices  
cases_m6E2[, ,] <- X_m6E2

# select the columns to adjust for simulation 
sel1_m6E2 <- which(colnames(X_m6E2) == "female")
sel2_m6E2 <- which(colnames(X_m6E2) == "int_m56E2")

# assign 0 to "female" column in layer 1
cases_m6E2[, sel1_m6E2, 1] <- 0
# assign 1 to female column in layer 2
cases_m6E2[, sel1_m6E2, 2] <- 1

# assign 0 to interaction ("int_m56E2") column in layer 1
cases_m6E2[, sel2_m6E2, 1] <- 0*X_m6E2[, "female"]
# assign "female" value to interaction column in layer 2
cases_m6E2[, sel2_m6E2, 2] <- 1*X_m6E2[, "female"]

# Loop over the matrices.
val_m6E2 <- matrix(NA, nrow = n_simulations, ncol = 2)

# for each layer in cases (third dimension)
for(i in 1:2) {
  ev_m6E2 <- sim_function(coefs = coefficients_m6_E2 ,
                          vcov = vcov_m6_E2 ,
                          response_function = response_function,
                          stochastic_component = stochastic_component,
                          scenario = cases_m6E2[,,i],
                          predicted_values = F
                          )$ev
  
  tmp_val_m6E2 <- apply(ev_m6E2, 1, mean)
  val_m6E2[, i] <- tmp_val_m6E2
}

# ... we then estimate the first differences and store these in an object called "fd_m4E2" ...
fd_m6E2 <- val_m6E2[, 1] - val_m6E2[, 2]

# ... we then proceed to generate the plots for a better visualization of the results ...
par(mfrow = c(1, 2)) # This will allow us to display the First Differences for the two models side by side ...

# ... we first plot the histogram ...
hist(
  fd_m6E2,
  breaks = 20,
  main = "Histogram of Simulated First Differences (2020)",
  xlab = "First Difference",
  las = 1,
  col = "lightblue",
  border = "white"
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m6E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m6E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m6E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m6E2), 3)), col = "black", pos = 4)
text(quantile(fd_m6E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m6E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m6E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m6E2, 0.975), 3)), col = "black", pos = 4)

# ... and we then generate a density plot ...
plot(
  density(fd_m6E2),
  main = "Density Plot of Simulated First Differences (2020)",
  xlab = "First Difference",
  ylab = "Density",
  las = 1,
  col = "lightblue",
  lwd = 2
)

# Add a line for the mean of the first differences
abline(v = mean(fd_m6E2), 
       col = "black",
       lwd = 2)

# Add dashed lines for the 2.5% and 97.5% quantiles
abline(v = quantile(fd_m6E2, c(0.025, 0.975)),
       col = "black",
       lty = "dashed",
       lwd = 2)

# Optionally, add text annotations for the mean and quantiles
text(mean(fd_m6E2), par("usr")[4] * 0.9, labels = paste("Mean:", round(mean(fd_m6E2), 3)), col = "black", pos = 4)
text(quantile(fd_m6E2, 0.025), par("usr")[4] * 0.8, labels = paste("2.5%:", round(quantile(fd_m6E2, 0.025), 3)), col = "black", pos = 4)
text(quantile(fd_m6E2, 0.975), par("usr")[4] * 0.8, labels = paste("97.5%:", round(quantile(fd_m6E2, 0.975), 3)), col = "black", pos = 4)

#_____________________________________________________________________________#
# ... the following command lines save the generated plots into a single PDF-file ...
dev.copy2pdf(file = ("First_Differences_OVA_m6_E2.pdf"), 
             family = "Times", 
             width = 12, 
             height=6)
#_____________________________________________________________________________#

```

## Analysis Part 2: Multinomial Choice Model and Fixed-Effects Regression 

``` {r multinomial function}
ll_mnl <- function(theta, X, Z) { #theta will contain all the coef (4*7), z - outcome matrix with T/F values
  # declarations
  k <- ncol(X) # k independent variables - 7 incl intercept
  J <- ncol(Z) # J choices in the dependent variable
  
  # create matrix of betas and set the first category to 0 - before it was a vector
  beta <- matrix(0, 
                 ncol = k, 
                 nrow = J)
  beta[-1, ] <- matrix(theta[1:(k * (J - 1))], #selects everything but the 1st row  - 7*3 - number of betas that we have
                       ncol = k, 
                       byrow = T)
  
  # Systematic component: utilities
  # X_i %*% beta_J in each row (i.e. for each available choice) - one row in x is multipl by one row in B - basic, loop through the rows
  V <- apply(beta, 1, # for each row(1) and column (2)
             function(b) 
               X %*% b) # we have as many rows as respondents,
  
  # Sum of exp(V)
  Sexp <- apply(V, 1, function(v) #apply sum function to all the rows - sum of the exp of rows in v ---> 1 value for each observation --- vector now
    sum(exp(v)))
  
  # probabilities
  P <- apply(V, 2, function(v) #apply to columns -- prob to vote for specific party
    exp(v) / Sexp)
  
  # log-likelihood
  loglik <- sum(log(P[Z])) #subset prob of a chosen categories (Z is T/F matrix) -multipl
  return(loglik)
}
```

``` {r common var}

# Step 1: Identify all variables that begin with "lm1"
lm1_vars <- grep("^lm1", names(data_panel), value = TRUE)

# Step 2: Combine all the variables into a single list of columns to check
all_vars1 <- c("female", "age", "edu3_2", "edu3_3", "dhincome_all", "livingpartner", "intpol", lm1_vars)

# Step 3: Filter the dataset for complete cases (rows with no missing values in these columns)
complete_cases1 <- complete.cases(data_panel[, all_vars1])
data_panel_complete1 <- data_panel[complete_cases1, ]

missing_values <- c(54, 55)

# ... we then create a duplicate of the variable variable "voteintentionspain" where the values defined above are coded as missing values for the duplicate/new variable ...
data_panel_complete1$voteintentionspain_redef <- ifelse(data_panel_complete1$voteintentionspain %in% missing_values, NA, data_panel_complete1$voteintentionspain)

data_panel_complete1  <- data_panel_complete1  %>%
   mutate(combined_dep_var = case_when(
    voteintentionspain_redef == 23 ~ "Vox",
    voteintentionspain_redef %in% c(51, 52, 53) ~ "No vote",
    TRUE ~ "Other"# Default case for all other values
  ))
na.omit(data_panel_complete1$combined_dep_var)
data_panel_complete1$combined_dep_var <- factor(data_panel_complete1$combined_dep_var)


cats1 <- sort(unique(data_panel_complete1$combined_dep_var))  # different categories - need it to make a matrix with choices
J1 <- length(unique(data_panel_complete1$combined_dep_var))  # number of categories

Z1 <- matrix(NA, 
            nrow = length(data_panel_complete1$combined_dep_var), 
            ncol = J1)  # indicator matrix

for (j in 1:J1) {
  Z1[, j] <- data_panel_complete1$combined_dep_var == cats1[j] #vote choice equals category or not
}
colnames(Z1) <- cats

dim(Z1)
# Sanity check
head(Z1)
head(data_panel_complete1$combined_dep_var)

# Prepare our usual matrix X
# we include relig, class, income, educ, age, urban
# those variables are in column 6 to 11 in our data frame



# Remove NA values for binary or categorical variables directly
female1 <- as.numeric(data_panel_complete1$female)
female1 <- female1[!is.na(female1)]

# Convert to numeric and remove NA values, with debugging
age1 <- as.numeric(data_panel_complete1$age)
age1 <- age1[!is.na(age1)]

edu3_21 <- as.numeric(data_panel_complete1$edu3_2)
edu3_21 <- edu3_21[!is.na(edu3_21)]

edu3_31 <- as.numeric(data_panel_complete1$edu3_3)
edu3_31 <- edu3_31[!is.na(edu3_31)]

# Remove NA values directly (already numeric in example)
dhincome_all1 <- data_panel_complete1$dhincome_all[!is.na(data_panel_complete1$dhincome_all)]
lm1_authoritarian1 <- data_panel_complete1$lm1_authoritarian[!is.na(data_panel_complete1$lm1_authoritarian)]

# Convert to numeric and remove NA values, with debugging
livingpartner1 <- as.numeric(data_panel_complete1$livingpartner)
livingpartner1 <- livingpartner1[!is.na(livingpartner1)]

intpol1 <- as.numeric(data_panel_complete1$intpol)
intpol1 <- intpol1[!is.na(intpol1)]

lm1_ideol1 <- as.numeric(data_panel_complete1$lm1_ideol)
lm1_ideol1 <- lm1_ideol1[!is.na(lm1_ideol1)]

lm1_nativism1 <- as.numeric(data_panel_complete1$lm1_nativism)
lm1_nativism1 <- lm1_nativism1[!is.na(lm1_nativism1)]

lm1_orgterr1 <- as.numeric(data_panel_complete1$lm1_orgterr)
lm1_orgterr1 <- lm1_orgterr1[!is.na(lm1_orgterr1)]

lm1_pop6amz1 <- as.numeric(data_panel_complete1$lm1_pop6amz)
lm1_pop6amz1 <- lm1_pop6amz1[!is.na(lm1_pop6amz1)]

lm1_msexism1 <- as.numeric(data_panel_complete1$lm1_msexism)
lm1_msexism1 <- lm1_msexism1[!is.na(lm1_msexism1)]

#int_m1E1 <- as.numeric(data_panel$int_m1E1)
#int_m1E1 <- int_m1E1[!is.na(int_m1E1)]

lengths <- sapply(list(female, age, edu3_2, edu3_3, dhincome_all, livingpartner, intpol, lm1_authoritarian, lm1_ideol, lm1_nativism, lm1_orgterr, lm1_pop6amz, lm1_msexism), length)
print(lengths)


X1 <- as.matrix( cbind(1,female1, age1, edu3_21, edu3_31, dhincome_all1, livingpartner1, intpol1, lm1_authoritarian1, lm1_ideol1, lm1_nativism1,
lm1_orgterr1, lm1_pop6amz1,lm1_msexism1))
#X1 <- na.omit(X1)
class(X1)
dim(X1)

```

``` {r regression}
startvals1 <- rep(0, ncol(X1) * (J1 - 1))

res111 <- optim(
  startvals1,
  ll_mnl,
  X = X1,
  Z = Z1,
  method = "BFGS",
  control = list(fnscale = -1, trace = TRUE),
  hessian = TRUE
)

res111$par 
betaHat <- matrix(res111$par,
                  ncol = ncol(X1), #number of indep var - 7
                  nrow = ncol(Z1)-1, #but we need to estimate 3 row instead of 4
                  byrow = T)

colnames(betaHat) <- c("(Intercept)", colnames(X1)[2:ncol(X1)])
rownames(betaHat) <-  levels(data_panel_complete1$combined_dep_var)[2:ncol(Z1)]


se <-
  matrix(sqrt(diag(solve(-res111$hessian))),
         ncol = ncol(X1),
         nrow = ncol(Z1)-1,
         byrow = T)
colnames(se) <- c("(Intercept)", colnames(X1)[2:ncol(X1)])
rownames(se) <-  levels(data_panel_complete1$combined_dep_var)[2:ncol(Z1)]

betaHat
se
```

``` {r check - issue here :(}
library('nnet')
data_panel_complete1$combined_dep_var <- factor(data_panel_complete1$combined_dep_var)
data_panel_complete1$combined_dep_var <- relevel(data_panel_complete1$combined_dep_var, ref = "No vote")
check <- multinom(combined_dep_var ~ 
                    female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol+ lm1_authoritarian+lm1_ideol+ lm1_nativism+
                    lm1_orgterr + lm1_pop6amz + lm1_msexism, 
                  data = data_panel_complete1)

summary(check)
betaHat
se
```

``` {r QOI}
# Get coefficients and the variance-covariance matrix for the simulation
mu <- res111$par
varcov <- solve(-res111$hessian)

# Define nsim, J (number of categories) and k (number of independent variables)
nsim <- 1000
J <- length(unique(data_panel_complete1$combined_dep_var))  # Number of categories
k <- ncol(X1)

set.seed(123)
# Set up the sampling distribution
S <- mvrnorm(nsim, mu, varcov)

# Store in an array similar to what we did in the ll function - we need to make a matrix - J rows, k columns and 1000 times
beta_S <- array(0, dim = c(J, k, nsim))

# Check dimensions:
dim(beta_S)

# fill the array with the sampling distribution of betas
for(sim in 1:nsim) { #take first set of betas and put in the matrix, go to the second layer, etc, etc
  beta_S[-1, ,sim] <- matrix(S[sim,],  #select everything but 1 row
                             ncol = k, 
                             byrow = T)
} #1000 matrices behind each other - each set of b is a matrix

beta_S
# Set up your scenarios
n_scenarios <- 2 # Number of scenarios; in the first scen everybody is not relig, in the 2nd - relig

cases <- array(NA, c(dim(X1),
                     n_scenarios))  

cases[, , ] <- X1 #fill with x

sel <- which(colnames(X1) == "female")

cases[, sel, 1] <- 0 #first case - male
cases[,,1]
cases[, sel, 2] <- 1 #second - everyone female
cases[,,2]

# Now our array V will have four (!) dimensions
V <- V2 <- #matrix of utilities
  array(NA, 
        dim = c(nrow(X1),       # number of observations - row
                J,             # number of categories - this form a matrix n*4 -columns
                nsim,          # number of simulations - how often we put each case behind each other
                n_scenarios))  # number of scenarios 
#the 1st column is always 0 (utilities to vote for CDA), 2nd row utility for 1st observation to vote for 3 parties (3 columns) - and again we do this 1000 times
# and we do it one more time for relig case ---> we have 4 dimens in total

# Loop over the scenarios
for(i in 1:n_scenarios){ #loop through the scenarios - in the 1 iter we go to non-relig, 2 - relig
  V[,,,i] <- apply(beta_S[,,], c(1,3),  #c(1,3)= every rpw in eacj simu
                   function(bs) cases[,,i] %*% bs) #obsevred values in the 1/2 iter * betas
}

# the apply command over more than two dimensions is hard!
# maybe a nested loop is more intuitive to understand what is happening here:


# Have a look at the dimensions
dim(V)

# Now we want to summarize over multiple dimensions
Sexp <- apply(V, c(1,3,4), function(v) sum(exp(v))) #sum of each row ; 1,3,4 - dimensions

dim(Sexp) #observ*simul *scenarios

# With V and Sexp we have everything to get P
P <- array(NA, c(nsim, J, n_scenarios))

for (scen in 1:n_scenarios) {
  for (category in 1:J) { #each column is div by the sum
    P[, category, scen] <- 
      apply(exp(V[, category, , scen]) / Sexp[, , scen], 2, mean) #apply to each indiv sim; apply to the sim in the 2nd dimen (simul)
  }
}

# Summarize to get our quantities of interest

# non-religious voters
QoI0Mean <- apply(P[, , 1], 2, mean)
QoI0CI <-
  apply(P[, , 1], 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

# religious voters
QoI1Mean <- apply(P[, , 2], 2, mean)
QoI1CI <-
  apply(P[, , 2], 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

partycolors <- c("mediumseagreen", 
                 "red", 
                 "orange")

QoIFD <- P[, , 2] - P[, , 1]

QoIFDMean <- apply(QoIFD, 2, mean)
QoIFDCI <-
  apply(QoIFD, 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

plot(
  x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y = c(QoI0Mean, QoI1Mean)
)
```

``` {r graph}
plot(
  x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y = c(QoI0Mean, QoI1Mean),
  xlim = c(0.1, 0.8),
  ylim = c(0.01, 0.9),
  bty = "n",
  xaxt = "n",
  las = 1,
  xlab = "",
  ylab = "Predicted Probability of Voting for Party",
  main = "Female and Male",
  font.main = 1,
  type = "n"
)
abline(h = seq(0, 0.9, 0.1),
       col = adjustcolor("black", alpha = 0.2))
points(
  x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y = c(QoI0Mean, QoI1Mean),
  pch = 19,
  cex = 1,
  col = partycolors
)
text(1,
     x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
   y = rep(0.01, 4),
   labels = rep(c("female", "male"), each = 3),
     srt = 45,
     cex = 0.9,
   pos=3)
axis(1, 
     at = c(0.2, 0.4, 0.6),
     labels = levels(data_panel_complete1$combined_dep_var),
     tick = F)
segments(
  x0 = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y0 = c(QoI0CI[1,], QoI1CI[1,]),
  y1 = c(QoI0CI[2,], QoI1CI[2,]) ,
  lwd = 6,
  lend = 1,
  col = adjustcolor(partycolors, alpha = 0.4)
)
abline(v = c(0.3, 0.55, 0.7),
       lty = "dashed",
       col = "lightgrey")

plot(
  x = c(0.2, 0.4, 0.6),
  y = QoIFDMean,
  xlim = c(0.1, 0.9),
  ylim = c(-0.5, 0.5),
  bty = "n",
  xaxt = "n",
  las = 1,
  xlab = "",
  ylab = "First Difference",
  main = "First Difference between female and not male voters",
  font.main = 1,
  type = "n"
)
abline(h = seq(-0.4, 0.4, 0.1),
       col = adjustcolor("black", alpha = 0.2))
abline(h = 0, lwd = 1, lty = "solid")
points(
  x = c(0.2, 0.4, 0.6),
  y = QoIFDMean,
  pch = 19,
  cex = 1,
  col = partycolors
)
text(x = (c(0.2, 0.4, 0.6) - 0.06),
     y = QoIFDMean,
     labels = levels(data_panel_complete1$combined_dep_var))
segments(
  x0 = c(0.2, 0.4, 0.6),
  y0 = QoIFDCI[1,],
  y1 = QoIFDCI[2,],
  lwd = 6,
  lend = 1,
  col = adjustcolor(partycolors, alpha = 0.4)
)
abline(v = c(0.3, 0.5, 0.7),
       lty = "dashed",
       col = "lightgrey")
```

``` {r simulation sexism}

lm1_msexism <- na.omit(as.numeric(data_panel$lm1_msexism))

sexism_seq <- seq(min(lm1_msexism), max(lm1_msexism), length.out = 10)


# Get coefficients and the variance-covariance matrix for the simulation
mu <- res111$par
varcov <- solve(-res111$hessian)

# Define nsim, J (number of categories) and k (number of independent variables)
nsim <- 1000
J <- length(unique(data_panel_complete$combined_dep_var))  # Number of categories
k <- ncol(X1)

# Set up the sampling distribution
S <- mvrnorm(nsim, mu, varcov)

# Store in an array similar to what we did in the ll function - we need to make a matrix - J rows, k columns and 1000 times
beta_S <- array(0, dim = c(J, k, nsim))

# Check dimensions:
dim(beta_S)

# fill the array with the sampling distribution of betas
for(sim in 1:nsim) { #take first set of betas and put in the matrix, go to the second layer, etc, etc
  beta_S[-1, ,sim] <- matrix(S[sim,],  #select everything but 1 row
                             ncol = k, 
                             byrow = T)
} #1000 matrices behind each other - each set of b is a matrix

beta_S

sel <- which(colnames(X1) == "lm1_msexism") # column 4
# Set up your scenarios
n_scenarios <- length(sexism_seq) # Number of scenarios; 10 as we have 10 cases

cases <- array(NA, c(dim(X1),
                     n_scenarios))  
dim(cases)

cases[, , ] <- X1 #fill with x

for (i in 1:n_scenarios) {
  cases[, sel, i] <-sexism_seq[i] #take observ values and assume that everyone has min income, 2nd time at 11 level, etc.
}


# Now our array V will have four (!) dimensions
 V2 <- #matrix of utilities
  array(NA, 
        dim = c(nrow(X1),       # number of observations - row
                J,             # number of categories - this form a matrix n*4 -columns
                nsim,          # number of simulations - how often we put each case behind each other
                n_scenarios))  # number of scenarios 
#the 1st column is always 0 (utilities to vote for CDA), 2nd row utility for 1st observation to vote for 3 parties (3 columns) - and again we do this 1000 times
# and we do it one more time for relig case ---> we have 4 dimens in total
dim(V2)

# 1) Loop over the scenarios
for (i in 1:n_scenarios) {
  # 2) in each scenario:
  #    loop over the simulations
  for (s in 1:nsim) {
    # 3) in each scenario and simulation:
    #    loop over the categories and calculate its utility
    for (j in 1:J) {
      # 4) calculate utility for the utility of 
      #    - the current scenario
      #    - based on the current set of simulated beta values
      #    - for the current outcome category
      
      V2[,j,s,i] <- cases[,,i] %*% beta_S[j,,s] 
      
      # cases[,,i] the i-th scenario that we specified
      # beta_S[j,,s] is the s-th simulation of beta for category j 
      # (remember: there's one set of beta for each category and each simulation)
    }
  }
}

# the apply command over more than two dimensions is hard!
# maybe a nested loop is more intuitive to understand what is happening here:

# Have a look at the dimensions
dim(V2)

# Now we want to summarize over multiple dimensions
Sexp <- apply(V2, c(1,3,4), function(v) sum(exp(v))) #sum of each row ; 1,3,4 - dimensions

dim(Sexp) #observ*simul *scenarios

# With V and Sexp we have everything to get P
P <- array(NA, c(nsim, J, n_scenarios))
dim(P)

for (scen in 1:n_scenarios) {
  for (category in 1:J) { #each column is div by the sum
    P[, category, scen] <- 
      apply(exp(V2[, category, , scen]) / Sexp[, , scen], 2, mean) #apply to each indiv sim; apply to the sim in the 2nd dimen (simul)
  }
}

P
# Summarize to get our quantities of interest

QoImean <- matrix(NA, nrow = 3, ncol = n_scenarios)
QoICI <- array(NA, dim = c(2,     # lower and upper bound
                           3,     # number of categories
                           10))   # number of scenarios


QoI_Mean <- apply(P, c(2, 3), mean) #mean of columns because each colum address each party, apply to every column in every layer
QoI_CI <-
  apply(P, c(2, 3), function(x)
    quantile(x, probs = c(0.025, 0.975)))

partycolors <- c("mediumseagreen", 
                 "red", 
                 "orange")
# Plot the results

plot(
  sexism_seq,
  QoI_Mean[1,],
  type = "n",
  ylim = c(0, 1),
  bty = "n",
  ylab = "Predicted Probability of voting for Party",
  xlab = "Sexism",
  main = "The Effect of Sexism",
  las = 1
)

for (i in 1:3) {
  lines(sexism_seq, QoI_Mean[i,], 
        col = partycolors[i],
        lwd = 2)
}

for (i in 1:3) {
  polygon(
    c(rev(sexism_seq), sexism_seq),
    c(rev(QoI_CI[1, i,]), QoI_CI[2, i,]),
    col = adjustcolor(partycolors[i], alpha = 0.2) ,
    border = NA
  )
}

legend(
  "topright",
  legend = levels(data_panel_complete$combined_dep_var),
  lty = 1,
  col = partycolors,
  bty = "n"
)

```
``` {r model 2020}
# Step 1: Identify all variables that begin with "lm1"
lm2_vars <- grep("^lm2", names(data_panel), value = TRUE)

# Step 2: Combine all the variables into a single list of columns to check
all_vars <- c("female", "age", "edu3_2", "edu3_3", "dhincome_all", "livingpartner", "intpol", lm2_vars)

# Step 3: Filter the dataset for complete cases (rows with no missing values in these columns)
complete_cases <- complete.cases(data_panel[, all_vars])
data_panel_complete <- data_panel[complete_cases, ]

missing_values <- c(54, 55)

# ... we then create a duplicate of the variable variable "voteintentionspain" where the values defined above are coded as missing values for the duplicate/new variable ...
data_panel_complete$voteintentionspain_redef <- ifelse(data_panel_complete$voteintentionspain %in% missing_values, NA, data_panel_complete$voteintentionspain)

data_panel_complete  <- data_panel_complete  %>%
   mutate(combined_dep_var = case_when(
    voteintentionspain_redef == 23 ~ "Vox",
    voteintentionspain_redef %in% c(51, 52, 53) ~ "No vote",
    TRUE ~ "Other"# Default case for all other values
  ))
na.omit(data_panel_complete$combined_dep_var)
data_panel_complete$combined_dep_var <- factor(data_panel_complete $combined_dep_var)


cats <- sort(unique(data_panel_complete $combined_dep_var))  # different categories - need it to make a matrix with choices
J1 <- length(unique(data_panel_complete $combined_dep_var))  # number of categories

Z1 <- matrix(NA, 
            nrow = length(data_panel_complete $combined_dep_var), 
            ncol = J1)  # indicator matrix

for (j in 1:J1) {
  Z1[, j] <- data_panel_complete $combined_dep_var == cats[j] #vote choice equals category or not
}
colnames(Z1) <- cats

dim(Z1)
# Sanity check
head(Z1)
head(data_panel_complete $combined_dep_var)

# Prepare our usual matrix X
# we include relig, class, income, educ, age, urban
# those variables are in column 6 to 11 in our data frame



# Remove NA values for binary or categorical variables directly
female <- as.numeric(data_panel_complete$female)
female <- female[!is.na(female)]

# Convert to numeric and remove NA values, with debugging
age <- as.numeric(data_panel_complete$age)
age <- age[!is.na(age)]

edu3_2 <- as.numeric(data_panel_complete$edu3_2)
edu3_2 <- edu3_2[!is.na(edu3_2)]

edu3_3 <- as.numeric(data_panel_complete$edu3_3)
edu3_3 <- edu3_3[!is.na(edu3_3)]

# Remove NA values directly (already numeric in example)
dhincome_all <- data_panel_complete$dhincome_all[!is.na(data_panel_complete$dhincome_all)]
lm2_authoritarian <- data_panel_complete$lm2_authoritarian[!is.na(data_panel_complete$lm2_authoritarian)]

# Convert to numeric and remove NA values, with debugging
livingpartner <- as.numeric(data_panel_complete$livingpartner)
livingpartner <- livingpartner[!is.na(livingpartner)]

intpol <- as.numeric(data_panel_complete$intpol)
intpol <- intpol[!is.na(intpol)]

lm2_ideol <- as.numeric(data_panel_complete$lm2_ideol)
lm2_ideol <- lm2_ideol[!is.na(lm2_ideol)]

lm2_nativism <- as.numeric(data_panel_complete$lm2_nativism)
lm2_nativism <- lm2_nativism[!is.na(lm2_nativism)]

lm2_orgterr <- as.numeric(data_panel_complete$lm2_orgterr)
lm2_orgterr <- lm2_orgterr[!is.na(lm2_orgterr)]

lm2_pop6amz <- as.numeric(data_panel_complete$lm2_pop6amz)
lm2_pop6amz <- lm2_pop6amz[!is.na(lm2_pop6amz)]

lm2_msexism <- as.numeric(data_panel_complete$lm2_msexism)
lm2_msexism <- lm2_msexism[!is.na(lm2_msexism)]

#int_m1E1 <- as.numeric(data_panel$int_m1E1)
#int_m1E1 <- int_m1E1[!is.na(int_m1E1)]

lengths <- sapply(list(female, age, edu3_2, edu3_3, dhincome_all, livingpartner, intpol, lm2_authoritarian, lm2_ideol, lm2_nativism, lm2_orgterr, lm2_pop6amz, lm2_msexism), length)
print(lengths)


X2 <- as.matrix( cbind(1,female, age, edu3_2, edu3_3, dhincome_all, livingpartner, intpol, lm2_authoritarian, lm2_ideol, lm2_nativism,
lm2_orgterr, lm2_pop6amz,lm2_msexism))
#X1 <- na.omit(X1)
class(X2)
dim(X2)
```

``` {r regression}
startvals2 <- rep(0, ncol(X2) * (J1 - 1))

res22 <- optim(
  startvals2,
  ll_mnl,
  X = X2,
  Z = Z1,
  method = "BFGS",
  control = list(fnscale = -1, trace = TRUE),
  hessian = TRUE
)

res22$par 
betaHat <- matrix(res22$par,
                  ncol = ncol(X2), #number of indep var - 7
                  nrow = ncol(Z1)-1, #but we need to estimate 3 row instead of 4
                  byrow = T)

colnames(betaHat) <- c("(Intercept)", colnames(X2)[2:ncol(X2)])
rownames(betaHat) <-  levels(data_panel_complete$combined_dep_var)[2:ncol(Z1)]


se <-
  matrix(sqrt(diag(solve(-res22$hessian))),
         ncol = ncol(X2),
         nrow = ncol(Z1)-1,
         byrow = T)
colnames(se) <- c("(Intercept)", colnames(X2)[2:ncol(X2)])
rownames(se) <-  levels(data_panel$combined_dep_var)[2:ncol(Z1)]

betaHat
se

```


```{r simulation 2020}
#Get coefficients and the variance-covariance matrix for the simulation
mu <- res22$par
varcov <- solve(-res22$hessian)

# Define nsim, J (number of categories) and k (number of independent variables)
nsim <- 1000
J <- length(unique(data_panel_complete$combined_dep_var))  # Number of categories
k <- ncol(X2)

set.seed(123)
# Set up the sampling distribution
S <- mvrnorm(nsim, mu, varcov)

# Store in an array similar to what we did in the ll function - we need to make a matrix - J rows, k columns and 1000 times
beta_S <- array(0, dim = c(J, k, nsim))

# Check dimensions:
dim(beta_S)

# fill the array with the sampling distribution of betas
for(sim in 1:nsim) { #take first set of betas and put in the matrix, go to the second layer, etc, etc
  beta_S[-1, ,sim] <- matrix(S[sim,],  #select everything but 1 row
                             ncol = k, 
                             byrow = T)
} #1000 matrices behind each other - each set of b is a matrix

beta_S
# Set up your scenarios
n_scenarios <- 2 # Number of scenarios; in the first scen everybody is not relig, in the 2nd - relig

cases <- array(NA, c(dim(X2),
                     n_scenarios))  

cases[, , ] <- X2 #fill with x

sel <- which(colnames(X2) == "female")

cases[, sel, 1] <- 0 #first case - male
cases[,,1]
cases[, sel, 2] <- 1 #second - everyone female
cases[,,2]

# Now our array V will have four (!) dimensions
V <- V2 <- #matrix of utilities
  array(NA, 
        dim = c(nrow(X2),       # number of observations - row
                J,             # number of categories - this form a matrix n*4 -columns
                nsim,          # number of simulations - how often we put each case behind each other
                n_scenarios))  # number of scenarios 
#the 1st column is always 0 (utilities to vote for CDA), 2nd row utility for 1st observation to vote for 3 parties (3 columns) - and again we do this 1000 times
# and we do it one more time for relig case ---> we have 4 dimens in total

# Loop over the scenarios
for(i in 1:n_scenarios){ #loop through the scenarios - in the 1 iter we go to non-relig, 2 - relig
  V[,,,i] <- apply(beta_S[,,], c(1,3),  #c(1,3)= every rpw in eacj simu
                   function(bs) cases[,,i] %*% bs) #obsevred values in the 1/2 iter * betas
}

# the apply command over more than two dimensions is hard!
# maybe a nested loop is more intuitive to understand what is happening here:


# Have a look at the dimensions
dim(V)

# Now we want to summarize over multiple dimensions
Sexp <- apply(V, c(1,3,4), function(v) sum(exp(v))) #sum of each row ; 1,3,4 - dimensions

dim(Sexp) #observ*simul *scenarios

# With V and Sexp we have everything to get P
P <- array(NA, c(nsim, J, n_scenarios))

for (scen in 1:n_scenarios) {
  for (category in 1:J) { #each column is div by the sum
    P[, category, scen] <- 
      apply(exp(V[, category, , scen]) / Sexp[, , scen], 2, mean) #apply to each indiv sim; apply to the sim in the 2nd dimen (simul)
  }
}

# Summarize to get our quantities of interest

# non-religious voters
QoI0Mean1 <- apply(P[, , 1], 2, mean)
QoI0CI1 <-
  apply(P[, , 1], 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

# religious voters
QoI1Mean1 <- apply(P[, , 2], 2, mean)
QoI1CI1 <-
  apply(P[, , 2], 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

partycolors <- c("mediumseagreen", 
                 "red", 
                 "orange")

QoIFD1 <- P[, , 2] - P[, , 1]

QoIFDMean1 <- apply(QoIFD1, 2, mean)
QoIFDCI1 <-
  apply(QoIFD1, 2, function(x)
    quantile(x, probs = c(0.025, 0.975)))

```

``` {r plot pred prob and fd}
plot(
  x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y = c(QoI0Mean1, QoI1Mean1),
  xlim = c(0.1, 0.8),
  ylim = c(0.01, 0.9),
  bty = "n",
  xaxt = "n",
  las = 1,
  xlab = "",
  ylab = "Predicted Probability of Voting for Party",
  main = "Female and Male",
  font.main = 1,
  type = "n"
)
abline(h = seq(0, 0.9, 0.1),
       col = adjustcolor("black", alpha = 0.2))
points(
  x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y = c(QoI0Mean1, QoI1Mean1),
  pch = 19,
  cex = 1,
  col = partycolors
)
text(1,
     x = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
   y = rep(0.01, 4),
   labels = rep(c("female", "male"), each = 3),
     srt = 45,
     cex = 0.9,
   pos=3)
axis(1, 
     at = c(0.2, 0.4, 0.6),
     labels = levels(data_panel_complete$combined_dep_var),
     tick = F)
segments(
  x0 = c(0.2, 0.4, 0.6, 0.25, 0.45, 0.65),
  y0 = c(QoI0CI1[1,], QoI1CI1[1,]),
  y1 = c(QoI0CI1[2,], QoI1CI1[2,]) ,
  lwd = 6,
  lend = 1,
  col = adjustcolor(partycolors, alpha = 0.4)
)
abline(v = c(0.3, 0.55, 0.7),
       lty = "dashed",
       col = "lightgrey")

plot(
  x = c(0.2, 0.4, 0.6),
  y = QoIFDMean1,
  xlim = c(0.1, 0.9),
  ylim = c(-0.5, 0.5),
  bty = "n",
  xaxt = "n",
  las = 1,
  xlab = "",
  ylab = "First Difference",
  main = "First Difference between female and not male voters",
  font.main = 1,
  type = "n"
)
abline(h = seq(-0.4, 0.4, 0.1),
       col = adjustcolor("black", alpha = 0.2))
abline(h = 0, lwd = 1, lty = "solid")
points(
  x = c(0.2, 0.4, 0.6),
  y = QoIFDMean1,
  pch = 19,
  cex = 1,
  col = partycolors
)
text(x = (c(0.2, 0.4, 0.6) - 0.06),
     y = QoIFDMean1,
     labels = levels(data_panel_complete$combined_dep_var))
segments(
  x0 = c(0.2, 0.4, 0.6),
  y0 = QoIFDCI1[1,],
  y1 = QoIFDCI1[2,],
  lwd = 6,
  lend = 1,
  col = adjustcolor(partycolors, alpha = 0.4)
)
abline(v = c(0.3, 0.5, 0.7),
       lty = "dashed",
       col = "lightgrey")
```


``` {r sexism 2020}
lm2_msexism <- na.omit(as.numeric(data_panel$lm2_msexism))

sexism_seq <- seq(min(lm2_msexism), max(lm2_msexism), length.out = 10)


# Get coefficients and the variance-covariance matrix for the simulation
mu <- res22$par
varcov <- solve(-res22$hessian)

# Define nsim, J (number of categories) and k (number of independent variables)
nsim <- 1000
J <- length(unique(data_panel_complete$combined_dep_var))  # Number of categories
k <- ncol(X2)

# Set up the sampling distribution
S <- mvrnorm(nsim, mu, varcov)

# Store in an array similar to what we did in the ll function - we need to make a matrix - J rows, k columns and 1000 times
beta_S <- array(0, dim = c(J, k, nsim))

# Check dimensions:
dim(beta_S)

# fill the array with the sampling distribution of betas
for(sim in 1:nsim) { #take first set of betas and put in the matrix, go to the second layer, etc, etc
  beta_S[-1, ,sim] <- matrix(S[sim,],  #select everything but 1 row
                             ncol = k, 
                             byrow = T)
} #1000 matrices behind each other - each set of b is a matrix

beta_S

sel <- which(colnames(X2) == "lm2_msexism") # column 4
# Set up your scenarios
n_scenarios <- length(sexism_seq) # Number of scenarios; 10 as we have 10 cases

cases <- array(NA, c(dim(X2),
                     n_scenarios))  
dim(cases)

cases[, , ] <- X2 #fill with x

for (i in 1:n_scenarios) {
  cases[, sel, i] <-sexism_seq[i] #take observ values and assume that everyone has min income, 2nd time at 11 level, etc.
}


# Now our array V will have four (!) dimensions
 V2 <- #matrix of utilities
  array(NA, 
        dim = c(nrow(X2),       # number of observations - row
                J,             # number of categories - this form a matrix n*4 -columns
                nsim,          # number of simulations - how often we put each case behind each other
                n_scenarios))  # number of scenarios 
#the 1st column is always 0 (utilities to vote for CDA), 2nd row utility for 1st observation to vote for 3 parties (3 columns) - and again we do this 1000 times
# and we do it one more time for relig case ---> we have 4 dimens in total
dim(V2)

# 1) Loop over the scenarios
for (i in 1:n_scenarios) {
  # 2) in each scenario:
  #    loop over the simulations
  for (s in 1:nsim) {
    # 3) in each scenario and simulation:
    #    loop over the categories and calculate its utility
    for (j in 1:J) {
      # 4) calculate utility for the utility of 
      #    - the current scenario
      #    - based on the current set of simulated beta values
      #    - for the current outcome category
      
      V2[,j,s,i] <- cases[,,i] %*% beta_S[j,,s] 
      
      # cases[,,i] the i-th scenario that we specified
      # beta_S[j,,s] is the s-th simulation of beta for category j 
      # (remember: there's one set of beta for each category and each simulation)
    }
  }
}

# the apply command over more than two dimensions is hard!
# maybe a nested loop is more intuitive to understand what is happening here:

# Have a look at the dimensions
dim(V2)

# Now we want to summarize over multiple dimensions
Sexp <- apply(V2, c(1,3,4), function(v) sum(exp(v))) #sum of each row ; 1,3,4 - dimensions

dim(Sexp) #observ*simul *scenarios

# With V and Sexp we have everything to get P
P <- array(NA, c(nsim, J, n_scenarios))
dim(P)

for (scen in 1:n_scenarios) {
  for (category in 1:J) { #each column is div by the sum
    P[, category, scen] <- 
      apply(exp(V2[, category, , scen]) / Sexp[, , scen], 2, mean) #apply to each indiv sim; apply to the sim in the 2nd dimen (simul)
  }
}

P
# Summarize to get our quantities of interest

QoImean2 <- matrix(NA, nrow = 3, ncol = n_scenarios)
QoICI2 <- array(NA, dim = c(2,     # lower and upper bound
                           3,     # number of categories
                           10))   # number of scenarios


QoI_Mean2 <- apply(P, c(2, 3), mean) #mean of columns because each colum address each party, apply to every column in every layer
QoI_CI2 <-
  apply(P, c(2, 3), function(x)
    quantile(x, probs = c(0.025, 0.975)))

partycolors <- c("mediumseagreen", 
                 "red", 
                 "orange")
# Plot the results

plot(
  sexism_seq,
  QoI_Mean2[1,],
  type = "n",
  ylim = c(0, 1),
  bty = "n",
  ylab = "Predicted Probability of voting for Party",
  xlab = "Sexism",
  main = "The Effect of Sexism",
  las = 1
)

for (i in 1:3) {
  lines(sexism_seq, QoI_Mean2[i,], 
        col = partycolors[i],
        lwd = 2)
}

for (i in 1:3) {
  polygon(
    c(rev(sexism_seq), sexism_seq),
    c(rev(QoI_CI2[1, i,]), QoI_CI2[2, i,]),
    col = adjustcolor(partycolors[i], alpha = 0.2) ,
    border = NA
  )
}

legend(
  "topright",
  legend = levels(data_panel_complete$combined_dep_var),
  lty = 1,
  col = partycolors,
  bty = "n"
)
```

#Interactions

``` {r interaction}
inter_2019 <-  female1*lm1_msexism1

X3<- as.matrix( cbind(1,female1, age1, edu3_21, edu3_31, dhincome_all1, livingpartner1, intpol1, lm1_authoritarian1, lm1_ideol1, lm1_nativism1,
lm1_orgterr1, lm1_pop6amz1,lm1_msexism1, inter_2019))

startvals3 <- rep(0, ncol(X3) * (J1 - 1))

res3 <- optim(
  startvals3,
  ll_mnl,
  X = X3,
  Z = Z1,
  method = "BFGS",
  control = list(fnscale = -1, trace = TRUE),
  hessian = TRUE
)

res3$par 
betaHat <- matrix(res3$par,
                  ncol = ncol(X3), #number of indep var - 7
                  nrow = ncol(Z1)-1, #but we need to estimate 3 row instead of 4
                  byrow = T)

colnames(betaHat) <- c("(Intercept)", colnames(X3)[2:ncol(X3)])
rownames(betaHat) <-  levels(data_panel_complete1$combined_dep_var)[2:ncol(Z1)]


se <-
  matrix(sqrt(diag(solve(-res3$hessian))),
         ncol = ncol(X3),
         nrow = ncol(Z1)-1,
         byrow = T)
colnames(se) <- c("(Intercept)", colnames(X3)[2:ncol(X3)])
rownames(se) <-  levels(data_panel_complete1$combined_dep_var)[2:ncol(Z1)]

betaHat
se

library('nnet')
data_panel_complete1$combined_dep_var <- factor(data_panel_complete1$combined_dep_var)
data_panel_complete1$combined_dep_var <- relevel(data_panel_complete1$combined_dep_var, ref = "No vote")
check <- multinom(combined_dep_var ~ 
                    female + age + edu3_2 + edu3_3 + dhincome_all + livingpartner + intpol+ lm1_authoritarian+lm1_ideol+ lm1_nativism+
                    lm1_orgterr + lm1_pop6amz + lm1_msexism + female*lm1_msexism, 
                  data = data_panel_complete1)

summary(check)
betaHat
se
```

``` {r simulation interaction}

lm1_msexism <- na.omit(as.numeric(data_panel$lm1_msexism))

sexism_seq <- seq(min(lm1_msexism), max(lm1_msexism), length.out = 10)


# Get coefficients and the variance-covariance matrix for the simulation
mu <- res3$par
varcov <- solve(-res3$hessian)

# Define nsim, J (number of categories) and k (number of independent variables)
nsim <- 1000
J <- length(unique(data_panel_complete1$combined_dep_var))  # Number of categories
k <- ncol(X3)

# Set up the sampling distribution
S <- mvrnorm(nsim, mu, varcov)

# Store in an array similar to what we did in the ll function - we need to make a matrix - J rows, k columns and 1000 times
beta_S <- array(0, dim = c(J, k, nsim))

# Check dimensions:
dim(beta_S)

# fill the array with the sampling distribution of betas
for(sim in 1:nsim) { #take first set of betas and put in the matrix, go to the second layer, etc, etc
  beta_S[-1, ,sim] <- matrix(S[sim,],  #select everything but 1 row
                             ncol = k, 
                             byrow = T)
} #1000 matrices behind each other - each set of b is a matrix

beta_S

sel <- which(colnames(X3) == "inter_2019") # column 4
# Set up your scenarios
n_scenarios <- length(sexism_seq) # Number of scenarios; 10 as we have 10 cases

cases <- array(NA, c(dim(X3),
                     n_scenarios))  
dim(cases)

cases[, , ] <- X3 #fill with x

for (i in 1:n_scenarios) {
  cases[, sel, i] <-sexism_seq[i] #take observ values and assume that everyone has min income, 2nd time at 11 level, etc.
}


# Now our array V will have four (!) dimensions
 V2 <- #matrix of utilities
  array(NA, 
        dim = c(nrow(X1),       # number of observations - row
                J,             # number of categories - this form a matrix n*4 -columns
                nsim,          # number of simulations - how often we put each case behind each other
                n_scenarios))  # number of scenarios 
#the 1st column is always 0 (utilities to vote for CDA), 2nd row utility for 1st observation to vote for 3 parties (3 columns) - and again we do this 1000 times
# and we do it one more time for relig case ---> we have 4 dimens in total
dim(V2)

# 1) Loop over the scenarios
for (i in 1:n_scenarios) {
  # 2) in each scenario:
  #    loop over the simulations
  for (s in 1:nsim) {
    # 3) in each scenario and simulation:
    #    loop over the categories and calculate its utility
    for (j in 1:J) {
      # 4) calculate utility for the utility of 
      #    - the current scenario
      #    - based on the current set of simulated beta values
      #    - for the current outcome category
      
      V2[,j,s,i] <- cases[,,i] %*% beta_S[j,,s] 
      
      # cases[,,i] the i-th scenario that we specified
      # beta_S[j,,s] is the s-th simulation of beta for category j 
      # (remember: there's one set of beta for each category and each simulation)
    }
  }
}

# the apply command over more than two dimensions is hard!
# maybe a nested loop is more intuitive to understand what is happening here:

# Have a look at the dimensions
dim(V2)

# Now we want to summarize over multiple dimensions
Sexp <- apply(V2, c(1,3,4), function(v) sum(exp(v))) #sum of each row ; 1,3,4 - dimensions

dim(Sexp) #observ*simul *scenarios

# With V and Sexp we have everything to get P
P <- array(NA, c(nsim, J, n_scenarios))
dim(P)

for (scen in 1:n_scenarios) {
  for (category in 1:J) { #each column is div by the sum
    P[, category, scen] <- 
      apply(exp(V2[, category, , scen]) / Sexp[, , scen], 2, mean) #apply to each indiv sim; apply to the sim in the 2nd dimen (simul)
  }
}

P
# Summarize to get our quantities of interest

QoImean <- matrix(NA, nrow = 3, ncol = n_scenarios)
QoICI <- array(NA, dim = c(2,     # lower and upper bound
                           3,     # number of categories
                           10))   # number of scenarios


QoI_Mean <- apply(P, c(2, 3), mean) #mean of columns because each colum address each party, apply to every column in every layer
QoI_CI <-
  apply(P, c(2, 3), function(x)
    quantile(x, probs = c(0.025, 0.975)))

partycolors <- c("mediumseagreen", 
                 "red", 
                 "orange")
# Plot the results

plot(
  sexism_seq,
  QoI_Mean[1,],
  type = "n",
  ylim = c(0, 1),
  bty = "n",
  ylab = "Predicted Probability of voting for Party",
  xlab = "Sexism",
  main = "The Effect of Sexism",
  las = 1
)

for (i in 1:3) {
  lines(sexism_seq, QoI_Mean[i,], 
        col = partycolors[i],
        lwd = 2)
}

for (i in 1:3) {
  polygon(
    c(rev(sexism_seq), sexism_seq),
    c(rev(QoI_CI[1, i,]), QoI_CI[2, i,]),
    col = adjustcolor(partycolors[i], alpha = 0.2) ,
    border = NA
  )
}

legend(
  "topright",
  legend = levels(data_panel_complete$combined_dep_var),
  lty = 1,
  col = partycolors,
  bty = "n"
)
```




